{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f79f523b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading rect5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 126.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shape of rect5 segment: (1008, 1008, 16)\n",
      "reading remaining5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00, 15.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shape of remaining5 segment: (3696, 2352, 16)\n",
      "train_images (224, 224, 16)\n",
      "Length of train images: 440\n",
      "Train loader length: 220\n",
      "Valid loader length: 895\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "\n",
    "from transformers import AutoImageProcessor#, TimesformerModel\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "# from timesformer_pytorch import TimeSformer\n",
    "\n",
    "import random\n",
    "import threading\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import wandb\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "import segmentation_models_pytorch as smp\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "import PIL.Image\n",
    "\n",
    "PIL.Image.MAX_IMAGE_PIXELS = 933120000\n",
    "\n",
    "import utils\n",
    "import models.swin as swin\n",
    "\n",
    "class CFG:\n",
    "    # ============== comp exp name =============\n",
    "    current_dir = './'\n",
    "    segment_path = './train_scrolls/'\n",
    "    \n",
    "    start_idx = 24\n",
    "    in_chans = 16\n",
    "    \n",
    "    size = 224\n",
    "    tile_size = 224\n",
    "    stride = tile_size // 8\n",
    "    \n",
    "    train_batch_size =  2 # 32\n",
    "    valid_batch_size = 5\n",
    "    lr = 1e-4\n",
    "    num_workers = 8\n",
    "    # ============== model cfg =============\n",
    "    scheduler = 'cosine'#, 'linear'\n",
    "    epochs = 16\n",
    "    warmup_factor = 10\n",
    "    \n",
    "    # Change the size of fragments\n",
    "    frags_ratio1 = ['frag','re']\n",
    "    frags_ratio2 = ['202','s4','left']\n",
    "    ratio1 = 2\n",
    "    ratio2 = 1\n",
    "    \n",
    "    # ============== fold =============\n",
    "    segments = ['rect5','remaining5'] \n",
    "    valid_id = 'remaining5'#20231215151901'\n",
    "    \n",
    "    # ============== fixed =============\n",
    "    min_lr = 1e-7\n",
    "    weight_decay = 1e-6\n",
    "    max_grad_norm = 100\n",
    "    num_workers = 8\n",
    "    seed = 0\n",
    "    \n",
    "    # ============== comp exp name =============\n",
    "    comp_name = 'vesuvius'\n",
    "    exp_name = 'pretraining_all'\n",
    "\n",
    "    outputs_path = f'./outputs/{comp_name}/{exp_name}/'\n",
    "    model_dir = outputs_path + \\\n",
    "        f'{comp_name}-models/'\n",
    "        \n",
    "    # ============== augmentation =============\n",
    "    train_aug_list = [\n",
    "        # A.HorizontalFlip(p=0.5),\n",
    "        # A.VerticalFlip(p=0.5),\n",
    "        # A.RandomBrightnessContrast(p=0.75),\n",
    "        # A.ShiftScaleRotate(rotate_limit=360,shift_limit=0.15,scale_limit=0.15,p=0.75),\n",
    "        # A.OneOf([\n",
    "        #         A.GaussNoise(var_limit=[10, 50]),\n",
    "        #         A.GaussianBlur(),\n",
    "        #         A.MotionBlur(),\n",
    "        #         ], p=0.4),\n",
    "        # A.CoarseDropout(max_holes=2, max_width=int(size * 0.2), max_height=int(size * 0.2), \n",
    "        #                 mask_fill_value=0, p=0.5),\n",
    "        # A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), \n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "\n",
    "    valid_aug_list = [\n",
    "        # A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), \n",
    "        ToTensorV2(transpose_mask=True),  \n",
    "    ]\n",
    "    \n",
    "def get_transforms(data, cfg):\n",
    "    if data == 'train':\n",
    "        aug = A.Compose(cfg.train_aug_list)\n",
    "    elif data == 'valid':\n",
    "        aug = A.Compose(cfg.valid_aug_list)\n",
    "    return aug   \n",
    "\n",
    "\n",
    "# End any existing run (if still active)\n",
    "if wandb.run is not None:\n",
    "    wandb.finish()\n",
    "        \n",
    "utils.cfg_init(CFG)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "fragment_id = CFG.valid_id\n",
    "run_slug=f'SWIN_{CFG.segments}_valid={CFG.valid_id}_size={CFG.size}_lr={CFG.lr}_in_chans={CFG.in_chans}'\n",
    "valid_mask_gt = cv2.imread(f\"{CFG.segment_path}{fragment_id}/{fragment_id}_inklabels.png\", 0)\n",
    "\n",
    "if any(sub in fragment_id for sub in CFG.frags_ratio1):\n",
    "    scale = 1 / CFG.ratio1\n",
    "    new_w = int(valid_mask_gt.shape[1] * scale)\n",
    "    new_h = int(valid_mask_gt.shape[0] * scale)\n",
    "    valid_mask_gt = cv2.resize(valid_mask_gt, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "elif any(sub in fragment_id for sub in CFG.frags_ratio2):\n",
    "    scale = 1 / CFG.ratio2\n",
    "    new_w = int(valid_mask_gt.shape[1] * scale)\n",
    "    new_h = int(valid_mask_gt.shape[0] * scale)\n",
    "    valid_mask_gt = cv2.resize(valid_mask_gt, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "pred_shape=valid_mask_gt.shape\n",
    "\n",
    "train_images, train_masks, valid_images, valid_masks, valid_xyxys = utils.get_train_valid_dataset(CFG)\n",
    "\n",
    "print('train_images',train_images[0].shape)\n",
    "print(\"Length of train images:\", len(train_images))\n",
    "\n",
    "valid_xyxys = np.stack(valid_xyxys)\n",
    "train_dataset = swin.TimesformerDataset(\n",
    "    train_images, CFG, labels=train_masks, transform=get_transforms(data='valid', cfg=CFG))\n",
    "valid_dataset = swin.TimesformerDataset(\n",
    "    valid_images, CFG, xyxys=valid_xyxys, labels=valid_masks, transform=get_transforms(data='valid', cfg=CFG))\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                            batch_size=CFG.train_batch_size,\n",
    "                            shuffle=True,\n",
    "                            num_workers=CFG.num_workers, pin_memory=True, drop_last=True,\n",
    "                            )\n",
    "valid_loader = DataLoader(valid_dataset,\n",
    "                            batch_size=CFG.valid_batch_size,\n",
    "                            shuffle=False,\n",
    "                            num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "\n",
    "print(f\"Train loader length: {len(train_loader)}\")\n",
    "print(f\"Valid loader length: {len(valid_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e225db7b",
   "metadata": {},
   "source": [
    "# STAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "078636c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_reconstruction(original, reconstructed, sample_idx=0, num_frames=1):\n",
    "    \"\"\"\n",
    "    Visualize original and reconstructed video frames side-by-side.\n",
    "    \n",
    "    Args:\n",
    "        original: Tensor (B, T, C, H, W) original input video batch.\n",
    "        reconstructed: Tensor (B, T, C, H, W) reconstructed output from model.\n",
    "        sample_idx: Which sample in batch to visualize.\n",
    "        num_frames: How many time frames to display.\n",
    "    \"\"\"\n",
    "\n",
    "    orig = original[sample_idx].cpu().numpy()  # (T, C, H, W)\n",
    "    recon = reconstructed[sample_idx].cpu().detach().numpy()  # (T, C, H, W)\n",
    "    \n",
    "    # For visualization, convert channel order from C,H,W to H,W,C and clip to [0,1]\n",
    "    orig = np.transpose(orig, (0, 2, 3, 1))\n",
    "    recon = np.transpose(recon, (0, 2, 3, 1))\n",
    "    orig = np.clip(orig, 0, 1)\n",
    "    recon = np.clip(recon, 0, 1)\n",
    "\n",
    "    fig, axs = plt.subplots(2, num_frames, figsize=(num_frames * 3, 6))\n",
    "    for i in range(num_frames):\n",
    "        axs[0, i].imshow(orig[i])\n",
    "        axs[0, i].set_title(f'Original Frame {i}')\n",
    "        axs[0, i].axis('off')\n",
    "        \n",
    "        axs[1, i].imshow(recon[i])\n",
    "        axs[1, i].set_title(f'Reconstructed Frame {i}')\n",
    "        axs[1, i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def visualize_x_masked(x_masked, sample_idx=0, num_frames=4):\n",
    "    \"\"\"\n",
    "    Visualize masked input video frames.\n",
    "    \n",
    "    Args:\n",
    "        x_masked: tensor (B, C, T, H, W)\n",
    "        sample_idx: which sample in batch to visualize\n",
    "        num_frames: how many frames to show\n",
    "    \"\"\"\n",
    "    video = x_masked[sample_idx]  # (C, T, H, W)\n",
    "    print(video.shape)\n",
    "    C, T, H, W = video.shape\n",
    "\n",
    "    fig, axs = plt.subplots(1, num_frames, figsize=(num_frames * 3, 3))\n",
    "    for i in range(num_frames):\n",
    "        frame = video[:, i, :, :].permute(1, 2, 0).cpu().numpy()  # (H, W, C)\n",
    "        if C == 3:\n",
    "            frame = frame.clip(0, 1)  # Assuming normalized video frames\n",
    "        else:\n",
    "            frame = frame.squeeze()  # For single-channel\n",
    "\n",
    "        axs[i].imshow(frame)\n",
    "        axs[i].axis('off')\n",
    "        axs[i].set_title(f'Frame {i}')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "118bf12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name      | Type              | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | encoder   | SwinTransformer3d | 27.9 M | train\n",
      "1 | decoder   | Sequential        | 5.3 M  | train\n",
      "2 | criterion | MSELoss           | 0      | train\n",
      "--------------------------------------------------------\n",
      "33.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "33.2 M    Total params\n",
      "132.653   Total estimated model params size (MB)\n",
      "183       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/220 [00:00<?, ?it/s] "
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[2, 3, 2, 14, 14]' is invalid for input of size 466944",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 124\u001b[0m\n\u001b[1;32m    118\u001b[0m model \u001b[38;5;241m=\u001b[39m MAEPretrainSwin(patch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m    119\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m    120\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m    121\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    122\u001b[0m     log_every_n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m    123\u001b[0m )\n\u001b[0;32m--> 124\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:561\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:48\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     51\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:599\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    592\u001b[0m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    593\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    595\u001b[0m     ckpt_path,\n\u001b[1;32m    596\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    597\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    598\u001b[0m )\n\u001b[0;32m--> 599\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1012\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m-> 1012\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1056\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1055\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1056\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:216\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:455\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 455\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:150\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:320\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 320\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    322\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanual_optimization\u001b[38;5;241m.\u001b[39mrun(kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:192\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m         closure()\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:270\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_ready()\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_completed()\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:176\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    179\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/core/module.py:1302\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimizer_step\u001b[39m(\n\u001b[1;32m   1272\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1273\u001b[0m     epoch: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     optimizer_closure: Optional[Callable[[], Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1277\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;124;03m    the optimizer.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1300\u001b[0m \n\u001b[1;32m   1301\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1302\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py:154\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:239\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py:123\u001b[0m, in \u001b[0;36mPrecision.optimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[39;00m\n\u001b[1;32m    122\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/optim/optimizer.py:485\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    481\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    482\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m             )\n\u001b[0;32m--> 485\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/optim/optimizer.py:79\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 79\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/optim/adam.py:225\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 225\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m    228\u001b[0m     params_with_grad: \u001b[38;5;28mlist\u001b[39m[Tensor] \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py:109\u001b[0m, in \u001b[0;36mPrecision._wrap_closure\u001b[0;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_wrap_closure\u001b[39m(\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     98\u001b[0m     model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     99\u001b[0m     optimizer: Steppable,\n\u001b[1;32m    100\u001b[0m     closure: Callable[[], Any],\n\u001b[1;32m    101\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    102\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    hook is called.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m \n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m     closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer)\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m closure_result\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:146\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:131\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39menable_grad()\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ClosureResult:\n\u001b[0;32m--> 131\u001b[0m     step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarning_cache\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:319\u001b[0m, in \u001b[0;36m_AutomaticOptimization._training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Performs the actual train step with the tied hooks.\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \n\u001b[1;32m    310\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    315\u001b[0m \n\u001b[1;32m    316\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    317\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\n\u001b[0;32m--> 319\u001b[0m training_step_output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mpost_training_step()  \u001b[38;5;66;03m# unused hook - call anyway for backward compatibility\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training_step_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mworld_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:328\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 328\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    331\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:391\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 103\u001b[0m, in \u001b[0;36mMAEPretrainSwin.training_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtraining_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, batch_idx):\n\u001b[1;32m    102\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m batch  \u001b[38;5;66;03m# shape: (B, 3, T, H, W)\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m     recon, x_masked \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(recon, x)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[29], line 86\u001b[0m, in \u001b[0;36mMAEPretrainSwin.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     82\u001b[0m x_masked, ids_keep, ids_shuffle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_masking(x_patched, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39mmask_ratio)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# print('x_maskd',x_masked.shape)\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# Unpatchify the masked patches\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m x_masked \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munpatchify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_masked\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Run encoder\u001b[39;00m\n\u001b[1;32m     89\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x_masked)\n",
      "Cell \u001b[0;32mIn[29], line 57\u001b[0m, in \u001b[0;36mMAEPretrainSwin.unpatchify\u001b[0;34m(self, x, original_shape)\u001b[0m\n\u001b[1;32m     54\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(B, num_patches, patch_size, patch_size, patch_size, C)\n\u001b[1;32m     56\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m)  \u001b[38;5;66;03m# (B, C, num_patches_T, num_patches_H, num_patches_W, patch_size, patch_size, patch_size)\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m14\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m14\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# x = x.reshape(B, C, T,x.shape[-1]//2,-1)\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# print('x_unpatch',x.shape)\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[2, 3, 2, 14, 14]' is invalid for input of size 466944"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torchvision.models.video import swin_transformer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "\n",
    "class MAEPretrainSwin(pl.LightningModule):\n",
    "    def __init__(self, lr=1e-4, mask_ratio=0.9, patch_size=16):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.encoder = swin_transformer.swin3d_t(weights=None)\n",
    "        self.encoder.head = nn.Identity()\n",
    "\n",
    "        # Feature hook (grab feature before classification)\n",
    "        self.features = None\n",
    "        self.encoder.features[-1].register_forward_hook(self._hook)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv3d(768, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(256, 16, kernel_size=1)\n",
    "        )\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.patch_size = patch_size\n",
    "        \n",
    "            # ✅ Add this line\n",
    "        self.train_loss_history = []\n",
    "\n",
    "\n",
    "    def _hook(self, module, input, output):\n",
    "        # Save the last feature map for reconstruction\n",
    "        self.features = output  # shape: (B, T', H', W', C)\n",
    "\n",
    "    def patchify(self, x):\n",
    "        x = x.permute(0,2,1,3,4)\n",
    "        B, C, T, H, W = x.shape\n",
    "        # print(x.shape)\n",
    "        # Ensure patch_size is compatible with input dimensions\n",
    "        assert T % self.patch_size == 0 and H % self.patch_size == 0 and W % self.patch_size == 0, \"Input dimensions must be divisible by patch size\"\n",
    "\n",
    "        x = x.unfold(2, self.patch_size, self.patch_size).unfold(3, self.patch_size, self.patch_size).unfold(4, self.patch_size, self.patch_size)\n",
    "        x = x.contiguous().view(B, C, -1, self.patch_size, self.patch_size, self.patch_size)\n",
    "        x = x.permute(0, 2, 1, 3, 4, 5)  # (B, num_patches, C, patch_size, patch_size, patch_size)\n",
    "        x = x.reshape(B, -1, C * self.patch_size * self.patch_size * self.patch_size)  # (B, num_patches, C * patch_size^3)\n",
    "        # print('patchify',x.shape)\n",
    "        return x\n",
    "\n",
    "    def unpatchify(self, x, original_shape):\n",
    "        B, num_patches, _ = x.shape\n",
    "        T, C, H, W = original_shape\n",
    "        patch_size = self.patch_size\n",
    "        \n",
    "        x = x.view(B, num_patches, patch_size, patch_size, patch_size, C)\n",
    "\n",
    "        x = x.permute(0, 5, 1, 2, 3, 4)  # (B, C, num_patches_T, num_patches_H, num_patches_W, patch_size, patch_size, patch_size)\n",
    "        x = x.reshape(B, C,2, 14,14)\n",
    "        # x = x.reshape(B, C, T,x.shape[-1]//2,-1)\n",
    "        # print('x_unpatch',x.shape)\n",
    "        return x\n",
    "\n",
    "    def random_masking(self, x, ratio):\n",
    "        B, N, D = x.shape  # (B, num_patches, patch_dim)\n",
    "        len_keep = int(N * (1 - ratio))\n",
    "\n",
    "        noise = torch.rand(B, N, device=x.device)\n",
    "        ids_shuffle = torch.argsort(noise, dim=1)\n",
    "        ids_keep = ids_shuffle[:, :len_keep]\n",
    "\n",
    "        x_masked = torch.gather(x, dim=1, index=ids_keep.unsqueeze(-1).expand(-1, -1, D))\n",
    "        return x_masked, ids_keep, ids_shuffle\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (B, 3, T, H, W)\n",
    "        B, C, T, H, W = x.shape\n",
    "\n",
    "        # Patchify the input\n",
    "        x_patched = self.patchify(x)\n",
    "        # print(x_patched.shape)\n",
    "\n",
    "        # Apply random masking\n",
    "        x_masked, ids_keep, ids_shuffle = self.random_masking(x_patched, self.hparams.mask_ratio)\n",
    "        # print('x_maskd',x_masked.shape)\n",
    "\n",
    "        # Unpatchify the masked patches\n",
    "        x_masked = self.unpatchify(x_masked, (C, T, H, W))\n",
    "\n",
    "        # Run encoder\n",
    "        _ = self.encoder(x_masked)\n",
    "\n",
    "        # Hook saved the features\n",
    "        feat = self.features  # (B, T', H', W', C)\n",
    "        feat = feat.permute(0, 4, 1, 2, 3)  # → (B, C, T', H', W')\n",
    "\n",
    "        # Decode\n",
    "        recon = self.decoder(feat)\n",
    "        recon = nn.functional.interpolate(recon, size=(T, H, W), mode='trilinear', align_corners=False)\n",
    "\n",
    "        return recon, x_masked\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch  # shape: (B, 3, T, H, W)\n",
    "        recon, x_masked = self(x)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = self.criterion(recon, x)\n",
    "        self.train_loss_history.append(loss.item())  # ✅ Track loss here\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        if batch_idx == 0:\n",
    "            visualize_reconstruction(x, recon, sample_idx=0, num_frames=2)\n",
    "            visualize_x_masked(x_masked, sample_idx=0, num_frames=2)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.hparams.lr)\n",
    "\n",
    "\n",
    "model = MAEPretrainSwin(patch_size=16)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator='auto',\n",
    "    log_every_n_steps=20,\n",
    ")\n",
    "trainer.fit(model, train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1de0fa06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/44 [03:22<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/44 [00:58<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12213"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model\n",
    "del trainer\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n",
    "import gc\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3151c3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot training loss\n",
    "plt.plot(model.train_loss_history[10:])\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304a380b",
   "metadata": {},
   "source": [
    "# assymtIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19d348c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_reconstruction(original, reconstructed, sample_idx=0, num_frames=2):\n",
    "    \"\"\"\n",
    "    Visualize original and reconstructed video frames side-by-side.\n",
    "    \n",
    "    Args:\n",
    "        original: Tensor (B, T, C, H, W) original input video batch.\n",
    "        reconstructed: Tensor (B, T, C, H, W) reconstructed output from model.\n",
    "        sample_idx: Which sample in batch to visualize.\n",
    "        num_frames: How many time frames to display.\n",
    "    \"\"\"\n",
    "\n",
    "    orig = original[sample_idx].cpu().numpy()  # (T, C, H, W)\n",
    "    recon = reconstructed[sample_idx].cpu().detach().numpy()  # (T, C, H, W)\n",
    "    \n",
    "    # For visualization, convert channel order from C,H,W to H,W,C and clip to [0,1]\n",
    "    orig = np.transpose(orig, (0, 2, 3, 1))\n",
    "    recon = np.transpose(recon, (0, 2, 3, 1))\n",
    "    orig = np.clip(orig, 0, 1)\n",
    "    recon = np.clip(recon, 0, 1)\n",
    "\n",
    "    fig, axs = plt.subplots(2, num_frames, figsize=(num_frames * 3, 6))\n",
    "    for i in range(num_frames):\n",
    "        axs[0, i].imshow(orig[i])\n",
    "        axs[0, i].set_title(f'Original Frame {i}')\n",
    "        axs[0, i].axis('off')\n",
    "        \n",
    "        axs[1, i].imshow(recon[i])\n",
    "        axs[1, i].set_title(f'Reconstructed Frame {i}')\n",
    "        axs[1, i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def visualize_x_masked(x_masked, sample_idx=0, num_frames=4):\n",
    "    \"\"\"\n",
    "    Visualize masked input video frames.\n",
    "    \n",
    "    Args:\n",
    "        x_masked: tensor (B, C, T, H, W)\n",
    "        sample_idx: which sample in batch to visualize\n",
    "        num_frames: how many frames to show\n",
    "    \"\"\"\n",
    "    video = x_masked[sample_idx]  # (C, T, H, W)\n",
    "    C, T, H, W = video.shape\n",
    "\n",
    "    fig, axs = plt.subplots(1, num_frames, figsize=(num_frames * 3, 3))\n",
    "    for i in range(num_frames):\n",
    "        frame = video[:, i, :, :].permute(1, 2, 0).cpu().numpy()  # (H, W, C)\n",
    "        if C == 3:\n",
    "            frame = frame.clip(0, 1)  # Assuming normalized video frames\n",
    "        else:\n",
    "            frame = frame.squeeze()  # For single-channel\n",
    "\n",
    "        axs[i].imshow(frame)\n",
    "        axs[i].axis('off')\n",
    "        axs[i].set_title(f'Frame {i}')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b22abc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/88 [06:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/88 [05:44<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/88 [00:33<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19617"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model\n",
    "del trainer\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n",
    "import gc\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cffea5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/dion/lib/python3.10/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "Trainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name                | Type               | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | encoder             | SwinTransformer3d  | 27.9 M | train\n",
      "1 | criterion           | MSELoss            | 0      | train\n",
      "2 | decoder_embed       | Linear             | 393 K  | train\n",
      "3 | decoder_transformer | TransformerEncoder | 6.3 M  | train\n",
      "4 | decoder_pred        | Linear             | 6.3 M  | train\n",
      "  | other params        | n/a                | 512 K  | n/a  \n",
      "-------------------------------------------------------------------\n",
      "41.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "41.4 M    Total params\n",
      "165.461   Total estimated model params size (MB)\n",
      "203       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/220 [00:00<?, ?it/s] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:   0%|          | 1/220 [00:00<00:42,  5.18it/s, v_num=304, train_loss=0.502]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:   1%|          | 2/220 [00:00<00:28,  7.75it/s, v_num=304, train_loss=0.485]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:   1%|▏         | 3/220 [00:00<00:22,  9.44it/s, v_num=304, train_loss=0.468]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:   2%|▏         | 4/220 [00:00<00:20, 10.51it/s, v_num=304, train_loss=0.455]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:   2%|▏         | 5/220 [00:00<00:18, 11.45it/s, v_num=304, train_loss=0.429]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:   3%|▎         | 6/220 [00:00<00:17, 12.19it/s, v_num=304, train_loss=0.399]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:   3%|▎         | 7/220 [00:00<00:16, 12.79it/s, v_num=304, train_loss=0.380]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:   4%|▎         | 8/220 [00:00<00:15, 13.29it/s, v_num=304, train_loss=0.348]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:   4%|▍         | 9/220 [00:00<00:15, 13.72it/s, v_num=304, train_loss=0.323]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:   5%|▍         | 10/220 [00:00<00:14, 14.07it/s, v_num=304, train_loss=0.292]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:   5%|▌         | 11/220 [00:00<00:14, 14.33it/s, v_num=304, train_loss=0.265]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:   5%|▌         | 12/220 [00:00<00:14, 14.56it/s, v_num=304, train_loss=0.227]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:   6%|▌         | 13/220 [00:00<00:14, 14.74it/s, v_num=304, train_loss=0.213]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:   6%|▋         | 14/220 [00:00<00:13, 14.96it/s, v_num=304, train_loss=0.188]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:   7%|▋         | 15/220 [00:00<00:13, 15.13it/s, v_num=304, train_loss=0.160]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:   7%|▋         | 16/220 [00:01<00:13, 15.30it/s, v_num=304, train_loss=0.145]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:   8%|▊         | 17/220 [00:01<00:13, 15.46it/s, v_num=304, train_loss=0.123]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:   8%|▊         | 18/220 [00:01<00:12, 15.58it/s, v_num=304, train_loss=0.110]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:   9%|▊         | 19/220 [00:01<00:12, 15.69it/s, v_num=304, train_loss=0.0996]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:   9%|▉         | 20/220 [00:01<00:12, 15.78it/s, v_num=304, train_loss=0.0901]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  10%|▉         | 21/220 [00:01<00:12, 15.86it/s, v_num=304, train_loss=0.0916]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  10%|█         | 22/220 [00:01<00:12, 15.97it/s, v_num=304, train_loss=0.0726]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  10%|█         | 23/220 [00:01<00:12, 16.07it/s, v_num=304, train_loss=0.0688]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  11%|█         | 24/220 [00:01<00:12, 16.16it/s, v_num=304, train_loss=0.0765]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  11%|█▏        | 25/220 [00:01<00:12, 16.24it/s, v_num=304, train_loss=0.0645]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  12%|█▏        | 26/220 [00:01<00:11, 16.31it/s, v_num=304, train_loss=0.0622]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  12%|█▏        | 27/220 [00:01<00:11, 16.37it/s, v_num=304, train_loss=0.0564]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  13%|█▎        | 28/220 [00:01<00:11, 16.43it/s, v_num=304, train_loss=0.0655]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  13%|█▎        | 29/220 [00:01<00:11, 16.48it/s, v_num=304, train_loss=0.0628]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  14%|█▎        | 30/220 [00:01<00:11, 16.53it/s, v_num=304, train_loss=0.0646]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  14%|█▍        | 31/220 [00:01<00:11, 16.59it/s, v_num=304, train_loss=0.0816]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  15%|█▍        | 32/220 [00:01<00:11, 16.64it/s, v_num=304, train_loss=0.0651]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  15%|█▌        | 33/220 [00:01<00:11, 16.70it/s, v_num=304, train_loss=0.0615]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  15%|█▌        | 34/220 [00:02<00:11, 16.75it/s, v_num=304, train_loss=0.0686]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  16%|█▌        | 35/220 [00:02<00:11, 16.80it/s, v_num=304, train_loss=0.0675]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  16%|█▋        | 36/220 [00:02<00:10, 16.83it/s, v_num=304, train_loss=0.0619]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  17%|█▋        | 37/220 [00:02<00:10, 16.89it/s, v_num=304, train_loss=0.0566]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  17%|█▋        | 38/220 [00:02<00:10, 16.94it/s, v_num=304, train_loss=0.0593]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  18%|█▊        | 39/220 [00:02<00:10, 16.99it/s, v_num=304, train_loss=0.0599]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  18%|█▊        | 40/220 [00:02<00:10, 17.04it/s, v_num=304, train_loss=0.0677]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  19%|█▊        | 41/220 [00:02<00:10, 17.09it/s, v_num=304, train_loss=0.0553]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  19%|█▉        | 42/220 [00:02<00:10, 17.13it/s, v_num=304, train_loss=0.0516]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  20%|█▉        | 43/220 [00:02<00:10, 17.15it/s, v_num=304, train_loss=0.0525]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  20%|██        | 44/220 [00:02<00:10, 17.18it/s, v_num=304, train_loss=0.0531]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  20%|██        | 45/220 [00:02<00:10, 17.21it/s, v_num=304, train_loss=0.051] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  21%|██        | 46/220 [00:02<00:10, 17.25it/s, v_num=304, train_loss=0.0602]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  21%|██▏       | 47/220 [00:02<00:10, 17.29it/s, v_num=304, train_loss=0.0534]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  22%|██▏       | 48/220 [00:02<00:09, 17.34it/s, v_num=304, train_loss=0.0599]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  22%|██▏       | 49/220 [00:02<00:09, 17.38it/s, v_num=304, train_loss=0.0555]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  23%|██▎       | 50/220 [00:02<00:09, 17.41it/s, v_num=304, train_loss=0.0612]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  23%|██▎       | 51/220 [00:02<00:09, 17.42it/s, v_num=304, train_loss=0.0562]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  24%|██▎       | 52/220 [00:02<00:09, 17.44it/s, v_num=304, train_loss=0.0727]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  24%|██▍       | 53/220 [00:03<00:09, 17.47it/s, v_num=304, train_loss=0.0541]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  25%|██▍       | 54/220 [00:03<00:09, 17.50it/s, v_num=304, train_loss=0.0587]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  25%|██▌       | 55/220 [00:03<00:09, 17.53it/s, v_num=304, train_loss=0.0571]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  25%|██▌       | 56/220 [00:03<00:09, 17.57it/s, v_num=304, train_loss=0.0611]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  26%|██▌       | 57/220 [00:03<00:09, 17.59it/s, v_num=304, train_loss=0.0443]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  26%|██▋       | 58/220 [00:03<00:09, 17.62it/s, v_num=304, train_loss=0.0533]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  27%|██▋       | 59/220 [00:03<00:09, 17.63it/s, v_num=304, train_loss=0.0459]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  27%|██▋       | 60/220 [00:03<00:09, 17.64it/s, v_num=304, train_loss=0.0433]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  28%|██▊       | 61/220 [00:03<00:09, 17.65it/s, v_num=304, train_loss=0.0561]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  28%|██▊       | 62/220 [00:03<00:08, 17.68it/s, v_num=304, train_loss=0.0638]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  29%|██▊       | 63/220 [00:03<00:08, 17.70it/s, v_num=304, train_loss=0.0524]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  29%|██▉       | 64/220 [00:03<00:08, 17.72it/s, v_num=304, train_loss=0.0513]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  30%|██▉       | 65/220 [00:03<00:08, 17.75it/s, v_num=304, train_loss=0.0435]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  30%|███       | 66/220 [00:03<00:08, 17.76it/s, v_num=304, train_loss=0.0563]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  30%|███       | 67/220 [00:03<00:08, 17.77it/s, v_num=304, train_loss=0.042] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  31%|███       | 68/220 [00:03<00:08, 17.78it/s, v_num=304, train_loss=0.0635]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  31%|███▏      | 69/220 [00:03<00:08, 17.80it/s, v_num=304, train_loss=0.0518]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  32%|███▏      | 70/220 [00:03<00:08, 17.81it/s, v_num=304, train_loss=0.0582]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  32%|███▏      | 71/220 [00:03<00:08, 17.83it/s, v_num=304, train_loss=0.0511]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  33%|███▎      | 72/220 [00:04<00:08, 17.85it/s, v_num=304, train_loss=0.0507]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  33%|███▎      | 73/220 [00:04<00:08, 17.88it/s, v_num=304, train_loss=0.0417]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  34%|███▎      | 74/220 [00:04<00:08, 17.89it/s, v_num=304, train_loss=0.0416]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  34%|███▍      | 75/220 [00:04<00:08, 17.89it/s, v_num=304, train_loss=0.0423]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  35%|███▍      | 76/220 [00:04<00:08, 17.90it/s, v_num=304, train_loss=0.0572]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  35%|███▌      | 77/220 [00:04<00:07, 17.91it/s, v_num=304, train_loss=0.0406]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  35%|███▌      | 78/220 [00:04<00:07, 17.93it/s, v_num=304, train_loss=0.0445]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  36%|███▌      | 79/220 [00:04<00:07, 17.95it/s, v_num=304, train_loss=0.0624]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  36%|███▋      | 80/220 [00:04<00:07, 17.97it/s, v_num=304, train_loss=0.0547]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  37%|███▋      | 81/220 [00:04<00:07, 17.98it/s, v_num=304, train_loss=0.0492]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  37%|███▋      | 82/220 [00:04<00:07, 17.99it/s, v_num=304, train_loss=0.0623]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  38%|███▊      | 83/220 [00:04<00:07, 18.00it/s, v_num=304, train_loss=0.043] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  38%|███▊      | 84/220 [00:04<00:07, 18.00it/s, v_num=304, train_loss=0.0468]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  39%|███▊      | 85/220 [00:04<00:07, 18.01it/s, v_num=304, train_loss=0.0507]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  39%|███▉      | 86/220 [00:04<00:07, 18.02it/s, v_num=304, train_loss=0.0486]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  40%|███▉      | 87/220 [00:04<00:07, 18.04it/s, v_num=304, train_loss=0.0496]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  40%|████      | 88/220 [00:04<00:07, 18.06it/s, v_num=304, train_loss=0.0447]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  40%|████      | 89/220 [00:04<00:07, 18.07it/s, v_num=304, train_loss=0.0504]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  41%|████      | 90/220 [00:04<00:07, 18.08it/s, v_num=304, train_loss=0.0434]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  41%|████▏     | 91/220 [00:05<00:07, 18.08it/s, v_num=304, train_loss=0.052] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  42%|████▏     | 92/220 [00:05<00:07, 18.08it/s, v_num=304, train_loss=0.0435]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  42%|████▏     | 93/220 [00:05<00:07, 18.09it/s, v_num=304, train_loss=0.0432]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  43%|████▎     | 94/220 [00:05<00:06, 18.10it/s, v_num=304, train_loss=0.0433]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  43%|████▎     | 95/220 [00:05<00:06, 18.12it/s, v_num=304, train_loss=0.0587]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  44%|████▎     | 96/220 [00:05<00:06, 18.13it/s, v_num=304, train_loss=0.0575]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  44%|████▍     | 97/220 [00:05<00:06, 18.14it/s, v_num=304, train_loss=0.0532]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  45%|████▍     | 98/220 [00:05<00:06, 18.15it/s, v_num=304, train_loss=0.0704]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  45%|████▌     | 99/220 [00:05<00:06, 18.15it/s, v_num=304, train_loss=0.0443]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  45%|████▌     | 100/220 [00:05<00:06, 18.15it/s, v_num=304, train_loss=0.0519]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  46%|████▌     | 101/220 [00:05<00:06, 18.16it/s, v_num=304, train_loss=0.0531]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  46%|████▋     | 102/220 [00:05<00:06, 18.17it/s, v_num=304, train_loss=0.047] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  47%|████▋     | 103/220 [00:05<00:06, 18.18it/s, v_num=304, train_loss=0.0494]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  47%|████▋     | 104/220 [00:05<00:06, 18.19it/s, v_num=304, train_loss=0.062] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  48%|████▊     | 105/220 [00:05<00:06, 18.20it/s, v_num=304, train_loss=0.0583]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  48%|████▊     | 106/220 [00:05<00:06, 18.21it/s, v_num=304, train_loss=0.0548]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  49%|████▊     | 107/220 [00:05<00:06, 18.21it/s, v_num=304, train_loss=0.0504]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  49%|████▉     | 108/220 [00:05<00:06, 18.21it/s, v_num=304, train_loss=0.0479]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  50%|████▉     | 109/220 [00:05<00:06, 18.22it/s, v_num=304, train_loss=0.0492]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  50%|█████     | 110/220 [00:06<00:06, 18.23it/s, v_num=304, train_loss=0.044] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  50%|█████     | 111/220 [00:06<00:05, 18.24it/s, v_num=304, train_loss=0.0464]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  51%|█████     | 112/220 [00:06<00:05, 18.25it/s, v_num=304, train_loss=0.0446]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  51%|█████▏    | 113/220 [00:06<00:05, 18.26it/s, v_num=304, train_loss=0.0517]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  52%|█████▏    | 114/220 [00:06<00:05, 18.26it/s, v_num=304, train_loss=0.049] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  52%|█████▏    | 115/220 [00:06<00:05, 18.26it/s, v_num=304, train_loss=0.0522]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  53%|█████▎    | 116/220 [00:06<00:05, 18.26it/s, v_num=304, train_loss=0.0594]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  53%|█████▎    | 117/220 [00:06<00:05, 18.27it/s, v_num=304, train_loss=0.048] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  54%|█████▎    | 118/220 [00:06<00:05, 18.27it/s, v_num=304, train_loss=0.0583]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  54%|█████▍    | 119/220 [00:06<00:05, 18.28it/s, v_num=304, train_loss=0.0581]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  55%|█████▍    | 120/220 [00:06<00:05, 18.29it/s, v_num=304, train_loss=0.0515]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  55%|█████▌    | 121/220 [00:06<00:05, 18.30it/s, v_num=304, train_loss=0.0421]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  55%|█████▌    | 122/220 [00:06<00:05, 18.31it/s, v_num=304, train_loss=0.0501]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  56%|█████▌    | 123/220 [00:06<00:05, 18.31it/s, v_num=304, train_loss=0.0628]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  56%|█████▋    | 124/220 [00:06<00:05, 18.31it/s, v_num=304, train_loss=0.0453]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  57%|█████▋    | 125/220 [00:06<00:05, 18.31it/s, v_num=304, train_loss=0.0549]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  57%|█████▋    | 126/220 [00:06<00:05, 18.32it/s, v_num=304, train_loss=0.0491]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  58%|█████▊    | 127/220 [00:06<00:05, 18.33it/s, v_num=304, train_loss=0.0478]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  58%|█████▊    | 128/220 [00:06<00:05, 18.34it/s, v_num=304, train_loss=0.0405]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  59%|█████▊    | 129/220 [00:07<00:04, 18.35it/s, v_num=304, train_loss=0.0516]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  59%|█████▉    | 130/220 [00:07<00:04, 18.35it/s, v_num=304, train_loss=0.0478]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  60%|█████▉    | 131/220 [00:07<00:04, 18.35it/s, v_num=304, train_loss=0.0513]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  60%|██████    | 132/220 [00:07<00:04, 18.35it/s, v_num=304, train_loss=0.0648]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  60%|██████    | 133/220 [00:07<00:04, 18.36it/s, v_num=304, train_loss=0.0433]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  61%|██████    | 134/220 [00:07<00:04, 18.36it/s, v_num=304, train_loss=0.0404]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  61%|██████▏   | 135/220 [00:07<00:04, 18.37it/s, v_num=304, train_loss=0.0501]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  62%|██████▏   | 136/220 [00:07<00:04, 18.38it/s, v_num=304, train_loss=0.0572]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  62%|██████▏   | 137/220 [00:07<00:04, 18.39it/s, v_num=304, train_loss=0.0402]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  63%|██████▎   | 138/220 [00:07<00:04, 18.39it/s, v_num=304, train_loss=0.0427]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  63%|██████▎   | 139/220 [00:07<00:04, 18.39it/s, v_num=304, train_loss=0.0423]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  64%|██████▎   | 140/220 [00:07<00:04, 18.39it/s, v_num=304, train_loss=0.0568]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  64%|██████▍   | 141/220 [00:07<00:04, 18.39it/s, v_num=304, train_loss=0.0443]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  65%|██████▍   | 142/220 [00:07<00:04, 18.40it/s, v_num=304, train_loss=0.041] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  65%|██████▌   | 143/220 [00:07<00:04, 18.41it/s, v_num=304, train_loss=0.0428]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  65%|██████▌   | 144/220 [00:07<00:04, 18.42it/s, v_num=304, train_loss=0.0383]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  66%|██████▌   | 145/220 [00:07<00:04, 18.42it/s, v_num=304, train_loss=0.0527]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  66%|██████▋   | 146/220 [00:07<00:04, 18.43it/s, v_num=304, train_loss=0.0587]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  67%|██████▋   | 147/220 [00:07<00:03, 18.43it/s, v_num=304, train_loss=0.0458]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  67%|██████▋   | 148/220 [00:08<00:03, 18.43it/s, v_num=304, train_loss=0.050] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  68%|██████▊   | 149/220 [00:08<00:03, 18.43it/s, v_num=304, train_loss=0.0392]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  68%|██████▊   | 150/220 [00:08<00:03, 18.44it/s, v_num=304, train_loss=0.0493]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  69%|██████▊   | 151/220 [00:08<00:03, 18.44it/s, v_num=304, train_loss=0.0566]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  69%|██████▉   | 152/220 [00:08<00:03, 18.45it/s, v_num=304, train_loss=0.042] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  70%|██████▉   | 153/220 [00:08<00:03, 18.46it/s, v_num=304, train_loss=0.0396]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  70%|███████   | 154/220 [00:08<00:03, 18.46it/s, v_num=304, train_loss=0.0539]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  70%|███████   | 155/220 [00:08<00:03, 18.46it/s, v_num=304, train_loss=0.0488]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  71%|███████   | 156/220 [00:08<00:03, 18.46it/s, v_num=304, train_loss=0.0527]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  71%|███████▏  | 157/220 [00:08<00:03, 18.45it/s, v_num=304, train_loss=0.0474]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  72%|███████▏  | 158/220 [00:08<00:03, 18.46it/s, v_num=304, train_loss=0.0394]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  72%|███████▏  | 159/220 [00:08<00:03, 18.46it/s, v_num=304, train_loss=0.0462]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  73%|███████▎  | 160/220 [00:08<00:03, 18.46it/s, v_num=304, train_loss=0.0436]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  73%|███████▎  | 161/220 [00:08<00:03, 18.45it/s, v_num=304, train_loss=0.0453]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  74%|███████▎  | 162/220 [00:08<00:03, 18.45it/s, v_num=304, train_loss=0.0491]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  74%|███████▍  | 163/220 [00:08<00:03, 18.45it/s, v_num=304, train_loss=0.048] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  75%|███████▍  | 164/220 [00:08<00:03, 18.44it/s, v_num=304, train_loss=0.0467]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  75%|███████▌  | 165/220 [00:08<00:02, 18.44it/s, v_num=304, train_loss=0.0522]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  75%|███████▌  | 166/220 [00:09<00:02, 18.44it/s, v_num=304, train_loss=0.0413]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  76%|███████▌  | 167/220 [00:09<00:02, 18.44it/s, v_num=304, train_loss=0.0469]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  76%|███████▋  | 168/220 [00:09<00:02, 18.44it/s, v_num=304, train_loss=0.0437]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  77%|███████▋  | 169/220 [00:09<00:02, 18.44it/s, v_num=304, train_loss=0.052] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  77%|███████▋  | 170/220 [00:09<00:02, 18.44it/s, v_num=304, train_loss=0.0422]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  78%|███████▊  | 171/220 [00:09<00:02, 18.44it/s, v_num=304, train_loss=0.054] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  78%|███████▊  | 172/220 [00:09<00:02, 18.43it/s, v_num=304, train_loss=0.0465]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  79%|███████▊  | 173/220 [00:09<00:02, 18.43it/s, v_num=304, train_loss=0.0418]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  79%|███████▉  | 174/220 [00:09<00:02, 18.43it/s, v_num=304, train_loss=0.0456]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  80%|███████▉  | 175/220 [00:09<00:02, 18.43it/s, v_num=304, train_loss=0.0429]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  80%|████████  | 176/220 [00:09<00:02, 18.43it/s, v_num=304, train_loss=0.0479]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  80%|████████  | 177/220 [00:09<00:02, 18.43it/s, v_num=304, train_loss=0.0442]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  81%|████████  | 178/220 [00:09<00:02, 18.44it/s, v_num=304, train_loss=0.0628]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  81%|████████▏ | 179/220 [00:09<00:02, 18.44it/s, v_num=304, train_loss=0.055] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  82%|████████▏ | 180/220 [00:09<00:02, 18.43it/s, v_num=304, train_loss=0.0594]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  82%|████████▏ | 181/220 [00:09<00:02, 18.44it/s, v_num=304, train_loss=0.0575]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  83%|████████▎ | 182/220 [00:09<00:02, 18.44it/s, v_num=304, train_loss=0.0562]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  83%|████████▎ | 183/220 [00:09<00:02, 18.45it/s, v_num=304, train_loss=0.0435]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  84%|████████▎ | 184/220 [00:09<00:01, 18.45it/s, v_num=304, train_loss=0.044] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  84%|████████▍ | 185/220 [00:10<00:01, 18.46it/s, v_num=304, train_loss=0.0431]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  85%|████████▍ | 186/220 [00:10<00:01, 18.46it/s, v_num=304, train_loss=0.0413]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  85%|████████▌ | 187/220 [00:10<00:01, 18.46it/s, v_num=304, train_loss=0.0457]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  85%|████████▌ | 188/220 [00:10<00:01, 18.46it/s, v_num=304, train_loss=0.0492]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  86%|████████▌ | 189/220 [00:10<00:01, 18.46it/s, v_num=304, train_loss=0.0479]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  86%|████████▋ | 190/220 [00:10<00:01, 18.47it/s, v_num=304, train_loss=0.0546]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  87%|████████▋ | 191/220 [00:10<00:01, 18.47it/s, v_num=304, train_loss=0.0466]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  87%|████████▋ | 192/220 [00:10<00:01, 18.48it/s, v_num=304, train_loss=0.0485]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  88%|████████▊ | 193/220 [00:10<00:01, 18.48it/s, v_num=304, train_loss=0.0474]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  88%|████████▊ | 194/220 [00:10<00:01, 18.49it/s, v_num=304, train_loss=0.0396]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  89%|████████▊ | 195/220 [00:10<00:01, 18.48it/s, v_num=304, train_loss=0.0484]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  89%|████████▉ | 196/220 [00:10<00:01, 18.48it/s, v_num=304, train_loss=0.0427]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  90%|████████▉ | 197/220 [00:10<00:01, 18.48it/s, v_num=304, train_loss=0.0527]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  90%|█████████ | 198/220 [00:10<00:01, 18.48it/s, v_num=304, train_loss=0.0368]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  90%|█████████ | 199/220 [00:10<00:01, 18.48it/s, v_num=304, train_loss=0.0502]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  91%|█████████ | 200/220 [00:10<00:01, 18.48it/s, v_num=304, train_loss=0.0418]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  91%|█████████▏| 201/220 [00:10<00:01, 18.48it/s, v_num=304, train_loss=0.0397]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  92%|█████████▏| 202/220 [00:10<00:00, 18.47it/s, v_num=304, train_loss=0.0471]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  92%|█████████▏| 203/220 [00:10<00:00, 18.47it/s, v_num=304, train_loss=0.0456]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  93%|█████████▎| 204/220 [00:11<00:00, 18.47it/s, v_num=304, train_loss=0.0427]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  93%|█████████▎| 205/220 [00:11<00:00, 18.46it/s, v_num=304, train_loss=0.038] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  94%|█████████▎| 206/220 [00:11<00:00, 18.46it/s, v_num=304, train_loss=0.0525]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  94%|█████████▍| 207/220 [00:11<00:00, 18.46it/s, v_num=304, train_loss=0.0455]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  95%|█████████▍| 208/220 [00:11<00:00, 18.46it/s, v_num=304, train_loss=0.0521]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  95%|█████████▌| 209/220 [00:11<00:00, 18.46it/s, v_num=304, train_loss=0.0512]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  95%|█████████▌| 210/220 [00:11<00:00, 18.46it/s, v_num=304, train_loss=0.044] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  96%|█████████▌| 211/220 [00:11<00:00, 18.46it/s, v_num=304, train_loss=0.0437]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  96%|█████████▋| 212/220 [00:11<00:00, 18.46it/s, v_num=304, train_loss=0.0404]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  97%|█████████▋| 213/220 [00:11<00:00, 18.46it/s, v_num=304, train_loss=0.0502]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  97%|█████████▋| 214/220 [00:11<00:00, 18.46it/s, v_num=304, train_loss=0.0368]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  98%|█████████▊| 215/220 [00:11<00:00, 18.46it/s, v_num=304, train_loss=0.0463]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  98%|█████████▊| 216/220 [00:11<00:00, 18.46it/s, v_num=304, train_loss=0.0518]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  99%|█████████▊| 217/220 [00:11<00:00, 18.46it/s, v_num=304, train_loss=0.0404]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0:  99%|█████████▉| 218/220 [00:11<00:00, 18.47it/s, v_num=304, train_loss=0.0604]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 0: 100%|█████████▉| 219/220 [00:11<00:00, 18.47it/s, v_num=304, train_loss=0.0376]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:   0%|          | 0/220 [00:00<?, ?it/s, v_num=304, train_loss=0.0381]          196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:   0%|          | 1/220 [00:01<05:21,  0.68it/s, v_num=304, train_loss=0.0519]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:   1%|          | 2/220 [00:01<02:45,  1.31it/s, v_num=304, train_loss=0.0518]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:   1%|▏         | 3/220 [00:01<01:54,  1.90it/s, v_num=304, train_loss=0.0415]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:   2%|▏         | 4/220 [00:01<01:28,  2.44it/s, v_num=304, train_loss=0.044] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:   2%|▏         | 5/220 [00:01<01:12,  2.95it/s, v_num=304, train_loss=0.0419]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:   3%|▎         | 6/220 [00:01<01:02,  3.43it/s, v_num=304, train_loss=0.0397]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:   3%|▎         | 7/220 [00:01<00:54,  3.87it/s, v_num=304, train_loss=0.0407]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:   4%|▎         | 8/220 [00:01<00:49,  4.30it/s, v_num=304, train_loss=0.0445]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:   4%|▍         | 9/220 [00:01<00:44,  4.70it/s, v_num=304, train_loss=0.0391]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:   5%|▍         | 10/220 [00:01<00:41,  5.07it/s, v_num=304, train_loss=0.0346]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:   5%|▌         | 11/220 [00:02<00:38,  5.43it/s, v_num=304, train_loss=0.0471]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:   5%|▌         | 12/220 [00:02<00:36,  5.74it/s, v_num=304, train_loss=0.0487]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:   6%|▌         | 13/220 [00:02<00:34,  6.06it/s, v_num=304, train_loss=0.0454]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:   6%|▋         | 14/220 [00:02<00:32,  6.36it/s, v_num=304, train_loss=0.0419]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:   7%|▋         | 15/220 [00:02<00:30,  6.64it/s, v_num=304, train_loss=0.0389]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:   7%|▋         | 16/220 [00:02<00:29,  6.91it/s, v_num=304, train_loss=0.0467]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:   8%|▊         | 17/220 [00:02<00:28,  7.18it/s, v_num=304, train_loss=0.0398]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:   8%|▊         | 18/220 [00:02<00:27,  7.43it/s, v_num=304, train_loss=0.0505]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:   9%|▊         | 19/220 [00:02<00:26,  7.67it/s, v_num=304, train_loss=0.0411]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:   9%|▉         | 20/220 [00:02<00:25,  7.87it/s, v_num=304, train_loss=0.040] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  10%|▉         | 21/220 [00:02<00:24,  8.08it/s, v_num=304, train_loss=0.0409]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  10%|█         | 22/220 [00:02<00:23,  8.28it/s, v_num=304, train_loss=0.0383]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  10%|█         | 23/220 [00:02<00:23,  8.48it/s, v_num=304, train_loss=0.0368]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  11%|█         | 24/220 [00:02<00:22,  8.67it/s, v_num=304, train_loss=0.0359]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  11%|█▏        | 25/220 [00:02<00:22,  8.86it/s, v_num=304, train_loss=0.0412]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  12%|█▏        | 26/220 [00:02<00:21,  9.04it/s, v_num=304, train_loss=0.0463]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  12%|█▏        | 27/220 [00:02<00:20,  9.21it/s, v_num=304, train_loss=0.0492]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  13%|█▎        | 28/220 [00:02<00:20,  9.35it/s, v_num=304, train_loss=0.0414]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  13%|█▎        | 29/220 [00:03<00:20,  9.51it/s, v_num=304, train_loss=0.0506]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  14%|█▎        | 30/220 [00:03<00:19,  9.66it/s, v_num=304, train_loss=0.0355]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  14%|█▍        | 31/220 [00:03<00:19,  9.80it/s, v_num=304, train_loss=0.0479]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  15%|█▍        | 32/220 [00:03<00:18,  9.95it/s, v_num=304, train_loss=0.0435]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  15%|█▌        | 33/220 [00:03<00:18, 10.09it/s, v_num=304, train_loss=0.0459]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  15%|█▌        | 34/220 [00:03<00:18, 10.22it/s, v_num=304, train_loss=0.0551]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  16%|█▌        | 35/220 [00:03<00:17, 10.35it/s, v_num=304, train_loss=0.0498]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  16%|█▋        | 36/220 [00:03<00:17, 10.45it/s, v_num=304, train_loss=0.0439]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  17%|█▋        | 37/220 [00:03<00:17, 10.57it/s, v_num=304, train_loss=0.0414]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  17%|█▋        | 38/220 [00:03<00:17, 10.69it/s, v_num=304, train_loss=0.0579]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  18%|█▊        | 39/220 [00:03<00:16, 10.80it/s, v_num=304, train_loss=0.0461]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  18%|█▊        | 40/220 [00:03<00:16, 10.91it/s, v_num=304, train_loss=0.0478]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  19%|█▊        | 41/220 [00:03<00:16, 11.02it/s, v_num=304, train_loss=0.0388]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  19%|█▉        | 42/220 [00:03<00:16, 11.12it/s, v_num=304, train_loss=0.0472]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  20%|█▉        | 43/220 [00:03<00:15, 11.22it/s, v_num=304, train_loss=0.0392]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  20%|██        | 44/220 [00:03<00:15, 11.29it/s, v_num=304, train_loss=0.0448]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  20%|██        | 45/220 [00:03<00:15, 11.39it/s, v_num=304, train_loss=0.0431]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  21%|██        | 46/220 [00:04<00:15, 11.48it/s, v_num=304, train_loss=0.0387]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  21%|██▏       | 47/220 [00:04<00:14, 11.57it/s, v_num=304, train_loss=0.0504]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  22%|██▏       | 48/220 [00:04<00:14, 11.66it/s, v_num=304, train_loss=0.0509]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  22%|██▏       | 49/220 [00:04<00:14, 11.75it/s, v_num=304, train_loss=0.0481]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  23%|██▎       | 50/220 [00:04<00:14, 11.84it/s, v_num=304, train_loss=0.0396]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  23%|██▎       | 51/220 [00:04<00:14, 11.92it/s, v_num=304, train_loss=0.0388]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  24%|██▎       | 52/220 [00:04<00:14, 11.97it/s, v_num=304, train_loss=0.0469]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  24%|██▍       | 53/220 [00:04<00:13, 12.05it/s, v_num=304, train_loss=0.046] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  25%|██▍       | 54/220 [00:04<00:13, 12.12it/s, v_num=304, train_loss=0.0409]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  25%|██▌       | 55/220 [00:04<00:13, 12.19it/s, v_num=304, train_loss=0.0492]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  25%|██▌       | 56/220 [00:04<00:13, 12.26it/s, v_num=304, train_loss=0.0389]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  26%|██▌       | 57/220 [00:04<00:13, 12.34it/s, v_num=304, train_loss=0.0514]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  26%|██▋       | 58/220 [00:04<00:13, 12.41it/s, v_num=304, train_loss=0.0388]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  27%|██▋       | 59/220 [00:04<00:12, 12.47it/s, v_num=304, train_loss=0.0392]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  27%|██▋       | 60/220 [00:04<00:12, 12.51it/s, v_num=304, train_loss=0.0494]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  28%|██▊       | 61/220 [00:04<00:12, 12.55it/s, v_num=304, train_loss=0.0382]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  28%|██▊       | 62/220 [00:04<00:12, 12.61it/s, v_num=304, train_loss=0.056] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  29%|██▊       | 63/220 [00:04<00:12, 12.67it/s, v_num=304, train_loss=0.0411]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  29%|██▉       | 64/220 [00:05<00:12, 12.73it/s, v_num=304, train_loss=0.0468]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  30%|██▉       | 65/220 [00:05<00:12, 12.79it/s, v_num=304, train_loss=0.0375]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  30%|███       | 66/220 [00:05<00:11, 12.85it/s, v_num=304, train_loss=0.0392]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  30%|███       | 67/220 [00:05<00:11, 12.91it/s, v_num=304, train_loss=0.039] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  31%|███       | 68/220 [00:05<00:11, 12.94it/s, v_num=304, train_loss=0.0467]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  31%|███▏      | 69/220 [00:05<00:11, 12.97it/s, v_num=304, train_loss=0.0353]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  32%|███▏      | 70/220 [00:05<00:11, 13.02it/s, v_num=304, train_loss=0.034] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  32%|███▏      | 71/220 [00:05<00:11, 13.07it/s, v_num=304, train_loss=0.0481]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  33%|███▎      | 72/220 [00:05<00:11, 13.12it/s, v_num=304, train_loss=0.0491]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  33%|███▎      | 73/220 [00:05<00:11, 13.18it/s, v_num=304, train_loss=0.0458]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  34%|███▎      | 74/220 [00:05<00:11, 13.23it/s, v_num=304, train_loss=0.0426]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  34%|███▍      | 75/220 [00:05<00:10, 13.28it/s, v_num=304, train_loss=0.060] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  35%|███▍      | 76/220 [00:05<00:10, 13.30it/s, v_num=304, train_loss=0.0482]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  35%|███▌      | 77/220 [00:05<00:10, 13.32it/s, v_num=304, train_loss=0.0448]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  35%|███▌      | 78/220 [00:05<00:10, 13.37it/s, v_num=304, train_loss=0.053] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  36%|███▌      | 79/220 [00:05<00:10, 13.41it/s, v_num=304, train_loss=0.0377]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  36%|███▋      | 80/220 [00:05<00:10, 13.46it/s, v_num=304, train_loss=0.0385]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  37%|███▋      | 81/220 [00:06<00:10, 13.50it/s, v_num=304, train_loss=0.0459]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  37%|███▋      | 82/220 [00:06<00:10, 13.54it/s, v_num=304, train_loss=0.0554]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  38%|███▊      | 83/220 [00:06<00:10, 13.58it/s, v_num=304, train_loss=0.0441]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  38%|███▊      | 84/220 [00:06<00:09, 13.61it/s, v_num=304, train_loss=0.0412]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  39%|███▊      | 85/220 [00:06<00:09, 13.62it/s, v_num=304, train_loss=0.0404]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  39%|███▉      | 86/220 [00:06<00:09, 13.66it/s, v_num=304, train_loss=0.0463]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  40%|███▉      | 87/220 [00:06<00:09, 13.70it/s, v_num=304, train_loss=0.0389]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  40%|████      | 88/220 [00:06<00:09, 13.74it/s, v_num=304, train_loss=0.0482]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  40%|████      | 89/220 [00:06<00:09, 13.78it/s, v_num=304, train_loss=0.0466]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  41%|████      | 90/220 [00:06<00:09, 13.82it/s, v_num=304, train_loss=0.0483]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  41%|████▏     | 91/220 [00:06<00:09, 13.85it/s, v_num=304, train_loss=0.0506]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  42%|████▏     | 92/220 [00:06<00:09, 13.87it/s, v_num=304, train_loss=0.0372]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  42%|████▏     | 93/220 [00:06<00:09, 13.88it/s, v_num=304, train_loss=0.0397]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  43%|████▎     | 94/220 [00:06<00:09, 13.92it/s, v_num=304, train_loss=0.0477]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  43%|████▎     | 95/220 [00:06<00:08, 13.96it/s, v_num=304, train_loss=0.0444]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  44%|████▎     | 96/220 [00:06<00:08, 13.99it/s, v_num=304, train_loss=0.0392]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  44%|████▍     | 97/220 [00:06<00:08, 14.02it/s, v_num=304, train_loss=0.0534]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  45%|████▍     | 98/220 [00:06<00:08, 14.06it/s, v_num=304, train_loss=0.0347]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  45%|████▌     | 99/220 [00:07<00:08, 14.09it/s, v_num=304, train_loss=0.0435]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  45%|████▌     | 100/220 [00:07<00:08, 14.10it/s, v_num=304, train_loss=0.0538]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  46%|████▌     | 101/220 [00:07<00:08, 14.11it/s, v_num=304, train_loss=0.0489]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  46%|████▋     | 102/220 [00:07<00:08, 14.14it/s, v_num=304, train_loss=0.0412]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  47%|████▋     | 103/220 [00:07<00:08, 14.17it/s, v_num=304, train_loss=0.0397]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  47%|████▋     | 104/220 [00:07<00:08, 14.20it/s, v_num=304, train_loss=0.0444]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  48%|████▊     | 105/220 [00:07<00:08, 14.23it/s, v_num=304, train_loss=0.0431]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  48%|████▊     | 106/220 [00:07<00:07, 14.26it/s, v_num=304, train_loss=0.0441]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  49%|████▊     | 107/220 [00:07<00:07, 14.29it/s, v_num=304, train_loss=0.043] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  49%|████▉     | 108/220 [00:07<00:07, 14.30it/s, v_num=304, train_loss=0.0382]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  50%|████▉     | 109/220 [00:07<00:07, 14.31it/s, v_num=304, train_loss=0.0452]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  50%|█████     | 110/220 [00:07<00:07, 14.34it/s, v_num=304, train_loss=0.0376]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  50%|█████     | 111/220 [00:07<00:07, 14.37it/s, v_num=304, train_loss=0.0342]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  51%|█████     | 112/220 [00:07<00:07, 14.39it/s, v_num=304, train_loss=0.0449]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  51%|█████▏    | 113/220 [00:07<00:07, 14.42it/s, v_num=304, train_loss=0.0409]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  52%|█████▏    | 114/220 [00:07<00:07, 14.45it/s, v_num=304, train_loss=0.0357]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  52%|█████▏    | 115/220 [00:07<00:07, 14.47it/s, v_num=304, train_loss=0.0355]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  53%|█████▎    | 116/220 [00:08<00:07, 14.48it/s, v_num=304, train_loss=0.0459]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  53%|█████▎    | 117/220 [00:08<00:07, 14.49it/s, v_num=304, train_loss=0.0437]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  54%|█████▎    | 118/220 [00:08<00:07, 14.52it/s, v_num=304, train_loss=0.0437]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  54%|█████▍    | 119/220 [00:08<00:06, 14.54it/s, v_num=304, train_loss=0.0449]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  55%|█████▍    | 120/220 [00:08<00:06, 14.56it/s, v_num=304, train_loss=0.0428]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  55%|█████▌    | 121/220 [00:08<00:06, 14.59it/s, v_num=304, train_loss=0.0453]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  55%|█████▌    | 122/220 [00:08<00:06, 14.62it/s, v_num=304, train_loss=0.0367]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  56%|█████▌    | 123/220 [00:08<00:06, 14.64it/s, v_num=304, train_loss=0.0366]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  56%|█████▋    | 124/220 [00:08<00:06, 14.64it/s, v_num=304, train_loss=0.0337]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  57%|█████▋    | 125/220 [00:08<00:06, 14.65it/s, v_num=304, train_loss=0.0406]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  57%|█████▋    | 126/220 [00:08<00:06, 14.67it/s, v_num=304, train_loss=0.0322]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  58%|█████▊    | 127/220 [00:08<00:06, 14.69it/s, v_num=304, train_loss=0.0356]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  58%|█████▊    | 128/220 [00:08<00:06, 14.71it/s, v_num=304, train_loss=0.0456]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  59%|█████▊    | 129/220 [00:08<00:06, 14.73it/s, v_num=304, train_loss=0.0385]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  59%|█████▉    | 130/220 [00:08<00:06, 14.76it/s, v_num=304, train_loss=0.0433]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  60%|█████▉    | 131/220 [00:08<00:06, 14.78it/s, v_num=304, train_loss=0.0391]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  60%|██████    | 132/220 [00:08<00:05, 14.78it/s, v_num=304, train_loss=0.0434]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  60%|██████    | 133/220 [00:08<00:05, 14.79it/s, v_num=304, train_loss=0.0405]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  61%|██████    | 134/220 [00:09<00:05, 14.81it/s, v_num=304, train_loss=0.047] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  61%|██████▏   | 135/220 [00:09<00:05, 14.83it/s, v_num=304, train_loss=0.0489]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  62%|██████▏   | 136/220 [00:09<00:05, 14.85it/s, v_num=304, train_loss=0.0444]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  62%|██████▏   | 137/220 [00:09<00:05, 14.87it/s, v_num=304, train_loss=0.0442]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  63%|██████▎   | 138/220 [00:09<00:05, 14.89it/s, v_num=304, train_loss=0.0411]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  63%|██████▎   | 139/220 [00:09<00:05, 14.91it/s, v_num=304, train_loss=0.0461]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  64%|██████▎   | 140/220 [00:09<00:05, 14.91it/s, v_num=304, train_loss=0.0389]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  64%|██████▍   | 141/220 [00:09<00:05, 14.91it/s, v_num=304, train_loss=0.043] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  65%|██████▍   | 142/220 [00:09<00:05, 14.93it/s, v_num=304, train_loss=0.0464]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  65%|██████▌   | 143/220 [00:09<00:05, 14.95it/s, v_num=304, train_loss=0.0505]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  65%|██████▌   | 144/220 [00:09<00:05, 14.97it/s, v_num=304, train_loss=0.040] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  66%|██████▌   | 145/220 [00:09<00:05, 14.99it/s, v_num=304, train_loss=0.038]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  66%|██████▋   | 146/220 [00:09<00:04, 15.00it/s, v_num=304, train_loss=0.0448]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  67%|██████▋   | 147/220 [00:09<00:04, 15.02it/s, v_num=304, train_loss=0.0375]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  67%|██████▋   | 148/220 [00:09<00:04, 15.03it/s, v_num=304, train_loss=0.0398]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  68%|██████▊   | 149/220 [00:09<00:04, 15.03it/s, v_num=304, train_loss=0.0441]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  68%|██████▊   | 150/220 [00:09<00:04, 15.05it/s, v_num=304, train_loss=0.0399]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  69%|██████▊   | 151/220 [00:10<00:04, 15.06it/s, v_num=304, train_loss=0.0379]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  69%|██████▉   | 152/220 [00:10<00:04, 15.08it/s, v_num=304, train_loss=0.0392]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  70%|██████▉   | 153/220 [00:10<00:04, 15.10it/s, v_num=304, train_loss=0.0447]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  70%|███████   | 154/220 [00:10<00:04, 15.11it/s, v_num=304, train_loss=0.0476]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  70%|███████   | 155/220 [00:10<00:04, 15.13it/s, v_num=304, train_loss=0.0397]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  71%|███████   | 156/220 [00:10<00:04, 15.13it/s, v_num=304, train_loss=0.0401]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  71%|███████▏  | 157/220 [00:10<00:04, 15.13it/s, v_num=304, train_loss=0.0504]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  72%|███████▏  | 158/220 [00:10<00:04, 15.15it/s, v_num=304, train_loss=0.0329]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  72%|███████▏  | 159/220 [00:10<00:04, 15.17it/s, v_num=304, train_loss=0.0443]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  73%|███████▎  | 160/220 [00:10<00:03, 15.18it/s, v_num=304, train_loss=0.046] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  73%|███████▎  | 161/220 [00:10<00:03, 15.20it/s, v_num=304, train_loss=0.0384]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  74%|███████▎  | 162/220 [00:10<00:03, 15.21it/s, v_num=304, train_loss=0.0369]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  74%|███████▍  | 163/220 [00:10<00:03, 15.23it/s, v_num=304, train_loss=0.0424]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  75%|███████▍  | 164/220 [00:10<00:03, 15.23it/s, v_num=304, train_loss=0.046] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  75%|███████▌  | 165/220 [00:10<00:03, 15.23it/s, v_num=304, train_loss=0.0361]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  75%|███████▌  | 166/220 [00:10<00:03, 15.25it/s, v_num=304, train_loss=0.0462]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  76%|███████▌  | 167/220 [00:10<00:03, 15.26it/s, v_num=304, train_loss=0.042] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  76%|███████▋  | 168/220 [00:10<00:03, 15.28it/s, v_num=304, train_loss=0.0424]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  77%|███████▋  | 169/220 [00:11<00:03, 15.29it/s, v_num=304, train_loss=0.0495]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  77%|███████▋  | 170/220 [00:11<00:03, 15.31it/s, v_num=304, train_loss=0.0468]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  78%|███████▊  | 171/220 [00:11<00:03, 15.32it/s, v_num=304, train_loss=0.0436]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  78%|███████▊  | 172/220 [00:11<00:03, 15.32it/s, v_num=304, train_loss=0.0464]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  79%|███████▊  | 173/220 [00:11<00:03, 15.32it/s, v_num=304, train_loss=0.0401]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  79%|███████▉  | 174/220 [00:11<00:02, 15.34it/s, v_num=304, train_loss=0.0454]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  80%|███████▉  | 175/220 [00:11<00:02, 15.35it/s, v_num=304, train_loss=0.0342]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  80%|████████  | 176/220 [00:11<00:02, 15.36it/s, v_num=304, train_loss=0.0472]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  80%|████████  | 177/220 [00:11<00:02, 15.38it/s, v_num=304, train_loss=0.0505]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  81%|████████  | 178/220 [00:11<00:02, 15.39it/s, v_num=304, train_loss=0.0436]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  81%|████████▏ | 179/220 [00:11<00:02, 15.40it/s, v_num=304, train_loss=0.0411]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  82%|████████▏ | 180/220 [00:11<00:02, 15.42it/s, v_num=304, train_loss=0.0394]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  82%|████████▏ | 181/220 [00:11<00:02, 15.41it/s, v_num=304, train_loss=0.0449]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  83%|████████▎ | 182/220 [00:11<00:02, 15.43it/s, v_num=304, train_loss=0.0442]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  83%|████████▎ | 183/220 [00:11<00:02, 15.44it/s, v_num=304, train_loss=0.0479]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  84%|████████▎ | 184/220 [00:11<00:02, 15.45it/s, v_num=304, train_loss=0.0444]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  84%|████████▍ | 185/220 [00:11<00:02, 15.46it/s, v_num=304, train_loss=0.0533]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  85%|████████▍ | 186/220 [00:12<00:02, 15.48it/s, v_num=304, train_loss=0.0407]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  85%|████████▌ | 187/220 [00:12<00:02, 15.49it/s, v_num=304, train_loss=0.0418]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  85%|████████▌ | 188/220 [00:12<00:02, 15.50it/s, v_num=304, train_loss=0.0531]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  86%|████████▌ | 189/220 [00:12<00:02, 15.50it/s, v_num=304, train_loss=0.0438]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  86%|████████▋ | 190/220 [00:12<00:01, 15.51it/s, v_num=304, train_loss=0.0427]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  87%|████████▋ | 191/220 [00:12<00:01, 15.52it/s, v_num=304, train_loss=0.0459]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  87%|████████▋ | 192/220 [00:12<00:01, 15.53it/s, v_num=304, train_loss=0.0395]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  88%|████████▊ | 193/220 [00:12<00:01, 15.54it/s, v_num=304, train_loss=0.0416]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  88%|████████▊ | 194/220 [00:12<00:01, 15.55it/s, v_num=304, train_loss=0.040] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  89%|████████▊ | 195/220 [00:12<00:01, 15.57it/s, v_num=304, train_loss=0.0468]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  89%|████████▉ | 196/220 [00:12<00:01, 15.57it/s, v_num=304, train_loss=0.0366]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  90%|████████▉ | 197/220 [00:12<00:01, 15.58it/s, v_num=304, train_loss=0.0358]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  90%|█████████ | 198/220 [00:12<00:01, 15.59it/s, v_num=304, train_loss=0.044] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  90%|█████████ | 199/220 [00:12<00:01, 15.60it/s, v_num=304, train_loss=0.0343]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  91%|█████████ | 200/220 [00:12<00:01, 15.61it/s, v_num=304, train_loss=0.0511]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  91%|█████████▏| 201/220 [00:12<00:01, 15.62it/s, v_num=304, train_loss=0.0406]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  92%|█████████▏| 202/220 [00:12<00:01, 15.63it/s, v_num=304, train_loss=0.037] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  92%|█████████▏| 203/220 [00:12<00:01, 15.64it/s, v_num=304, train_loss=0.0478]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  93%|█████████▎| 204/220 [00:13<00:01, 15.65it/s, v_num=304, train_loss=0.0409]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  93%|█████████▎| 205/220 [00:13<00:00, 15.66it/s, v_num=304, train_loss=0.0405]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  94%|█████████▎| 206/220 [00:13<00:00, 15.67it/s, v_num=304, train_loss=0.0515]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  94%|█████████▍| 207/220 [00:13<00:00, 15.69it/s, v_num=304, train_loss=0.0321]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  95%|█████████▍| 208/220 [00:13<00:00, 15.70it/s, v_num=304, train_loss=0.0387]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  95%|█████████▌| 209/220 [00:13<00:00, 15.72it/s, v_num=304, train_loss=0.047] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  95%|█████████▌| 210/220 [00:13<00:00, 15.73it/s, v_num=304, train_loss=0.0413]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  96%|█████████▌| 211/220 [00:13<00:00, 15.75it/s, v_num=304, train_loss=0.0455]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  96%|█████████▋| 212/220 [00:13<00:00, 15.76it/s, v_num=304, train_loss=0.0449]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  97%|█████████▋| 213/220 [00:13<00:00, 15.78it/s, v_num=304, train_loss=0.0334]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  97%|█████████▋| 214/220 [00:13<00:00, 15.79it/s, v_num=304, train_loss=0.0412]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  98%|█████████▊| 215/220 [00:13<00:00, 15.81it/s, v_num=304, train_loss=0.0511]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  98%|█████████▊| 216/220 [00:13<00:00, 15.82it/s, v_num=304, train_loss=0.0461]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  99%|█████████▊| 217/220 [00:13<00:00, 15.83it/s, v_num=304, train_loss=0.0389]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1:  99%|█████████▉| 218/220 [00:13<00:00, 15.85it/s, v_num=304, train_loss=0.0368]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 1: 100%|█████████▉| 219/220 [00:13<00:00, 15.86it/s, v_num=304, train_loss=0.0507]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:   0%|          | 0/220 [00:00<?, ?it/s, v_num=304, train_loss=0.0447]          196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:   0%|          | 1/220 [00:01<05:22,  0.68it/s, v_num=304, train_loss=0.0387]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:   1%|          | 2/220 [00:01<02:46,  1.31it/s, v_num=304, train_loss=0.0427]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:   1%|▏         | 3/220 [00:01<01:54,  1.90it/s, v_num=304, train_loss=0.0374]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:   2%|▏         | 4/220 [00:01<01:27,  2.45it/s, v_num=304, train_loss=0.0411]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:   2%|▏         | 5/220 [00:01<01:12,  2.97it/s, v_num=304, train_loss=0.0458]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:   3%|▎         | 6/220 [00:01<01:02,  3.45it/s, v_num=304, train_loss=0.0356]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:   3%|▎         | 7/220 [00:01<00:54,  3.90it/s, v_num=304, train_loss=0.0405]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:   4%|▎         | 8/220 [00:01<00:48,  4.33it/s, v_num=304, train_loss=0.0502]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:   4%|▍         | 9/220 [00:01<00:44,  4.73it/s, v_num=304, train_loss=0.0497]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:   5%|▍         | 10/220 [00:01<00:41,  5.11it/s, v_num=304, train_loss=0.0435]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:   5%|▌         | 11/220 [00:02<00:38,  5.47it/s, v_num=304, train_loss=0.0466]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:   5%|▌         | 12/220 [00:02<00:35,  5.81it/s, v_num=304, train_loss=0.0556]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:   6%|▌         | 13/220 [00:02<00:33,  6.13it/s, v_num=304, train_loss=0.0395]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:   6%|▋         | 14/220 [00:02<00:32,  6.43it/s, v_num=304, train_loss=0.0395]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:   7%|▋         | 15/220 [00:02<00:30,  6.72it/s, v_num=304, train_loss=0.0419]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:   7%|▋         | 16/220 [00:02<00:29,  7.00it/s, v_num=304, train_loss=0.0414]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:   8%|▊         | 17/220 [00:02<00:27,  7.27it/s, v_num=304, train_loss=0.0461]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:   8%|▊         | 18/220 [00:02<00:26,  7.52it/s, v_num=304, train_loss=0.0499]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:   9%|▊         | 19/220 [00:02<00:25,  7.77it/s, v_num=304, train_loss=0.0491]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:   9%|▉         | 20/220 [00:02<00:24,  8.00it/s, v_num=304, train_loss=0.063] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  10%|▉         | 21/220 [00:02<00:24,  8.23it/s, v_num=304, train_loss=0.0587]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  10%|█         | 22/220 [00:02<00:23,  8.45it/s, v_num=304, train_loss=0.044] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  10%|█         | 23/220 [00:02<00:22,  8.65it/s, v_num=304, train_loss=0.0474]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  11%|█         | 24/220 [00:02<00:22,  8.85it/s, v_num=304, train_loss=0.0552]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  11%|█▏        | 25/220 [00:02<00:21,  9.04it/s, v_num=304, train_loss=0.047] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  12%|█▏        | 26/220 [00:02<00:21,  9.23it/s, v_num=304, train_loss=0.037]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  12%|█▏        | 27/220 [00:02<00:20,  9.41it/s, v_num=304, train_loss=0.0467]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  13%|█▎        | 28/220 [00:02<00:20,  9.59it/s, v_num=304, train_loss=0.0503]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  13%|█▎        | 29/220 [00:02<00:19,  9.76it/s, v_num=304, train_loss=0.040] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  14%|█▎        | 30/220 [00:03<00:19,  9.93it/s, v_num=304, train_loss=0.0496]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  14%|█▍        | 31/220 [00:03<00:18, 10.08it/s, v_num=304, train_loss=0.0488]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  15%|█▍        | 32/220 [00:03<00:18, 10.23it/s, v_num=304, train_loss=0.0393]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  15%|█▌        | 33/220 [00:03<00:18, 10.37it/s, v_num=304, train_loss=0.0379]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  15%|█▌        | 34/220 [00:03<00:17, 10.51it/s, v_num=304, train_loss=0.0369]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  16%|█▌        | 35/220 [00:03<00:17, 10.65it/s, v_num=304, train_loss=0.041] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  16%|█▋        | 36/220 [00:03<00:17, 10.79it/s, v_num=304, train_loss=0.0343]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  17%|█▋        | 37/220 [00:03<00:16, 10.92it/s, v_num=304, train_loss=0.0441]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  17%|█▋        | 38/220 [00:03<00:16, 11.05it/s, v_num=304, train_loss=0.0379]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  18%|█▊        | 39/220 [00:03<00:16, 11.17it/s, v_num=304, train_loss=0.0357]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  18%|█▊        | 40/220 [00:03<00:15, 11.27it/s, v_num=304, train_loss=0.0401]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  19%|█▊        | 41/220 [00:03<00:15, 11.37it/s, v_num=304, train_loss=0.0388]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  19%|█▉        | 42/220 [00:03<00:15, 11.47it/s, v_num=304, train_loss=0.0344]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  20%|█▉        | 43/220 [00:03<00:15, 11.57it/s, v_num=304, train_loss=0.0493]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  20%|██        | 44/220 [00:03<00:15, 11.67it/s, v_num=304, train_loss=0.038] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  20%|██        | 45/220 [00:03<00:14, 11.77it/s, v_num=304, train_loss=0.0462]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  21%|██        | 46/220 [00:03<00:14, 11.87it/s, v_num=304, train_loss=0.0376]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  21%|██▏       | 47/220 [00:03<00:14, 11.96it/s, v_num=304, train_loss=0.0395]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  22%|██▏       | 48/220 [00:03<00:14, 12.05it/s, v_num=304, train_loss=0.0373]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  22%|██▏       | 49/220 [00:04<00:14, 12.13it/s, v_num=304, train_loss=0.0401]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  23%|██▎       | 50/220 [00:04<00:13, 12.21it/s, v_num=304, train_loss=0.041] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  23%|██▎       | 51/220 [00:04<00:13, 12.28it/s, v_num=304, train_loss=0.0324]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  24%|██▎       | 52/220 [00:04<00:13, 12.36it/s, v_num=304, train_loss=0.0466]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  24%|██▍       | 53/220 [00:04<00:13, 12.44it/s, v_num=304, train_loss=0.0346]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  25%|██▍       | 54/220 [00:04<00:13, 12.52it/s, v_num=304, train_loss=0.0377]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  25%|██▌       | 55/220 [00:04<00:13, 12.59it/s, v_num=304, train_loss=0.0483]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  25%|██▌       | 56/220 [00:04<00:12, 12.67it/s, v_num=304, train_loss=0.0374]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  26%|██▌       | 57/220 [00:04<00:12, 12.73it/s, v_num=304, train_loss=0.050] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  26%|██▋       | 58/220 [00:04<00:12, 12.80it/s, v_num=304, train_loss=0.0357]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  27%|██▋       | 59/220 [00:04<00:12, 12.86it/s, v_num=304, train_loss=0.0384]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  27%|██▋       | 60/220 [00:04<00:12, 12.92it/s, v_num=304, train_loss=0.0458]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  28%|██▊       | 61/220 [00:04<00:12, 12.99it/s, v_num=304, train_loss=0.0362]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  28%|██▊       | 62/220 [00:04<00:12, 13.05it/s, v_num=304, train_loss=0.0472]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  29%|██▊       | 63/220 [00:04<00:11, 13.11it/s, v_num=304, train_loss=0.0311]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  29%|██▉       | 64/220 [00:04<00:11, 13.17it/s, v_num=304, train_loss=0.0513]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  30%|██▉       | 65/220 [00:04<00:11, 13.23it/s, v_num=304, train_loss=0.0396]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  30%|███       | 66/220 [00:04<00:11, 13.28it/s, v_num=304, train_loss=0.0414]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  30%|███       | 67/220 [00:05<00:11, 13.33it/s, v_num=304, train_loss=0.0373]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  31%|███       | 68/220 [00:05<00:11, 13.39it/s, v_num=304, train_loss=0.0366]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  31%|███▏      | 69/220 [00:05<00:11, 13.45it/s, v_num=304, train_loss=0.0411]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  32%|███▏      | 70/220 [00:05<00:11, 13.50it/s, v_num=304, train_loss=0.0375]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  32%|███▏      | 71/220 [00:05<00:10, 13.55it/s, v_num=304, train_loss=0.0353]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  33%|███▎      | 72/220 [00:05<00:10, 13.61it/s, v_num=304, train_loss=0.0391]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  33%|███▎      | 73/220 [00:05<00:10, 13.66it/s, v_num=304, train_loss=0.0421]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  34%|███▎      | 74/220 [00:05<00:10, 13.70it/s, v_num=304, train_loss=0.037] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  34%|███▍      | 75/220 [00:05<00:10, 13.75it/s, v_num=304, train_loss=0.050]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  35%|███▍      | 76/220 [00:05<00:10, 13.81it/s, v_num=304, train_loss=0.0397]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  35%|███▌      | 77/220 [00:05<00:10, 13.86it/s, v_num=304, train_loss=0.0424]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  35%|███▌      | 78/220 [00:05<00:10, 13.91it/s, v_num=304, train_loss=0.0368]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  36%|███▌      | 79/220 [00:05<00:10, 13.96it/s, v_num=304, train_loss=0.0323]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  36%|███▋      | 80/220 [00:05<00:09, 14.01it/s, v_num=304, train_loss=0.0368]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  37%|███▋      | 81/220 [00:05<00:09, 14.05it/s, v_num=304, train_loss=0.0311]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  37%|███▋      | 82/220 [00:05<00:09, 14.09it/s, v_num=304, train_loss=0.0322]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  38%|███▊      | 83/220 [00:05<00:09, 14.13it/s, v_num=304, train_loss=0.0455]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  38%|███▊      | 84/220 [00:05<00:09, 14.18it/s, v_num=304, train_loss=0.044] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  39%|███▊      | 85/220 [00:05<00:09, 14.22it/s, v_num=304, train_loss=0.055]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  39%|███▉      | 86/220 [00:06<00:09, 14.26it/s, v_num=304, train_loss=0.0521]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  40%|███▉      | 87/220 [00:06<00:09, 14.29it/s, v_num=304, train_loss=0.0443]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  40%|████      | 88/220 [00:06<00:09, 14.32it/s, v_num=304, train_loss=0.0394]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  40%|████      | 89/220 [00:06<00:09, 14.35it/s, v_num=304, train_loss=0.0437]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  41%|████      | 90/220 [00:06<00:09, 14.38it/s, v_num=304, train_loss=0.0336]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  41%|████▏     | 91/220 [00:06<00:08, 14.42it/s, v_num=304, train_loss=0.0454]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  42%|████▏     | 92/220 [00:06<00:08, 14.45it/s, v_num=304, train_loss=0.0453]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  42%|████▏     | 93/220 [00:06<00:08, 14.49it/s, v_num=304, train_loss=0.0353]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  43%|████▎     | 94/220 [00:06<00:08, 14.52it/s, v_num=304, train_loss=0.0359]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  43%|████▎     | 95/220 [00:06<00:08, 14.55it/s, v_num=304, train_loss=0.039] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  44%|████▎     | 96/220 [00:06<00:08, 14.58it/s, v_num=304, train_loss=0.034]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  44%|████▍     | 97/220 [00:06<00:08, 14.61it/s, v_num=304, train_loss=0.0439]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  45%|████▍     | 98/220 [00:06<00:08, 14.64it/s, v_num=304, train_loss=0.0337]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  45%|████▌     | 99/220 [00:06<00:08, 14.67it/s, v_num=304, train_loss=0.0334]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  45%|████▌     | 100/220 [00:06<00:08, 14.70it/s, v_num=304, train_loss=0.0363]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  46%|████▌     | 101/220 [00:06<00:08, 14.73it/s, v_num=304, train_loss=0.0431]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  46%|████▋     | 102/220 [00:06<00:07, 14.76it/s, v_num=304, train_loss=0.041] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  47%|████▋     | 103/220 [00:06<00:07, 14.79it/s, v_num=304, train_loss=0.0386]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  47%|████▋     | 104/220 [00:07<00:07, 14.81it/s, v_num=304, train_loss=0.0366]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  48%|████▊     | 105/220 [00:07<00:07, 14.83it/s, v_num=304, train_loss=0.0365]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  48%|████▊     | 106/220 [00:07<00:07, 14.86it/s, v_num=304, train_loss=0.0494]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  49%|████▊     | 107/220 [00:07<00:07, 14.89it/s, v_num=304, train_loss=0.0393]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  49%|████▉     | 108/220 [00:07<00:07, 14.91it/s, v_num=304, train_loss=0.0343]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  50%|████▉     | 109/220 [00:07<00:07, 14.94it/s, v_num=304, train_loss=0.0406]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  50%|█████     | 110/220 [00:07<00:07, 14.97it/s, v_num=304, train_loss=0.0346]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  50%|█████     | 111/220 [00:07<00:07, 14.99it/s, v_num=304, train_loss=0.034] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  51%|█████     | 112/220 [00:07<00:07, 15.01it/s, v_num=304, train_loss=0.0395]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  51%|█████▏    | 113/220 [00:07<00:07, 15.03it/s, v_num=304, train_loss=0.0478]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  52%|█████▏    | 114/220 [00:07<00:07, 15.06it/s, v_num=304, train_loss=0.0512]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  52%|█████▏    | 115/220 [00:07<00:06, 15.08it/s, v_num=304, train_loss=0.0347]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  53%|█████▎    | 116/220 [00:07<00:06, 15.10it/s, v_num=304, train_loss=0.0361]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  53%|█████▎    | 117/220 [00:07<00:06, 15.13it/s, v_num=304, train_loss=0.043] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  54%|█████▎    | 118/220 [00:07<00:06, 15.15it/s, v_num=304, train_loss=0.0328]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  54%|█████▍    | 119/220 [00:07<00:06, 15.18it/s, v_num=304, train_loss=0.0358]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  55%|█████▍    | 120/220 [00:07<00:06, 15.19it/s, v_num=304, train_loss=0.0332]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  55%|█████▌    | 121/220 [00:07<00:06, 15.21it/s, v_num=304, train_loss=0.0438]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  55%|█████▌    | 122/220 [00:08<00:06, 15.23it/s, v_num=304, train_loss=0.0458]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  56%|█████▌    | 123/220 [00:08<00:06, 15.26it/s, v_num=304, train_loss=0.047] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  56%|█████▋    | 124/220 [00:08<00:06, 15.28it/s, v_num=304, train_loss=0.0422]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  57%|█████▋    | 125/220 [00:08<00:06, 15.30it/s, v_num=304, train_loss=0.0447]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  57%|█████▋    | 126/220 [00:08<00:06, 15.32it/s, v_num=304, train_loss=0.0393]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  58%|█████▊    | 127/220 [00:08<00:06, 15.34it/s, v_num=304, train_loss=0.0511]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  58%|█████▊    | 128/220 [00:08<00:05, 15.36it/s, v_num=304, train_loss=0.0364]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  59%|█████▊    | 129/220 [00:08<00:05, 15.37it/s, v_num=304, train_loss=0.0336]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  59%|█████▉    | 130/220 [00:08<00:05, 15.39it/s, v_num=304, train_loss=0.0347]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  60%|█████▉    | 131/220 [00:08<00:05, 15.41it/s, v_num=304, train_loss=0.0367]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  60%|██████    | 132/220 [00:08<00:05, 15.43it/s, v_num=304, train_loss=0.0386]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  60%|██████    | 133/220 [00:08<00:05, 15.45it/s, v_num=304, train_loss=0.0395]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  61%|██████    | 134/220 [00:08<00:05, 15.47it/s, v_num=304, train_loss=0.0381]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  61%|██████▏   | 135/220 [00:08<00:05, 15.48it/s, v_num=304, train_loss=0.0333]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  62%|██████▏   | 136/220 [00:08<00:05, 15.50it/s, v_num=304, train_loss=0.0492]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  62%|██████▏   | 137/220 [00:08<00:05, 15.51it/s, v_num=304, train_loss=0.0487]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  63%|██████▎   | 138/220 [00:08<00:05, 15.53it/s, v_num=304, train_loss=0.0376]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  63%|██████▎   | 139/220 [00:08<00:05, 15.55it/s, v_num=304, train_loss=0.035] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  64%|██████▎   | 140/220 [00:08<00:05, 15.57it/s, v_num=304, train_loss=0.0523]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  64%|██████▍   | 141/220 [00:09<00:05, 15.59it/s, v_num=304, train_loss=0.0415]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  65%|██████▍   | 142/220 [00:09<00:04, 15.60it/s, v_num=304, train_loss=0.0406]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  65%|██████▌   | 143/220 [00:09<00:04, 15.62it/s, v_num=304, train_loss=0.0471]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  65%|██████▌   | 144/220 [00:09<00:04, 15.63it/s, v_num=304, train_loss=0.0417]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  66%|██████▌   | 145/220 [00:09<00:04, 15.65it/s, v_num=304, train_loss=0.0355]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  66%|██████▋   | 146/220 [00:09<00:04, 15.66it/s, v_num=304, train_loss=0.0361]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  67%|██████▋   | 147/220 [00:09<00:04, 15.68it/s, v_num=304, train_loss=0.0373]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  67%|██████▋   | 148/220 [00:09<00:04, 15.70it/s, v_num=304, train_loss=0.0334]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  68%|██████▊   | 149/220 [00:09<00:04, 15.71it/s, v_num=304, train_loss=0.035] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  68%|██████▊   | 150/220 [00:09<00:04, 15.73it/s, v_num=304, train_loss=0.0408]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  69%|██████▊   | 151/220 [00:09<00:04, 15.74it/s, v_num=304, train_loss=0.0456]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  69%|██████▉   | 152/220 [00:09<00:04, 15.76it/s, v_num=304, train_loss=0.045] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  70%|██████▉   | 153/220 [00:09<00:04, 15.77it/s, v_num=304, train_loss=0.0366]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  70%|███████   | 154/220 [00:09<00:04, 15.78it/s, v_num=304, train_loss=0.0408]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  70%|███████   | 155/220 [00:09<00:04, 15.80it/s, v_num=304, train_loss=0.0546]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  71%|███████   | 156/220 [00:09<00:04, 15.81it/s, v_num=304, train_loss=0.0381]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  71%|███████▏  | 157/220 [00:09<00:03, 15.83it/s, v_num=304, train_loss=0.039] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  72%|███████▏  | 158/220 [00:09<00:03, 15.84it/s, v_num=304, train_loss=0.0457]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  72%|███████▏  | 159/220 [00:10<00:03, 15.86it/s, v_num=304, train_loss=0.0439]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  73%|███████▎  | 160/220 [00:10<00:03, 15.87it/s, v_num=304, train_loss=0.0417]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  73%|███████▎  | 161/220 [00:10<00:03, 15.88it/s, v_num=304, train_loss=0.0384]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  74%|███████▎  | 162/220 [00:10<00:03, 15.89it/s, v_num=304, train_loss=0.0417]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  74%|███████▍  | 163/220 [00:10<00:03, 15.91it/s, v_num=304, train_loss=0.0406]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  75%|███████▍  | 164/220 [00:10<00:03, 15.92it/s, v_num=304, train_loss=0.0451]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  75%|███████▌  | 165/220 [00:10<00:03, 15.94it/s, v_num=304, train_loss=0.0443]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  75%|███████▌  | 166/220 [00:10<00:03, 15.95it/s, v_num=304, train_loss=0.0363]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  76%|███████▌  | 167/220 [00:10<00:03, 15.96it/s, v_num=304, train_loss=0.042] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  76%|███████▋  | 168/220 [00:10<00:03, 15.97it/s, v_num=304, train_loss=0.0462]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  77%|███████▋  | 169/220 [00:10<00:03, 15.98it/s, v_num=304, train_loss=0.0357]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  77%|███████▋  | 170/220 [00:10<00:03, 15.99it/s, v_num=304, train_loss=0.0447]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  78%|███████▊  | 171/220 [00:10<00:03, 16.01it/s, v_num=304, train_loss=0.045] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  78%|███████▊  | 172/220 [00:10<00:02, 16.02it/s, v_num=304, train_loss=0.0315]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  79%|███████▊  | 173/220 [00:10<00:02, 16.03it/s, v_num=304, train_loss=0.0437]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  79%|███████▉  | 174/220 [00:10<00:02, 16.05it/s, v_num=304, train_loss=0.0398]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  80%|███████▉  | 175/220 [00:10<00:02, 16.06it/s, v_num=304, train_loss=0.0436]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  80%|████████  | 176/220 [00:10<00:02, 16.06it/s, v_num=304, train_loss=0.0545]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  80%|████████  | 177/220 [00:11<00:02, 16.07it/s, v_num=304, train_loss=0.0346]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  81%|████████  | 178/220 [00:11<00:02, 16.09it/s, v_num=304, train_loss=0.0388]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  81%|████████▏ | 179/220 [00:11<00:02, 16.10it/s, v_num=304, train_loss=0.0323]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  82%|████████▏ | 180/220 [00:11<00:02, 16.11it/s, v_num=304, train_loss=0.0418]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  82%|████████▏ | 181/220 [00:11<00:02, 16.12it/s, v_num=304, train_loss=0.0348]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  83%|████████▎ | 182/220 [00:11<00:02, 16.13it/s, v_num=304, train_loss=0.0554]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  83%|████████▎ | 183/220 [00:11<00:02, 16.14it/s, v_num=304, train_loss=0.0488]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  84%|████████▎ | 184/220 [00:11<00:02, 16.15it/s, v_num=304, train_loss=0.0409]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  84%|████████▍ | 185/220 [00:11<00:02, 16.16it/s, v_num=304, train_loss=0.0414]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  85%|████████▍ | 186/220 [00:11<00:02, 16.17it/s, v_num=304, train_loss=0.0476]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  85%|████████▌ | 187/220 [00:11<00:02, 16.18it/s, v_num=304, train_loss=0.0444]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  85%|████████▌ | 188/220 [00:11<00:01, 16.19it/s, v_num=304, train_loss=0.0452]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  86%|████████▌ | 189/220 [00:11<00:01, 16.20it/s, v_num=304, train_loss=0.0473]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  86%|████████▋ | 190/220 [00:11<00:01, 16.21it/s, v_num=304, train_loss=0.0545]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  87%|████████▋ | 191/220 [00:11<00:01, 16.23it/s, v_num=304, train_loss=0.0367]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  87%|████████▋ | 192/220 [00:11<00:01, 16.24it/s, v_num=304, train_loss=0.0428]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  88%|████████▊ | 193/220 [00:11<00:01, 16.25it/s, v_num=304, train_loss=0.0507]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  88%|████████▊ | 194/220 [00:11<00:01, 16.26it/s, v_num=304, train_loss=0.0424]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  89%|████████▊ | 195/220 [00:11<00:01, 16.27it/s, v_num=304, train_loss=0.0382]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  89%|████████▉ | 196/220 [00:12<00:01, 16.28it/s, v_num=304, train_loss=0.0341]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  90%|████████▉ | 197/220 [00:12<00:01, 16.30it/s, v_num=304, train_loss=0.0491]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  90%|█████████ | 198/220 [00:12<00:01, 16.31it/s, v_num=304, train_loss=0.0392]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  90%|█████████ | 199/220 [00:12<00:01, 16.32it/s, v_num=304, train_loss=0.0387]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  91%|█████████ | 200/220 [00:12<00:01, 16.33it/s, v_num=304, train_loss=0.0318]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  91%|█████████▏| 201/220 [00:12<00:01, 16.34it/s, v_num=304, train_loss=0.035] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  92%|█████████▏| 202/220 [00:12<00:01, 16.34it/s, v_num=304, train_loss=0.0519]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  92%|█████████▏| 203/220 [00:12<00:01, 16.35it/s, v_num=304, train_loss=0.0371]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  93%|█████████▎| 204/220 [00:12<00:00, 16.36it/s, v_num=304, train_loss=0.0396]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  93%|█████████▎| 205/220 [00:12<00:00, 16.37it/s, v_num=304, train_loss=0.0385]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  94%|█████████▎| 206/220 [00:12<00:00, 16.38it/s, v_num=304, train_loss=0.0399]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  94%|█████████▍| 207/220 [00:12<00:00, 16.39it/s, v_num=304, train_loss=0.0395]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  95%|█████████▍| 208/220 [00:12<00:00, 16.40it/s, v_num=304, train_loss=0.0428]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  95%|█████████▌| 209/220 [00:12<00:00, 16.41it/s, v_num=304, train_loss=0.039] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  95%|█████████▌| 210/220 [00:12<00:00, 16.42it/s, v_num=304, train_loss=0.0424]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  96%|█████████▌| 211/220 [00:12<00:00, 16.43it/s, v_num=304, train_loss=0.0314]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  96%|█████████▋| 212/220 [00:12<00:00, 16.43it/s, v_num=304, train_loss=0.036] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  97%|█████████▋| 213/220 [00:12<00:00, 16.44it/s, v_num=304, train_loss=0.033]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  97%|█████████▋| 214/220 [00:13<00:00, 16.45it/s, v_num=304, train_loss=0.0339]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  98%|█████████▊| 215/220 [00:13<00:00, 16.46it/s, v_num=304, train_loss=0.0311]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  98%|█████████▊| 216/220 [00:13<00:00, 16.47it/s, v_num=304, train_loss=0.0565]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  99%|█████████▊| 217/220 [00:13<00:00, 16.47it/s, v_num=304, train_loss=0.034] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2:  99%|█████████▉| 218/220 [00:13<00:00, 16.48it/s, v_num=304, train_loss=0.0313]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 2: 100%|█████████▉| 219/220 [00:13<00:00, 16.49it/s, v_num=304, train_loss=0.0415]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:   0%|          | 0/220 [00:00<?, ?it/s, v_num=304, train_loss=0.0317]          196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:   0%|          | 1/220 [00:01<05:25,  0.67it/s, v_num=304, train_loss=0.0355]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:   1%|          | 2/220 [00:01<02:47,  1.30it/s, v_num=304, train_loss=0.0368]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:   1%|▏         | 3/220 [00:01<01:55,  1.88it/s, v_num=304, train_loss=0.0275]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:   2%|▏         | 4/220 [00:01<01:29,  2.42it/s, v_num=304, train_loss=0.0496]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:   2%|▏         | 5/220 [00:01<01:13,  2.93it/s, v_num=304, train_loss=0.0341]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:   3%|▎         | 6/220 [00:01<01:02,  3.41it/s, v_num=304, train_loss=0.0452]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:   3%|▎         | 7/220 [00:01<00:55,  3.86it/s, v_num=304, train_loss=0.0479]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:   4%|▎         | 8/220 [00:01<00:49,  4.28it/s, v_num=304, train_loss=0.0455]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:   4%|▍         | 9/220 [00:01<00:45,  4.68it/s, v_num=304, train_loss=0.0468]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:   5%|▍         | 10/220 [00:01<00:41,  5.06it/s, v_num=304, train_loss=0.0361]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:   5%|▌         | 11/220 [00:02<00:38,  5.41it/s, v_num=304, train_loss=0.0458]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:   5%|▌         | 12/220 [00:02<00:36,  5.75it/s, v_num=304, train_loss=0.0348]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:   6%|▌         | 13/220 [00:02<00:34,  6.06it/s, v_num=304, train_loss=0.0357]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:   6%|▋         | 14/220 [00:02<00:32,  6.37it/s, v_num=304, train_loss=0.0337]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:   7%|▋         | 15/220 [00:02<00:30,  6.65it/s, v_num=304, train_loss=0.0431]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:   7%|▋         | 16/220 [00:02<00:29,  6.93it/s, v_num=304, train_loss=0.0323]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:   8%|▊         | 17/220 [00:02<00:28,  7.19it/s, v_num=304, train_loss=0.0429]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:   8%|▊         | 18/220 [00:02<00:27,  7.45it/s, v_num=304, train_loss=0.0381]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:   9%|▊         | 19/220 [00:02<00:26,  7.68it/s, v_num=304, train_loss=0.0395]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:   9%|▉         | 20/220 [00:02<00:25,  7.91it/s, v_num=304, train_loss=0.0314]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  10%|▉         | 21/220 [00:02<00:24,  8.13it/s, v_num=304, train_loss=0.0359]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  10%|█         | 22/220 [00:02<00:23,  8.34it/s, v_num=304, train_loss=0.0357]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  10%|█         | 23/220 [00:02<00:23,  8.54it/s, v_num=304, train_loss=0.0461]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  11%|█         | 24/220 [00:02<00:22,  8.73it/s, v_num=304, train_loss=0.0357]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  11%|█▏        | 25/220 [00:02<00:21,  8.92it/s, v_num=304, train_loss=0.0394]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  12%|█▏        | 26/220 [00:02<00:21,  9.10it/s, v_num=304, train_loss=0.0441]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  12%|█▏        | 27/220 [00:02<00:20,  9.28it/s, v_num=304, train_loss=0.033] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  13%|█▎        | 28/220 [00:02<00:20,  9.44it/s, v_num=304, train_loss=0.0379]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  13%|█▎        | 29/220 [00:03<00:19,  9.59it/s, v_num=304, train_loss=0.0403]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  14%|█▎        | 30/220 [00:03<00:19,  9.75it/s, v_num=304, train_loss=0.0347]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  14%|█▍        | 31/220 [00:03<00:19,  9.89it/s, v_num=304, train_loss=0.0409]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  15%|█▍        | 32/220 [00:03<00:18, 10.04it/s, v_num=304, train_loss=0.0448]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  15%|█▌        | 33/220 [00:03<00:18, 10.18it/s, v_num=304, train_loss=0.037] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  15%|█▌        | 34/220 [00:03<00:18, 10.32it/s, v_num=304, train_loss=0.0443]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  16%|█▌        | 35/220 [00:03<00:17, 10.45it/s, v_num=304, train_loss=0.0366]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  16%|█▋        | 36/220 [00:03<00:17, 10.57it/s, v_num=304, train_loss=0.0489]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  17%|█▋        | 37/220 [00:03<00:17, 10.69it/s, v_num=304, train_loss=0.0446]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  17%|█▋        | 38/220 [00:03<00:16, 10.81it/s, v_num=304, train_loss=0.0411]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  18%|█▊        | 39/220 [00:03<00:16, 10.92it/s, v_num=304, train_loss=0.033] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  18%|█▊        | 40/220 [00:03<00:16, 11.04it/s, v_num=304, train_loss=0.0461]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  19%|█▊        | 41/220 [00:03<00:16, 11.15it/s, v_num=304, train_loss=0.0369]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  19%|█▉        | 42/220 [00:03<00:15, 11.25it/s, v_num=304, train_loss=0.0424]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  20%|█▉        | 43/220 [00:03<00:15, 11.35it/s, v_num=304, train_loss=0.0367]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  20%|██        | 44/220 [00:03<00:15, 11.45it/s, v_num=304, train_loss=0.0441]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  20%|██        | 45/220 [00:03<00:15, 11.54it/s, v_num=304, train_loss=0.0428]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  21%|██        | 46/220 [00:03<00:14, 11.63it/s, v_num=304, train_loss=0.0423]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  21%|██▏       | 47/220 [00:04<00:14, 11.72it/s, v_num=304, train_loss=0.0506]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  22%|██▏       | 48/220 [00:04<00:14, 11.78it/s, v_num=304, train_loss=0.0427]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  22%|██▏       | 49/220 [00:04<00:14, 11.86it/s, v_num=304, train_loss=0.0479]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  23%|██▎       | 50/220 [00:04<00:14, 11.95it/s, v_num=304, train_loss=0.0436]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  23%|██▎       | 51/220 [00:04<00:14, 12.03it/s, v_num=304, train_loss=0.0359]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  24%|██▎       | 52/220 [00:04<00:13, 12.10it/s, v_num=304, train_loss=0.0341]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  24%|██▍       | 53/220 [00:04<00:13, 12.18it/s, v_num=304, train_loss=0.0459]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  25%|██▍       | 54/220 [00:04<00:13, 12.25it/s, v_num=304, train_loss=0.0344]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  25%|██▌       | 55/220 [00:04<00:13, 12.33it/s, v_num=304, train_loss=0.0312]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  25%|██▌       | 56/220 [00:04<00:13, 12.37it/s, v_num=304, train_loss=0.0404]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  26%|██▌       | 57/220 [00:04<00:13, 12.44it/s, v_num=304, train_loss=0.0341]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  26%|██▋       | 58/220 [00:04<00:12, 12.51it/s, v_num=304, train_loss=0.040] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  27%|██▋       | 59/220 [00:04<00:12, 12.58it/s, v_num=304, train_loss=0.0513]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  27%|██▋       | 60/220 [00:04<00:12, 12.64it/s, v_num=304, train_loss=0.045] 196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  28%|██▊       | 61/220 [00:04<00:12, 12.70it/s, v_num=304, train_loss=0.035]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  28%|██▊       | 62/220 [00:04<00:12, 12.77it/s, v_num=304, train_loss=0.0356]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  29%|██▊       | 63/220 [00:04<00:12, 12.83it/s, v_num=304, train_loss=0.0317]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  29%|██▉       | 64/220 [00:04<00:12, 12.86it/s, v_num=304, train_loss=0.0304]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  30%|██▉       | 65/220 [00:05<00:11, 12.92it/s, v_num=304, train_loss=0.0438]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  30%|███       | 66/220 [00:05<00:11, 12.98it/s, v_num=304, train_loss=0.0354]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  30%|███       | 67/220 [00:05<00:11, 13.03it/s, v_num=304, train_loss=0.0387]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  31%|███       | 68/220 [00:05<00:11, 13.08it/s, v_num=304, train_loss=0.0318]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  31%|███▏      | 69/220 [00:05<00:11, 13.13it/s, v_num=304, train_loss=0.0399]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  32%|███▏      | 70/220 [00:05<00:11, 13.19it/s, v_num=304, train_loss=0.0509]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  32%|███▏      | 71/220 [00:05<00:11, 13.24it/s, v_num=304, train_loss=0.0351]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  33%|███▎      | 72/220 [00:05<00:11, 13.26it/s, v_num=304, train_loss=0.0298]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  33%|███▎      | 73/220 [00:05<00:11, 13.31it/s, v_num=304, train_loss=0.0369]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  34%|███▎      | 74/220 [00:05<00:10, 13.36it/s, v_num=304, train_loss=0.0303]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  34%|███▍      | 75/220 [00:05<00:10, 13.41it/s, v_num=304, train_loss=0.0375]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  35%|███▍      | 76/220 [00:05<00:10, 13.45it/s, v_num=304, train_loss=0.0356]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  35%|███▌      | 77/220 [00:05<00:10, 13.50it/s, v_num=304, train_loss=0.0323]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  35%|███▌      | 78/220 [00:05<00:10, 13.54it/s, v_num=304, train_loss=0.0512]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n",
      "Epoch 3:  36%|███▌      | 79/220 [00:05<00:10, 13.59it/s, v_num=304, train_loss=0.0307]196\n",
      "torch.Size([2, 16, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:48\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:599\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    593\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    595\u001b[0m     ckpt_path,\n\u001b[1;32m    596\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    597\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    598\u001b[0m )\n\u001b[0;32m--> 599\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1012\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m-> 1012\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1056\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:216\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:455\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 455\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:150\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:320\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 320\u001b[0m     batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:192\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:270\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:176\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/core/module.py:1302\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;124;03mthe optimizer.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1300\u001b[0m \n\u001b[1;32m   1301\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1302\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py:154\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:239\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py:123\u001b[0m, in \u001b[0;36mPrecision.optimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/optim/optimizer.py:485\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    482\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m             )\n\u001b[0;32m--> 485\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/optim/optimizer.py:79\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 79\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/optim/adam.py:225\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 225\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py:109\u001b[0m, in \u001b[0;36mPrecision._wrap_closure\u001b[0;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03mhook is called.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m \n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:146\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:140\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:241\u001b[0m, in \u001b[0;36m_AutomaticOptimization._make_backward_fn.<locals>.backward_fn\u001b[0;34m(loss)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbackward_fn\u001b[39m(loss: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 241\u001b[0m     \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbackward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:328\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 328\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:213\u001b[0m, in \u001b[0;36mStrategy.backward\u001b[0;34m(self, closure_loss, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m closure_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mpre_backward(closure_loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module)\n\u001b[0;32m--> 213\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m closure_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mpost_backward(closure_loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py:73\u001b[0m, in \u001b[0;36mPrecision.backward\u001b[0;34m(self, tensor, model, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs the actual backpropagation.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m \n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/core/module.py:1097\u001b[0m, in \u001b[0;36mLightningModule.backward\u001b[0;34m(self, loss, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1097\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/autograd/__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 350\u001b[0m\n\u001b[1;32m    344\u001b[0m model \u001b[38;5;241m=\u001b[39m MAEPretrainSwin(patch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m    345\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m    346\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m    347\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    348\u001b[0m     log_every_n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m    349\u001b[0m )\n\u001b[0;32m--> 350\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:561\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:65\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[1;32m     64\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[0;32m---> 65\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m     68\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "# from torch.optim import AdamW\n",
    "# from warmup_scheduler import GradualWarmupScheduler\n",
    "\n",
    "# import utils\n",
    "\n",
    "# from transformers import SegformerForSemanticSegmentation\n",
    "# from torchvision.models.video import swin_transformer\n",
    "# import albumentations as A\n",
    "# class MAEPretrainSwin(pl.LightningModule):\n",
    "#     def __init__(self, lr=1e-4, mask_ratio=4, patch_size=16, embed_dim=768, decoder_dim=512, decoder_layers=4,input_T=16,input_H=224,input_W=224):\n",
    "#         super().__init__()\n",
    "#         self.save_hyperparameters()\n",
    "#         self.encoder = swin_transformer.swin3d_t(weights='KINETICS400_V1')\n",
    "        \n",
    "#         self.encoder.head = nn.Identity()\n",
    "#         self.encoder.features[-1].register_forward_hook(self._hook)\n",
    "\n",
    "#         self.features = None\n",
    "#         self.patch_size = patch_size\n",
    "#         self.criterion = nn.MSELoss()\n",
    "#         self.train_loss_history = []\n",
    "\n",
    "#         # Transformer decoder components\n",
    "#         self.decoder_embed = nn.Linear(embed_dim, decoder_dim)\n",
    "#         self.decoder_pos_embed = nn.Parameter(torch.randn(1, 1000, decoder_dim))  # Assume max 1000 patches\n",
    "#         decoder_layer = nn.TransformerEncoderLayer(d_model=decoder_dim, nhead=8, dim_feedforward=2048)\n",
    "#         self.decoder_transformer = nn.TransformerEncoder(decoder_layer, num_layers=decoder_layers)\n",
    "#         self.decoder_pred = nn.Linear(decoder_dim, 3 * patch_size**3)  # Output prediction per patch\n",
    "\n",
    "#         # Mask token for masked patches in decoder\n",
    "#         self.mask_token = nn.Parameter(torch.zeros(1, 1, decoder_dim))\n",
    "#         nn.init.normal_(self.mask_token, std=0.02)\n",
    "\n",
    "#     def _hook(self, module, input, output):\n",
    "#         self.features = output  # Save encoder output feature map\n",
    "\n",
    "#     def patchify(self, x):\n",
    "#         x = x.permute(0,2,1,3,4)  # (B,C,T,H,W)\n",
    "#         B, C, T, H, W = x.shape\n",
    "#         assert T % self.patch_size == 0 and H % self.patch_size == 0 and W % self.patch_size == 0\n",
    "#         x = x.unfold(2, self.patch_size, self.patch_size).unfold(3, self.patch_size, self.patch_size).unfold(4, self.patch_size, self.patch_size)\n",
    "#         x = x.contiguous().view(B, C, -1, self.patch_size, self.patch_size, self.patch_size)\n",
    "#         x = x.permute(0, 2, 1, 3, 4, 5)  # (B, N, C, ps, ps, ps)\n",
    "#         x = x.reshape(B, -1, C * self.patch_size**3)\n",
    "#         return x\n",
    "\n",
    "#     def unpatchify(self, x, patch_shape):\n",
    "#         B, N, D = x.shape\n",
    "#         pt, ph, pw = patch_shape\n",
    "#         ps = self.patch_size\n",
    "#         C = D // (ps**3)\n",
    "#         assert pt * ph * pw == N\n",
    "#         x = x.view(B, pt, ph, pw, C, ps, ps, ps)\n",
    "#         x = x.permute(0, 4, 1, 5, 2, 6, 3, 7)\n",
    "#         x = x.contiguous().view(B, C, pt * ps, ph * ps, pw * ps)\n",
    "#         return x\n",
    "\n",
    "#     def tube_masking(self, x, square_size=4):\n",
    "#         B, N, D = x.shape\n",
    "#         T, H, W = self.hparams.input_T, self.hparams.input_H, self.hparams.input_W\n",
    "#         ps = self.patch_size\n",
    "#         pt, ph, pw = T // ps, H // ps, W // ps\n",
    "#         num_spatial = ph * pw\n",
    "#         # assert square_size <= ph and square_size <= pw\n",
    "\n",
    "#         ids_keep = []\n",
    "#         for b in range(B):\n",
    "#             top = torch.randint(0, ph - square_size + 1, (1,))\n",
    "#             left = torch.randint(0, pw - square_size + 1, (1,))\n",
    "#             spatial_ids = [(top + i) * pw + (left + j) for i in range(square_size) for j in range(square_size)]\n",
    "\n",
    "#             tube_indices = []\n",
    "#             for t in range(pt):\n",
    "#                 for idx in spatial_ids:\n",
    "#                     tube_indices.append(t * num_spatial + idx)\n",
    "\n",
    "#             ids_keep.append(torch.tensor(tube_indices, device=x.device))\n",
    "#         ids_keep = torch.stack(ids_keep, dim=0)  # (B, kept_patches)\n",
    "#         x_masked = torch.gather(x, 1, ids_keep.unsqueeze(-1).expand(-1, -1, D))\n",
    "\n",
    "#         num_total = x.shape[1]\n",
    "#         num_keep = ids_keep.shape[1]\n",
    "#         mask_ratio_actual = 1 - (num_keep / num_total)\n",
    "#         # print(f\"Actual mask ratio: {mask_ratio_actual:.4f} ({num_keep}/{num_total} patches kept)\")\n",
    "#         return x_masked, ids_keep, None\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         B, T, C, H, W = x.shape\n",
    "\n",
    "#         # 1. Patchify input video\n",
    "#         x_patched = self.patchify(x)  # (B, N, D)\n",
    "#         N = x_patched.shape[1]\n",
    "\n",
    "#         # 2. Mask patches, keep a tube of patches visible to encoder\n",
    "#         x_masked, ids_keep, _ = self.tube_masking(x_patched, square_size=model.hparams.mask_ratio)  # (B, n_visible, D)\n",
    "#         ids_keep = ids_keep.long()\n",
    "\n",
    "#         # Calculate masked patch indices\n",
    "#         all_ids = torch.arange(N, device=x.device).unsqueeze(0).expand(B, -1)  # (B, N)\n",
    "#         mask = torch.ones_like(all_ids, dtype=torch.bool)\n",
    "#         mask.scatter_(1, ids_keep, False)\n",
    "#         ids_masked = all_ids[mask].view(B, -1)\n",
    "\n",
    "#         # 3. Unpatchify visible patches to video for encoder\n",
    "#         pt, ph, pw = T // self.patch_size, H // self.patch_size, W // self.patch_size\n",
    "#         # We know the tube shape is (pt, square_size, square_size)\n",
    "#         x_masked_video = self.unpatchify(x_masked, (pt, model.hparams.mask_ratio, model.hparams.mask_ratio))  # (B, C, T, H_mask, W_mask)\n",
    "\n",
    "#         # 4. Encoder forward on masked video\n",
    "#         _ = self.encoder(x_masked_video)\n",
    "#         feat = self.features  # (B, T', H', W', C)\n",
    "#         feat = feat.permute(0, 4, 1, 2, 3)  # (B, C, T', H', W')\n",
    "#         feat = F.interpolate(feat, size=(pt, model.hparams.mask_ratio, model.hparams.mask_ratio), mode='trilinear', align_corners=False)\n",
    "#         feat = feat.flatten(2).transpose(1, 2)  # (B, n_visible, embed_dim)\n",
    "\n",
    "#         # 5. Embed encoder features to decoder_dim\n",
    "#         x_vis = self.decoder_embed(feat)  # (B, n_visible, decoder_dim)\n",
    "\n",
    "#         # 6. Prepare mask tokens for masked patches\n",
    "#         mask_tokens = self.mask_token.expand(B, ids_masked.shape[1], -1)  # (B, n_masked, decoder_dim)\n",
    "\n",
    "#         # 7. Create full sequence tensor for decoder input\n",
    "#         x_dec = torch.zeros(B, N, x_vis.shape[2], device=x.device, dtype=x_vis.dtype)\n",
    "#         x_dec.scatter_(1, ids_keep.unsqueeze(-1).expand(-1, -1, x_vis.shape[2]), x_vis)\n",
    "#         x_dec.scatter_(1, ids_masked.unsqueeze(-1).expand(-1, -1, x_vis.shape[2]), mask_tokens)\n",
    "\n",
    "#         # 8. Add positional embedding\n",
    "#         pos_embed = self.decoder_pos_embed[:, :N, :]\n",
    "#         x_dec = x_dec + pos_embed\n",
    "\n",
    "#         # 9. Decode full sequence\n",
    "#         x_dec = self.decoder_transformer(x_dec)\n",
    "#         # print(x_dec.shape)\n",
    "#         pred = self.decoder_pred(x_dec)  # (B, N, patch_dim)\n",
    "        \n",
    "\n",
    "#         # 10. Compute reconstruction loss only on masked patches (in training_step)\n",
    "#         # 11. Unpatchify pred to video\n",
    "#         recon = self.unpatchify(pred, (pt, ph, pw))  # (B, C, T, H, W)\n",
    "#         recon = recon.permute(0, 2, 1, 3, 4)  # (B, T, C, H, W)\n",
    "\n",
    "#         return recon, x_masked_video, mask, ids_masked, pred, x_patched\n",
    "\n",
    "#     def training_step(self, batch, batch_idx):\n",
    "#         x, y = batch  # (B, 3, T, H, W)\n",
    "#         recon, x_masked, mask, ids_masked, pred, target = self(x)\n",
    "\n",
    "#         # Compute loss only on masked patches\n",
    "#         # We want pred and target only on masked patches\n",
    "#         loss = self.criterion(pred[mask], target[mask])\n",
    "#         self.train_loss_history.append(loss.item())\n",
    "#         self.train_loss_history.append(loss.item())  # ✅ Track loss here\n",
    "#         self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "#         # Visualize first batch, first 4 frames (optional: only on first batch)\n",
    "#         # if batch_idx == 0:\n",
    "#         #     visualize_reconstruction(x, recon, sample_idx=0, num_frames=4)\n",
    "#         #     visualize_x_masked(x_masked, sample_idx=0, num_frames=4)\n",
    "\n",
    "#         return loss\n",
    "\n",
    "#     def configure_optimizers(self):\n",
    "#         return torch.optim.AdamW(self.parameters(), lr=self.hparams.lr)\n",
    "\n",
    "\n",
    "# # -----------------------------\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "#     model = MAEPretrainSwin(patch_size=16)\n",
    "#     trainer = pl.Trainer(\n",
    "#         max_epochs=50,\n",
    "#         accelerator='auto',\n",
    "#         log_every_n_steps=20,\n",
    "#     )\n",
    "#     trainer.fit(model, train_loader)\n",
    "from torch.optim import AdamW\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "\n",
    "import utils\n",
    "\n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "from torchvision.models.video import swin_transformer\n",
    "import albumentations as A\n",
    "class MAEPretrainSwin(pl.LightningModule):\n",
    "    def __init__(self, lr=1e-4, mask_ratio=4, patch_size=16, embed_dim=768, decoder_dim=512, decoder_layers=2,input_T=16,input_H=224,input_W=224):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.encoder = swin_transformer.swin3d_t(weights='KINETICS400_V1')\n",
    "        \n",
    "        self.encoder.head = nn.Identity()\n",
    "        self.encoder.features[-1].register_forward_hook(self._hook)\n",
    "\n",
    "        self.features = None\n",
    "        self.patch_size = patch_size\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.train_loss_history = []\n",
    "\n",
    "        # Transformer decoder components\n",
    "        self.decoder_embed = nn.Linear(embed_dim, decoder_dim)\n",
    "        self.decoder_pos_embed = nn.Parameter(torch.randn(1, 1000, decoder_dim))  # Assume max 1000 patches\n",
    "        decoder_layer = nn.TransformerEncoderLayer(d_model=decoder_dim, nhead=8, dim_feedforward=2048)\n",
    "        self.decoder_transformer = nn.TransformerEncoder(decoder_layer, num_layers=decoder_layers)\n",
    "        self.decoder_pred = nn.Linear(decoder_dim, 3 * patch_size**3)  # Output prediction per patch\n",
    "\n",
    "        # Mask token for masked patches in decoder\n",
    "        self.mask_token = nn.Parameter(torch.zeros(1, 1, decoder_dim))\n",
    "        nn.init.normal_(self.mask_token, std=0.02)\n",
    "\n",
    "    def _hook(self, module, input, output):\n",
    "        self.features = output  # Save encoder output feature map\n",
    "\n",
    "    def patchify(self, x):\n",
    "        x = x.permute(0,2,1,3,4)  # (B,C,T,H,W)\n",
    "        B, C, T, H, W = x.shape\n",
    "        assert T % self.patch_size == 0 and H % self.patch_size == 0 and W % self.patch_size == 0\n",
    "        x = x.unfold(2, self.patch_size, self.patch_size).unfold(3, self.patch_size, self.patch_size).unfold(4, self.patch_size, self.patch_size)\n",
    "        x = x.contiguous().view(B, C, -1, self.patch_size, self.patch_size, self.patch_size)\n",
    "        x = x.permute(0, 2, 1, 3, 4, 5)  # (B, N, C, ps, ps, ps)\n",
    "        x = x.reshape(B, -1, C * self.patch_size**3)\n",
    "        return x\n",
    "\n",
    "    def unpatchify(self, x, patch_shape):\n",
    "        B, N, D = x.shape\n",
    "        pt, ph, pw = patch_shape\n",
    "        ps = self.patch_size\n",
    "        C = D // (ps**3)\n",
    "        assert pt * ph * pw == N\n",
    "        x = x.view(B, pt, ph, pw, C, ps, ps, ps)\n",
    "        x = x.permute(0, 4, 1, 5, 2, 6, 3, 7)\n",
    "        x = x.contiguous().view(B, C, pt * ps, ph * ps, pw * ps)\n",
    "        return x\n",
    "\n",
    "    def tube_masking(self, x, square_size=4):\n",
    "        B, N, D = x.shape\n",
    "        T, H, W = self.hparams.input_T, self.hparams.input_H, self.hparams.input_W\n",
    "        ps = self.patch_size\n",
    "        pt, ph, pw = T // ps, H // ps, W // ps\n",
    "        num_spatial = ph * pw\n",
    "        assert square_size <= ph and square_size <= pw\n",
    "\n",
    "        ids_keep = []\n",
    "        for b in range(B):\n",
    "            top = torch.randint(0, ph - square_size + 1, (1,))\n",
    "            left = torch.randint(0, pw - square_size + 1, (1,))\n",
    "            spatial_ids = [(top + i) * pw + (left + j) for i in range(square_size) for j in range(square_size)]\n",
    "\n",
    "            tube_indices = []\n",
    "            for t in range(pt):\n",
    "                for idx in spatial_ids:\n",
    "                    tube_indices.append(t * num_spatial + idx)\n",
    "\n",
    "            ids_keep.append(torch.tensor(tube_indices, device=x.device))\n",
    "        ids_keep = torch.stack(ids_keep, dim=0)  # (B, kept_patches)\n",
    "        x_masked = torch.gather(x, 1, ids_keep.unsqueeze(-1).expand(-1, -1, D))\n",
    "\n",
    "        num_total = x.shape[1]\n",
    "        num_keep = ids_keep.shape[1]\n",
    "        mask_ratio_actual = 1 - (num_keep / num_total)\n",
    "        # print(f\"Actual mask ratio: {mask_ratio_actual:.4f} ({num_keep}/{num_total} patches kept)\")\n",
    "        return x_masked, ids_keep, None\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C, H, W = x.shape\n",
    "\n",
    "        # 1. Patchify input video\n",
    "        x_patched = self.patchify(x)  # (B, N, D)\n",
    "        N = x_patched.shape[1]\n",
    "        print(N)\n",
    "\n",
    "        # 2. Mask patches, keep a tube of patches visible to encoder\n",
    "        x_masked, ids_keep, _ = self.tube_masking(x_patched, square_size=model.hparams.mask_ratio)  # (B, n_visible, D)\n",
    "        ids_keep = ids_keep.long()\n",
    "\n",
    "        # Calculate masked patch indices\n",
    "        all_ids = torch.arange(N, device=x.device).unsqueeze(0).expand(B, -1)  # (B, N)\n",
    "        mask = torch.ones_like(all_ids, dtype=torch.bool)\n",
    "        mask.scatter_(1, ids_keep, False)\n",
    "        ids_masked = all_ids[mask].view(B, -1)\n",
    "\n",
    "        # 3. Unpatchify visible patches to video for encoder\n",
    "        pt, ph, pw = T // self.patch_size, H // self.patch_size, W // self.patch_size\n",
    "        # We know the tube shape is (pt, square_size, square_size)\n",
    "        x_masked_video = self.unpatchify(x_masked, (pt, model.hparams.mask_ratio, model.hparams.mask_ratio))  # (B, C, T, H_mask, W_mask)\n",
    "\n",
    "        # 4. Encoder forward on masked video\n",
    "        _ = self.encoder(x_masked_video)\n",
    "        feat = self.features  # (B, T', H', W', C)\n",
    "        feat = feat.permute(0, 4, 1, 2, 3)  # (B, C, T', H', W')\n",
    "        feat = F.interpolate(feat, size=(pt, model.hparams.mask_ratio, model.hparams.mask_ratio), mode='trilinear', align_corners=False)\n",
    "        feat = feat.flatten(2).transpose(1, 2)  # (B, n_visible, embed_dim)\n",
    "\n",
    "        # 5. Embed encoder features to decoder_dim\n",
    "        x_vis = self.decoder_embed(feat)  # (B, n_visible, decoder_dim)\n",
    "\n",
    "        # 6. Prepare mask tokens for masked patches\n",
    "        mask_tokens = self.mask_token.expand(B, ids_masked.shape[1], -1)  # (B, n_masked, decoder_dim)\n",
    "\n",
    "        # 7. Create full sequence tensor for decoder input\n",
    "        x_dec = torch.zeros(B, N, x_vis.shape[2], device=x.device, dtype=x_vis.dtype)\n",
    "        x_dec.scatter_(1, ids_keep.unsqueeze(-1).expand(-1, -1, x_vis.shape[2]), x_vis)\n",
    "        x_dec.scatter_(1, ids_masked.unsqueeze(-1).expand(-1, -1, x_vis.shape[2]), mask_tokens)\n",
    "\n",
    "        # 8. Add positional embedding\n",
    "        pos_embed = self.decoder_pos_embed[:, :N, :]\n",
    "        x_dec = x_dec + pos_embed\n",
    "\n",
    "        # 9. Decode full sequence\n",
    "        x_dec = self.decoder_transformer(x_dec)\n",
    "        pred = self.decoder_pred(x_dec)  # (B, N, patch_dim)\n",
    "        # pred.reshape(B, C, T, H, W)\n",
    "        # print(pred.shape)\n",
    "        # 10. Compute reconstruction loss only on masked patches (in training_step)\n",
    "        # 11. Unpatchify pred to video\n",
    "        recon = self.unpatchify(pred, (pt, ph, pw))  # (B, C, T, H, W)\n",
    "        recon = recon.permute(0, 2, 1, 3, 4)  # (B, T, C, H, W)\n",
    "        print(recon.shape)\n",
    "\n",
    "        return recon, x_masked_video, mask, ids_masked, pred, x_patched\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch  # (B, 3, T, H, W)\n",
    "        \n",
    "        recon, x_masked, mask, ids_masked, pred, target = self(x)\n",
    "\n",
    "        # Compute loss only on masked patches\n",
    "        # We want pred and target only on masked patches\n",
    "        loss = self.criterion(pred, target)\n",
    "        self.train_loss_history.append(loss.item())\n",
    "        self.train_loss_history.append(loss.item())  # ✅ Track loss here\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        # Visualize first batch, first 4 frames (optional: only on first batch)\n",
    "        # if batch_idx == 0:\n",
    "            # visualize_reconstruction(x, recon, sample_idx=2, num_frames=2)\n",
    "            # visualize_x_masked(x_masked, sample_idx=8, num_frames=2)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.hparams.lr)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    model = MAEPretrainSwin(patch_size=16)\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=50,\n",
    "        accelerator='auto',\n",
    "        log_every_n_steps=20,\n",
    "    )\n",
    "    trainer.fit(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c258e7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot training loss\n",
    "plt.plot(model.train_loss_history[10:])\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e465ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192691"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model\n",
    "del trainer\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n",
    "import gc\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626046b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a647e187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d76022b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/44 [02:36<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/44 [02:16<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/44 [01:47<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/44 [01:14<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23852"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model\n",
    "del trainer\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n",
    "import gc\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6ae14ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name      | Type              | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | encoder   | SwinTransformer3d | 27.9 M | train\n",
      "1 | decoder   | Sequential        | 5.3 M  | train\n",
      "2 | criterion | MSELoss           | 0      | train\n",
      "--------------------------------------------------------\n",
      "33.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "33.2 M    Total params\n",
      "132.653   Total estimated model params size (MB)\n",
      "183       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  11%|█▏        | 5/44 [00:05<00:40,  0.97it/s, v_num=122, train_loss=0.0254] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:48\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:599\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    593\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    595\u001b[0m     ckpt_path,\n\u001b[1;32m    596\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    597\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    598\u001b[0m )\n\u001b[0;32m--> 599\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1012\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m-> 1012\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1056\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:216\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:455\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 455\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:150\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:339\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[0;32m--> 339\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_callback_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_train_batch_end\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(trainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_train_batch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch_output, batch, batch_idx)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:227\u001b[0m, in \u001b[0;36m_call_callback_hooks\u001b[0;34m(trainer, hook_name, monitoring_callbacks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Callback]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcallback\u001b[38;5;241m.\u001b[39mstate_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 227\u001b[0m             \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pl_module:\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py:279\u001b[0m, in \u001b[0;36mTQDMProgressBar.on_train_batch_end\u001b[0;34m(self, trainer, pl_module, outputs, batch, batch_idx)\u001b[0m\n\u001b[1;32m    278\u001b[0m _update_n(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_progress_bar, n)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_progress_bar\u001b[38;5;241m.\u001b[39mset_postfix(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpl_module\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/callbacks/progress/progress_bar.py:198\u001b[0m, in \u001b[0;36mProgressBar.get_metrics\u001b[0;34m(self, trainer, pl_module)\u001b[0m\n\u001b[1;32m    197\u001b[0m standard_metrics \u001b[38;5;241m=\u001b[39m get_standard_metrics(trainer)\n\u001b[0;32m--> 198\u001b[0m pbar_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_bar_metrics\u001b[49m\n\u001b[1;32m    199\u001b[0m duplicates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(standard_metrics\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;241m&\u001b[39m pbar_metrics\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1667\u001b[0m, in \u001b[0;36mTrainer.progress_bar_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1661\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"The metrics sent to the progress bar.\u001b[39;00m\n\u001b[1;32m   1662\u001b[0m \n\u001b[1;32m   1663\u001b[0m \u001b[38;5;124;03mThis includes metrics logged via :meth:`~pytorch_lightning.core.LightningModule.log` with the\u001b[39;00m\n\u001b[1;32m   1664\u001b[0m \u001b[38;5;124;03m:paramref:`~pytorch_lightning.core.LightningModule.log.prog_bar` argument set.\u001b[39;00m\n\u001b[1;32m   1665\u001b[0m \n\u001b[1;32m   1666\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_logger_connector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_bar_metrics\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:254\u001b[0m, in \u001b[0;36m_LoggerConnector.progress_bar_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_results:\n\u001b[0;32m--> 254\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpbar\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_progress_bar_metrics\u001b[38;5;241m.\u001b[39mupdate(metrics)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:235\u001b[0m, in \u001b[0;36m_LoggerConnector.metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_results\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mon_step\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:493\u001b[0m, in \u001b[0;36m_ResultCollection.metrics\u001b[0;34m(self, on_step)\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result_metric\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mprog_bar:\n\u001b[0;32m--> 493\u001b[0m         metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpbar\u001b[39m\u001b[38;5;124m\"\u001b[39m][forked_name] \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_tensors_to_scalars\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metrics\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/lightning_fabric/utilities/apply_func.py:136\u001b[0m, in \u001b[0;36mconvert_tensors_to_scalars\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_to_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_item\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/lightning_utilities/core/apply_func.py:66\u001b[0m, in \u001b[0;36mapply_to_collection\u001b[0;34m(data, dtype, function, wrong_dtype, include_none, allow_frozen, *args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, dtype):  \u001b[38;5;66;03m# single element\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mlist\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, dtype) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data):  \u001b[38;5;66;03m# 1d homogeneous list\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/lightning_fabric/utilities/apply_func.py:134\u001b[0m, in \u001b[0;36mconvert_tensors_to_scalars.<locals>.to_item\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe metric `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` does not contain a single element, thus it cannot be converted to a scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    133\u001b[0m     )\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 99\u001b[0m\n\u001b[1;32m     91\u001b[0m model \u001b[38;5;241m=\u001b[39m MAEPretrainSwin()\n\u001b[1;32m     93\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m     94\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     95\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     96\u001b[0m     log_every_n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m     97\u001b[0m )\n\u001b[0;32m---> 99\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:561\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:65\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[1;32m     64\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[0;32m---> 65\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m     68\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torchvision.models.video import swin_transformer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "\n",
    "class MAEPretrainSwin(pl.LightningModule):\n",
    "    def __init__(self, lr=1e-4, mask_ratio=0.5):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.encoder = swin_transformer.swin3d_t(weights=None)\n",
    "        self.encoder.head = nn.Identity()\n",
    "\n",
    "        # Feature hook (grab feature before classification)\n",
    "        self.features = None\n",
    "        self.encoder.features[-1].register_forward_hook(self._hook)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv3d(768, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(256, 16, kernel_size=1)\n",
    "        )\n",
    "\n",
    "        self.criterion = nn.MSELoss()\n",
    "                \n",
    "            # ✅ Add this line\n",
    "        self.train_loss_history = []\n",
    "\n",
    "    def _hook(self, module, input, output):\n",
    "        # Save the last feature map for reconstruction\n",
    "        self.features = output  # shape: (B, T', H', W', C)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (B, 3, T, H, W)\n",
    "        B, C, T, H, W = x.shape\n",
    "        # Apply masking\n",
    "        mask = torch.rand(B, 1, T, H, W, device=x.device) < self.hparams.mask_ratio\n",
    "        x_masked = x.clone()\n",
    "        x_masked[mask.expand_as(x_masked)] = 0.0  # zero out masked regions\n",
    "        # Run encoder (Swin3D expects full input, so this is soft-masking)\n",
    "        # print(x.shape)\n",
    "        x = x.permute(0,2,1,3,4)\n",
    "        _ = self.encoder(x)\n",
    "        \n",
    "\n",
    "        # Hook saved the features\n",
    "        feat = self.features  # (B, T', H', W', C)\n",
    "        feat = feat.permute(0, 4, 1, 2, 3)  # → (B, C, T', H', W')\n",
    "        # Decode\n",
    "        recon = self.decoder(feat)\n",
    "        # print(recon.shape)\n",
    "        recon = nn.functional.interpolate(recon, size=(T, H, W), mode='trilinear', align_corners=False)\n",
    "\n",
    "        return recon, mask\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x,y = batch  # shape: (B, 3, T, H, W)\n",
    "        recon, mask = self(x)\n",
    "\n",
    "        # Compute loss only on masked parts\n",
    "        loss = self.criterion(recon[mask.expand_as(x)], x[mask.expand_as(x)])\n",
    "        self.train_loss_history.append(loss.item())  # ✅ Track loss here\n",
    "\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.hparams.lr)\n",
    "\n",
    "    def random_masking(self, x, ratio):\n",
    "        B, T, C, H, W = x.shape\n",
    "        x = x.view(B, T * H * W, C)\n",
    "        N = x.shape[1]\n",
    "        len_keep = int(N * (1 - ratio))\n",
    "\n",
    "        noise = torch.rand(B, N, device=x.device)\n",
    "        ids_shuffle = torch.argsort(noise, dim=1)\n",
    "        ids_keep = ids_shuffle[:, :len_keep]\n",
    "\n",
    "        x_masked = torch.gather(x, dim=1, index=ids_keep.unsqueeze(-1).expand(-1, -1, C))\n",
    "        return x_masked, ids_shuffle\n",
    "\n",
    "# Training Script\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    model = MAEPretrainSwin()\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=10,\n",
    "        accelerator='auto',\n",
    "        log_every_n_steps=20,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77291ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot training loss\n",
    "plt.plot(model.train_loss_history[10:])\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd739cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c068d56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccceb9c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9e32b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4b8cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 8 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=8)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name      | Type              | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | encoder   | SwinTransformer3d | 27.9 M | train\n",
      "1 | decoder   | Sequential        | 5.3 M  | train\n",
      "2 | criterion | MSELoss           | 0      | train\n",
      "--------------------------------------------------------\n",
      "33.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "33.2 M    Total params\n",
      "132.653   Total estimated model params size (MB)\n",
      "183       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/5 [00:00<?, ?it/s] "
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[2, 16, 32, 32, 3]' is invalid for input of size 9828",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 88\u001b[0m\n\u001b[1;32m     82\u001b[0m model \u001b[38;5;241m=\u001b[39m MAEPretrainSwin()\n\u001b[1;32m     83\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m     84\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     85\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     86\u001b[0m     log_every_n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m     87\u001b[0m )\n\u001b[0;32m---> 88\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:561\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:48\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     51\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:599\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    592\u001b[0m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    593\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    595\u001b[0m     ckpt_path,\n\u001b[1;32m    596\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    597\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    598\u001b[0m )\n\u001b[0;32m--> 599\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1012\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m-> 1012\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1056\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1055\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1056\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:216\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:455\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 455\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:150\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:320\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 320\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    322\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanual_optimization\u001b[38;5;241m.\u001b[39mrun(kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:192\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m         closure()\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:270\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_ready()\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_completed()\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:176\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    179\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/core/module.py:1302\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimizer_step\u001b[39m(\n\u001b[1;32m   1272\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1273\u001b[0m     epoch: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     optimizer_closure: Optional[Callable[[], Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1277\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;124;03m    the optimizer.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1300\u001b[0m \n\u001b[1;32m   1301\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1302\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py:154\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:239\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py:123\u001b[0m, in \u001b[0;36mPrecision.optimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[39;00m\n\u001b[1;32m    122\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/optim/optimizer.py:485\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    481\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    482\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m             )\n\u001b[0;32m--> 485\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/optim/optimizer.py:79\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 79\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/optim/adam.py:225\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 225\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m    228\u001b[0m     params_with_grad: \u001b[38;5;28mlist\u001b[39m[Tensor] \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py:109\u001b[0m, in \u001b[0;36mPrecision._wrap_closure\u001b[0;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_wrap_closure\u001b[39m(\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     98\u001b[0m     model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     99\u001b[0m     optimizer: Steppable,\n\u001b[1;32m    100\u001b[0m     closure: Callable[[], Any],\n\u001b[1;32m    101\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    102\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    hook is called.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m \n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m     closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer)\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m closure_result\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:146\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:131\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39menable_grad()\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ClosureResult:\n\u001b[0;32m--> 131\u001b[0m     step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarning_cache\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:319\u001b[0m, in \u001b[0;36m_AutomaticOptimization._training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Performs the actual train step with the tied hooks.\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \n\u001b[1;32m    310\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    315\u001b[0m \n\u001b[1;32m    316\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    317\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\n\u001b[0;32m--> 319\u001b[0m training_step_output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mpost_training_step()  \u001b[38;5;66;03m# unused hook - call anyway for backward compatibility\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training_step_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mworld_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:328\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 328\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    331\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:391\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 67\u001b[0m, in \u001b[0;36mMAEPretrainSwin.training_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtraining_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, batch_idx):\n\u001b[1;32m     66\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m batch  \u001b[38;5;66;03m# shape: (B, 3, T, H, W)\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m     recon, x_masked, ids_keep, ids_shuffle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# Compute loss only on masked parts\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(recon, x)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[5], line 50\u001b[0m, in \u001b[0;36mMAEPretrainSwin.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Apply random masking\u001b[39;00m\n\u001b[1;32m     49\u001b[0m x_masked, ids_keep, ids_shuffle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_masking(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39mmask_ratio)\n\u001b[0;32m---> 50\u001b[0m x_masked \u001b[38;5;241m=\u001b[39m \u001b[43mx_masked\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# (B, C, T, H, W)\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Run encoder\u001b[39;00m\n\u001b[1;32m     53\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x_masked)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[2, 16, 32, 32, 3]' is invalid for input of size 9828"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import pytorch_lightning as pl\n",
    "# from torchvision.models.video import swin_transformer\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "# import numpy as np\n",
    "\n",
    "# class MAEPretrainSwin(pl.LightningModule):\n",
    "#     def __init__(self, lr=1e-4, mask_ratio=0.9):\n",
    "#         super().__init__()\n",
    "#         self.save_hyperparameters()\n",
    "#         self.encoder = swin_transformer.swin3d_t(weights=None)\n",
    "#         self.encoder.head = nn.Identity()\n",
    "\n",
    "#         # Feature hook (grab feature before classification)\n",
    "#         self.features = None\n",
    "#         self.encoder.features[-1].register_forward_hook(self._hook)\n",
    "\n",
    "#         self.decoder = nn.Sequential(\n",
    "#             nn.Conv3d(768, 256, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv3d(256, 16, kernel_size=1)\n",
    "#         )\n",
    "#         self.criterion = nn.MSELoss()\n",
    "\n",
    "#     def _hook(self, module, input, output):\n",
    "#         # Save the last feature map for reconstruction\n",
    "#         self.features = output  # shape: (B, T', H', W', C)\n",
    "\n",
    "#     def random_masking(self, x, ratio):\n",
    "#         B, C, T, H, W = x.shape\n",
    "#         x = x.permute(0, 2, 3, 4, 1)  # (B, T, H, W, C)\n",
    "#         x = x.reshape(B, T * H * W, C)  # (B, N, C)\n",
    "#         N = x.shape[1]\n",
    "#         len_keep = int(N * (1 - ratio))\n",
    "\n",
    "#         noise = torch.rand(B, N, device=x.device)\n",
    "#         ids_shuffle = torch.argsort(noise, dim=1)\n",
    "#         ids_keep = ids_shuffle[:, :len_keep]\n",
    "\n",
    "#         x_masked = torch.gather(x, dim=1, index=ids_keep.unsqueeze(-1).expand(-1, -1, C))\n",
    "#         return x_masked, ids_keep, ids_shuffle\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # x shape: (B, 3, T, H, W)\n",
    "#         B, C, T, H, W = x.shape\n",
    "\n",
    "#         # Apply random masking\n",
    "#         x_masked, ids_keep, ids_shuffle = self.random_masking(x, self.hparams.mask_ratio)\n",
    "#         x_masked = x_masked.view(B, T, H, W, C).permute(0, 4, 1, 2, 3)  # (B, C, T, H, W)\n",
    "\n",
    "#         # Run encoder\n",
    "#         _ = self.encoder(x_masked)\n",
    "\n",
    "#         # Hook saved the features\n",
    "#         feat = self.features  # (B, T', H', W', C)\n",
    "#         feat = feat.permute(0, 4, 1, 2, 3)  # → (B, C, T', H', W')\n",
    "\n",
    "#         # Decode\n",
    "#         recon = self.decoder(feat)\n",
    "#         recon = nn.functional.interpolate(recon, size=(T, H, W), mode='trilinear', align_corners=False)\n",
    "\n",
    "#         return recon, x_masked, ids_keep, ids_shuffle\n",
    "\n",
    "#     def training_step(self, batch, batch_idx):\n",
    "#         x, y = batch  # shape: (B, 3, T, H, W)\n",
    "#         recon, x_masked, ids_keep, ids_shuffle = self(x)\n",
    "\n",
    "#         # Compute loss only on masked parts\n",
    "#         loss = self.criterion(recon, x)\n",
    "#         self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "#         return loss\n",
    "\n",
    "#     def configure_optimizers(self):\n",
    "#         return torch.optim.AdamW(self.parameters(), lr=self.hparams.lr)\n",
    "\n",
    "# # Training Script\n",
    "# # -----------------------------\n",
    "# if __name__ == \"__main__\":\n",
    "#     # dataset = DummyVideoDataset(num_samples=100, frames=16)\n",
    "#     # dataloader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "#     model = MAEPretrainSwin()\n",
    "#     trainer = pl.Trainer(\n",
    "#         max_epochs=10,\n",
    "#         accelerator='auto',\n",
    "#         log_every_n_steps=20,\n",
    "#     )\n",
    "#     trainer.fit(model, train_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f6d7b6",
   "metadata": {},
   "source": [
    "# NOT SYMMTIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c53c221",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/dion/lib/python3.10/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "Trainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name         | Type               | Params | Mode \n",
      "------------------------------------------------------------\n",
      "0 | patch_embed  | PatchEmbed3D       | 1.2 M  | train\n",
      "1 | encoder      | TransformerEncoder | 33.1 M | train\n",
      "2 | decoder      | Sequential         | 1.2 M  | train\n",
      "3 | criterion    | MSELoss            | 0      | train\n",
      "  | other params | n/a                | 768    | n/a  \n",
      "------------------------------------------------------------\n",
      "35.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "35.4 M    Total params\n",
      "141.785   Total estimated model params size (MB)\n",
      "67        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/ubuntu/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/50 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/dion/lib/python3.10/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([2, 1568, 768])) that is different to the input size (torch.Size([2, 1568, 1536])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1568, 768])\n",
      "torch.Size([2, 392, 768])\n",
      "torch.Size([2, 392, 768])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (1536) must match the size of tensor b (768) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 147\u001b[0m\n\u001b[1;32m    134\u001b[0m model \u001b[38;5;241m=\u001b[39m MAEPretrainVideo(\n\u001b[1;32m    135\u001b[0m     lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m,\n\u001b[1;32m    136\u001b[0m     mask_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.75\u001b[39m,\n\u001b[1;32m    137\u001b[0m     patch_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m16\u001b[39m),  \u001b[38;5;66;03m# (T, H, W)\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     embed_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m768\u001b[39m\n\u001b[1;32m    139\u001b[0m )\n\u001b[1;32m    141\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m    142\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m    143\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    144\u001b[0m     log_every_n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    145\u001b[0m )\n\u001b[0;32m--> 147\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:561\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:48\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     51\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:599\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    592\u001b[0m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    593\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    595\u001b[0m     ckpt_path,\n\u001b[1;32m    596\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    597\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    598\u001b[0m )\n\u001b[0;32m--> 599\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1012\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m-> 1012\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1056\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1055\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1056\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:216\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:455\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 455\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:150\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:320\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 320\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    322\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanual_optimization\u001b[38;5;241m.\u001b[39mrun(kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:192\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m         closure()\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:270\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_ready()\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_completed()\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:176\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    179\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/core/module.py:1302\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimizer_step\u001b[39m(\n\u001b[1;32m   1272\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1273\u001b[0m     epoch: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     optimizer_closure: Optional[Callable[[], Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1277\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;124;03m    the optimizer.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1300\u001b[0m \n\u001b[1;32m   1301\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1302\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py:154\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:239\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py:123\u001b[0m, in \u001b[0;36mPrecision.optimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[39;00m\n\u001b[1;32m    122\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/optim/optimizer.py:485\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    481\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    482\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m             )\n\u001b[0;32m--> 485\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/optim/optimizer.py:79\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 79\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/optim/adam.py:225\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 225\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m    228\u001b[0m     params_with_grad: \u001b[38;5;28mlist\u001b[39m[Tensor] \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py:109\u001b[0m, in \u001b[0;36mPrecision._wrap_closure\u001b[0;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_wrap_closure\u001b[39m(\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     98\u001b[0m     model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     99\u001b[0m     optimizer: Steppable,\n\u001b[1;32m    100\u001b[0m     closure: Callable[[], Any],\n\u001b[1;32m    101\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    102\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    hook is called.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m \n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m     closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer)\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m closure_result\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:146\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:131\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39menable_grad()\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ClosureResult:\n\u001b[0;32m--> 131\u001b[0m     step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarning_cache\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:319\u001b[0m, in \u001b[0;36m_AutomaticOptimization._training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Performs the actual train step with the tied hooks.\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \n\u001b[1;32m    310\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    315\u001b[0m \n\u001b[1;32m    316\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    317\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\n\u001b[0;32m--> 319\u001b[0m training_step_output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mpost_training_step()  \u001b[38;5;66;03m# unused hook - call anyway for backward compatibility\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training_step_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mworld_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:328\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 328\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    331\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:391\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 118\u001b[0m, in \u001b[0;36mMAEPretrainVideo.training_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    115\u001b[0m x \u001b[38;5;241m=\u001b[39m batch  \u001b[38;5;66;03m# (B, 3, T, H, W)\u001b[39;00m\n\u001b[1;32m    116\u001b[0m rec, target, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x)\n\u001b[0;32m--> 118\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss, prog_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: train_loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/nn/modules/loss.py:610\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 610\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/nn/functional.py:3884\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction, weight)\u001b[0m\n\u001b[1;32m   3881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3882\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3884\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3887\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weight\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/functional.py:77\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (1536) must match the size of tensor b (768) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ---------------------------\n",
    "# Dummy Video Dataset\n",
    "# ---------------------------\n",
    "class DummyVideoDataset(Dataset):\n",
    "    def __init__(self, num_samples=10, channels=3, frames=16, height=224, width=224):\n",
    "        self.num_samples = num_samples\n",
    "        self.shape = (channels, frames, height, width)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video = torch.rand(self.shape)\n",
    "        return video\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Patch Embedding for 3D (Video)\n",
    "# ---------------------------\n",
    "# class PatchEmbed3D(nn.Module):\n",
    "#     def __init__(self, patch_size=(2, 16, 16), in_chans=3, embed_dim=768):\n",
    "#         super().__init__()\n",
    "#         self.proj = nn.Conv3d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "#         self.patch_size = patch_size\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # x: (B, 3, T, H, W)\n",
    "#         x = self.proj(x)  # (B, D, T', H', W')\n",
    "#         x = x.flatten(2).transpose(1, 2)  # (B, N_patches, embed_dim)\n",
    "#         return x\n",
    "class PatchEmbed3D(nn.Module):\n",
    "    def __init__(self, patch_size=(2, 16, 16), in_chans=3, embed_dim=768):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv3d(\n",
    "            in_chans, embed_dim,\n",
    "            kernel_size=patch_size,\n",
    "            stride=patch_size\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)  # (B, embed_dim, T', H', W')\n",
    "        x = x.flatten(2).transpose(1, 2)  # (B, N, embed_dim)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# MAE Lightning Module\n",
    "# ---------------------------\n",
    "class MAEPretrainVideo(pl.LightningModule):\n",
    "    def __init__(self, lr=1e-4, mask_ratio=0.75, patch_size=(2, 16, 16), embed_dim=768):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.patch_embed = PatchEmbed3D(patch_size=patch_size, in_chans=3, embed_dim=embed_dim)\n",
    "\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=embed_dim, nhead=8),\n",
    "            num_layers=6\n",
    "        )\n",
    "        self.mask_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "\n",
    "        # self.mask_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        nn.init.normal_(self.mask_token, std=0.02)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(embed_dim, patch_size[0] * patch_size[1] * patch_size[2] * 3),\n",
    "        )\n",
    "\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.patch_dim = patch_size[0] * patch_size[1] * patch_size[2] * 3\n",
    "\n",
    "    def random_masking(self, x, mask_ratio):\n",
    "        B, N, D = x.shape\n",
    "        len_keep = int(N * (1 - mask_ratio))\n",
    "        noise = torch.rand(B, N, device=x.device)\n",
    "\n",
    "        ids_shuffle = torch.argsort(noise, dim=1)\n",
    "        ids_restore = torch.argsort(ids_shuffle, dim=1)\n",
    "\n",
    "        ids_keep = ids_shuffle[:, :len_keep]\n",
    "        x_visible = torch.gather(x, dim=1, index=ids_keep.unsqueeze(-1).expand(-1, -1, D))\n",
    "\n",
    "        return x_visible, ids_keep, ids_restore\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Step 1: Patchify\n",
    "        x_patches = self.patch_embed(x)  # (B, N, D)\n",
    "        print(x_patches.shape)\n",
    "\n",
    "        # Step 2: Random Masking\n",
    "        x_visible, ids_keep, ids_restore = self.random_masking(x_patches, self.hparams.mask_ratio)\n",
    "        print(x_visible.shape)\n",
    "        # Step 3: Encode only visible patches\n",
    "        x_encoded = self.encoder(x_visible)  # (B, N_vis, D)\n",
    "        print(x_encoded.shape)\n",
    "        # Step 4: Add mask tokens\n",
    "        B, N, D = x_patches.shape\n",
    "        mask_tokens = self.mask_token.expand(B, N - x_encoded.shape[1], -1)\n",
    "        x_combined = torch.cat([x_encoded, mask_tokens], dim=1)\n",
    "\n",
    "        # Step 5: Unshuffle to original order\n",
    "        x_decoder_input = torch.gather(x_combined, dim=1, index=ids_restore.unsqueeze(-1).expand(-1, -1, D))\n",
    "\n",
    "        # Step 6: Decode to patch pixels\n",
    "        x_rec = self.decoder(x_decoder_input)  # (B, N, patch_volume)\n",
    "        return x_rec, x_patches, ids_restore\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x = batch  # (B, 3, T, H, W)\n",
    "        rec, target, _ = self(x)\n",
    "\n",
    "        loss = self.criterion(rec, target)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        print(f\"Step {batch_idx}: train_loss = {loss.item():.6f}\")\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.hparams.lr)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Train the Model\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    dataset = DummyVideoDataset(num_samples=100, frames=16)\n",
    "    dataloader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "\n",
    "    model = MAEPretrainVideo(\n",
    "        lr=1e-4,\n",
    "        mask_ratio=0.75,\n",
    "        patch_size=(2, 16, 16),  # (T, H, W)\n",
    "        embed_dim=768\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=5,\n",
    "        accelerator='auto',\n",
    "        log_every_n_steps=1\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0032a817",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name         | Type              | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | encoder      | SwinTransformer3d | 27.9 M | train\n",
      "1 | decoder      | Sequential        | 1.2 M  | train\n",
      "2 | criterion    | MSELoss           | 0      | train\n",
      "  | other params | n/a               | 768    | n/a  \n",
      "-----------------------------------------------------------\n",
      "29.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "29.0 M    Total params\n",
      "116.130   Total estimated model params size (MB)\n",
      "181       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/ubuntu/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/50 [05:22<?, ?it/s] \n",
      "Epoch 0:   0%|          | 0/50 [04:09<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/50 [03:18<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/50 [02:51<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/50 [02:37<?, ?it/s]\n",
      "Step 0: train_loss = 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:48\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:599\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    593\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    595\u001b[0m     ckpt_path,\n\u001b[1;32m    596\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    597\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    598\u001b[0m )\n\u001b[0;32m--> 599\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1012\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m-> 1012\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1056\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:216\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:455\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 455\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:150\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:320\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 320\u001b[0m     batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:192\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:270\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:176\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/core/module.py:1302\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;124;03mthe optimizer.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1300\u001b[0m \n\u001b[1;32m   1301\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1302\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py:154\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:239\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py:123\u001b[0m, in \u001b[0;36mPrecision.optimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/optim/optimizer.py:485\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    482\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m             )\n\u001b[0;32m--> 485\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/optim/optimizer.py:79\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 79\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/optim/adam.py:225\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 225\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py:109\u001b[0m, in \u001b[0;36mPrecision._wrap_closure\u001b[0;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03mhook is called.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m \n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:146\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:140\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:241\u001b[0m, in \u001b[0;36m_AutomaticOptimization._make_backward_fn.<locals>.backward_fn\u001b[0;34m(loss)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbackward_fn\u001b[39m(loss: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 241\u001b[0m     \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbackward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:328\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 328\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:213\u001b[0m, in \u001b[0;36mStrategy.backward\u001b[0;34m(self, closure_loss, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m closure_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mpre_backward(closure_loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module)\n\u001b[0;32m--> 213\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m closure_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mpost_backward(closure_loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py:73\u001b[0m, in \u001b[0;36mPrecision.backward\u001b[0;34m(self, tensor, model, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs the actual backpropagation.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m \n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/core/module.py:1097\u001b[0m, in \u001b[0;36mLightningModule.backward\u001b[0;34m(self, loss, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1097\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/autograd/__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 160\u001b[0m\n\u001b[1;32m    148\u001b[0m model \u001b[38;5;241m=\u001b[39m MAEWithSwin3D(\n\u001b[1;32m    149\u001b[0m     lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m,\n\u001b[1;32m    150\u001b[0m     patch_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m16\u001b[39m),  \u001b[38;5;66;03m# time, height, width\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     mask_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.75\u001b[39m\n\u001b[1;32m    152\u001b[0m )\n\u001b[1;32m    154\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m    155\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    156\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    157\u001b[0m     log_every_n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    158\u001b[0m )\n\u001b[0;32m--> 160\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:561\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:65\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[1;32m     64\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[0;32m---> 65\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m     68\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models.video import swin_transformer\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Dummy Dataset\n",
    "# ---------------------------\n",
    "class DummyVideoDataset(Dataset):\n",
    "    def __init__(self, num_samples=100, channels=3, frames=16, height=224, width=224):\n",
    "        self.num_samples = num_samples\n",
    "        self.shape = (channels, frames, height, width)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video = torch.rand(self.shape)\n",
    "        return video\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# MAE + Swin3D Tube Encoder\n",
    "# ---------------------------\n",
    "class MAEWithSwin3D(pl.LightningModule):\n",
    "    def __init__(self, lr=1e-4, patch_size=(2, 16, 16), mask_ratio=0.75):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.encoder = swin_transformer.swin3d_t(weights=None)\n",
    "        self.encoder.head = nn.Identity()  # remove classifier\n",
    "        self.embed_dim = 768  # swin3d_t output\n",
    "\n",
    "        # Tube (patch) size\n",
    "        self.patch_size = patch_size\n",
    "        self.mask_ratio = mask_ratio\n",
    "        self.patch_dim = patch_size[0] * patch_size[1] * patch_size[2] * 3  # pixel dim of tube\n",
    "\n",
    "        # Mask token\n",
    "        self.mask_token = nn.Parameter(torch.zeros(1, self.embed_dim))\n",
    "        nn.init.normal_(self.mask_token, std=0.02)\n",
    "\n",
    "        # Decoder: embed → pixel patch\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(self.embed_dim, self.patch_dim)\n",
    "        )\n",
    "\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def patchify(self, video):\n",
    "        B, C, T, H, W = video.shape\n",
    "        pt, ph, pw = self.patch_size\n",
    "        assert T % pt == 0 and H % ph == 0 and W % pw == 0\n",
    "\n",
    "        video = video.view(\n",
    "            B, C,\n",
    "            T // pt, pt,\n",
    "            H // ph, ph,\n",
    "            W // pw, pw\n",
    "        )  # (B, C, T', pt, H', ph, W', pw)\n",
    "\n",
    "        video = video.permute(0, 2, 4, 6, 1, 3, 5, 7)  # (B, T', H', W', C, pt, ph, pw)\n",
    "        patches = video.reshape(B, -1, C, pt, ph, pw)  # (B, N, C, pt, ph, pw)\n",
    "        return patches\n",
    "\n",
    "    def unpatchify(self, patches, original_shape):\n",
    "        B, N, C, pt, ph, pw = patches.shape\n",
    "        _, _, T, H, W = original_shape\n",
    "        T_ = T // pt\n",
    "        H_ = H // ph\n",
    "        W_ = W // pw\n",
    "\n",
    "        patches = patches.view(B, T_, H_, W_, C, pt, ph, pw)\n",
    "        patches = patches.permute(0, 4, 1, 5, 2, 6, 3, 7)\n",
    "        video = patches.reshape(B, C, T, H, W)\n",
    "        return video\n",
    "\n",
    "    def random_masking(self, N, device):\n",
    "        len_keep = int(N * (1 - self.mask_ratio))\n",
    "        noise = torch.rand(N, device=device)\n",
    "        ids_shuffle = torch.argsort(noise)\n",
    "        ids_keep = ids_shuffle[:len_keep]\n",
    "        ids_mask = ids_shuffle[len_keep:]\n",
    "        return ids_keep, ids_mask\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, T, H, W = x.shape\n",
    "        patches = self.patchify(x)  # (B, N, C, pt, ph, pw)\n",
    "        B, N, C, pt, ph, pw = patches.shape\n",
    "\n",
    "        rec_patches = torch.zeros(B, N, C, pt, ph, pw, device=x.device)\n",
    "        mask_flags = torch.zeros(B, N, device=x.device)\n",
    "\n",
    "        for b in range(B):\n",
    "            ids_keep, ids_mask = self.random_masking(N, x.device)\n",
    "            visible_patches = patches[b, ids_keep]  # (N_vis, C, pt, ph, pw)\n",
    "\n",
    "            # Encode each visible patch with Swin3D\n",
    "            vis_recon = []\n",
    "            for tube in visible_patches:\n",
    "                tube = tube.unsqueeze(0)  # (1, C, pt, ph, pw)\n",
    "                emb = self.encoder(tube)  # (1, embed_dim)\n",
    "                rec = self.decoder(emb)  # (1, patch_dim)\n",
    "                rec = rec.view(C, pt, ph, pw)\n",
    "                vis_recon.append(rec)\n",
    "\n",
    "            vis_recon = torch.stack(vis_recon)  # (N_vis, C, pt, ph, pw)\n",
    "            rec_patches[b, ids_mask] = patches[b, ids_mask]  # keep ground truth\n",
    "            rec_patches[b, ids_keep] = vis_recon  # set recon\n",
    "            mask_flags[b, ids_mask] = 1  # mark for loss\n",
    "\n",
    "        return rec_patches, patches, mask_flags\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x = batch  # (B, 3, T, H, W)\n",
    "        recon_patches, target_patches, mask_flags = self(x)\n",
    "\n",
    "        # Compute loss only on masked patches\n",
    "        B, N = mask_flags.shape\n",
    "        loss = 0\n",
    "        count = 0\n",
    "        for b in range(B):\n",
    "            mask = mask_flags[b] == 1\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "            loss += self.criterion(\n",
    "                recon_patches[b, mask], target_patches[b, mask]\n",
    "            )\n",
    "            count += 1\n",
    "        loss = loss / max(count, 1)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        print(f\"Step {batch_idx}: train_loss = {loss.item():.6f}\")\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.hparams.lr)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Train Script\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    dataset = DummyVideoDataset(num_samples=100, frames=16)\n",
    "    dataloader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "\n",
    "    model = MAEWithSwin3D(\n",
    "        lr=1e-4,\n",
    "        patch_size=(2, 16, 16),  # time, height, width\n",
    "        mask_ratio=0.75\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=2,\n",
    "        accelerator='auto',\n",
    "        log_every_n_steps=1\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e0096d",
   "metadata": {},
   "source": [
    "# HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca363848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading frag5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00, 11.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shape of frag5 segment: (3696, 2352, 16)\n",
      "(3696, 2352)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torchvision.models.video import swin_transformer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import utils\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "class CFG:\n",
    "    # ============== comp exp name =============\n",
    "    current_dir = './'\n",
    "    segment_path = './train_scrolls/'\n",
    "    \n",
    "    start_idx = 24\n",
    "    in_chans = 16\n",
    "    \n",
    "    size = 224\n",
    "    tile_size = 224\n",
    "    stride = tile_size // 8 \n",
    "    \n",
    "    train_batch_size =  10 # 32\n",
    "    valid_batch_size = 10\n",
    "    \n",
    "    lr = 1e-4\n",
    "    num_workers = 8\n",
    "    # ============== model cfg =============\n",
    "    scheduler = 'linear' # 'cosine', 'linear'\n",
    "    epochs = 30\n",
    "    warmup_factor = 10\n",
    "    \n",
    "    # Size of fragments\n",
    "    frags_ratio1 = [\"rem\",'rect','frag']\n",
    "    frags_ratio2 = ['nothing']\n",
    "    ratio1 = 2\n",
    "    ratio2 = 1\n",
    "    \n",
    "    # ============== fold =============\n",
    "    segments = ['frag5',\"rect5\"] \n",
    "    valid_id = 'frag5'\n",
    "    # ============== fixed =============\n",
    "    min_lr = 1e-7\n",
    "    weight_decay = 1e-6\n",
    "    max_grad_norm = 100\n",
    "    num_workers = 8\n",
    "    seed = 0\n",
    "    \n",
    "        # ============== augmentation =============\n",
    "    train_aug_list = [\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.75),\n",
    "        A.ShiftScaleRotate(rotate_limit=360,shift_limit=0.15,scale_limit=0.15,p=0.75),\n",
    "        A.OneOf([\n",
    "                A.GaussNoise(var_limit=[10, 50]),\n",
    "                A.GaussianBlur(),\n",
    "                A.MotionBlur(),\n",
    "                ], p=0.4),\n",
    "        A.CoarseDropout(max_holes=2, max_width=int(size * 0.2), max_height=int(size * 0.2), \n",
    "                        mask_fill_value=0, p=0.5),\n",
    "        A.Normalize(\n",
    "            mean= [0] * in_chans,\n",
    "            std= [1] * in_chans\n",
    "        ),\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "\n",
    "    valid_aug_list = [\n",
    "        A.Normalize(\n",
    "            mean= [0] * in_chans,\n",
    "            std= [1] * in_chans\n",
    "        ),\n",
    "        ToTensorV2(transpose_mask=True),  \n",
    "    ]\n",
    "\n",
    "train_images, train_masks, valid_images, valid_masks, valid_xyxys = utils.get_train_valid_dataset(CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "39989519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(data, cfg):\n",
    "    if data == 'train':\n",
    "        aug = A.Compose(cfg.train_aug_list)\n",
    "    elif data == 'valid':\n",
    "        aug = A.Compose(cfg.valid_aug_list)\n",
    "    return aug  \n",
    "from models import swin\n",
    "train_dataset = swin.TimesformerDataset(\n",
    "    valid_images[:100], CFG, labels=valid_masks, transform=get_transforms(data='valid', cfg=CFG))\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                            batch_size=CFG.train_batch_size,\n",
    "                            shuffle=True,\n",
    "                            num_workers=CFG.num_workers, pin_memory=True, drop_last=True,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4d0b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name      | Type              | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | encoder   | SwinTransformer3d | 27.9 M | train\n",
      "1 | decoder   | Sequential        | 2.7 M  | train\n",
      "2 | criterion | MSELoss           | 0      | train\n",
      "--------------------------------------------------------\n",
      "30.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "30.5 M    Total params\n",
      "122.023   Total estimated model params size (MB)\n",
      "183       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/10 [00:00<?, ?it/s] "
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 86\u001b[0m\n\u001b[1;32m     77\u001b[0m model \u001b[38;5;241m=\u001b[39m MAEPretrainSwin(mask_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.\u001b[39m)\n\u001b[1;32m     79\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m     80\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m     81\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     82\u001b[0m     logger\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     83\u001b[0m     enable_checkpointing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     84\u001b[0m )\n\u001b[0;32m---> 86\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:561\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:48\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     51\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:599\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    592\u001b[0m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    593\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    595\u001b[0m     ckpt_path,\n\u001b[1;32m    596\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    597\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    598\u001b[0m )\n\u001b[0;32m--> 599\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1012\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m-> 1012\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1056\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1055\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1056\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:216\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:455\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 455\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:150\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:320\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 320\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    322\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanual_optimization\u001b[38;5;241m.\u001b[39mrun(kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:192\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m         closure()\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:270\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_ready()\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_completed()\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:176\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    179\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/core/module.py:1302\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimizer_step\u001b[39m(\n\u001b[1;32m   1272\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1273\u001b[0m     epoch: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     optimizer_closure: Optional[Callable[[], Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1277\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;124;03m    the optimizer.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1300\u001b[0m \n\u001b[1;32m   1301\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1302\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py:154\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:239\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py:123\u001b[0m, in \u001b[0;36mPrecision.optimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[39;00m\n\u001b[1;32m    122\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/optim/optimizer.py:485\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    481\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    482\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m             )\n\u001b[0;32m--> 485\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/optim/optimizer.py:79\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 79\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/optim/adam.py:225\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 225\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m    228\u001b[0m     params_with_grad: \u001b[38;5;28mlist\u001b[39m[Tensor] \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py:109\u001b[0m, in \u001b[0;36mPrecision._wrap_closure\u001b[0;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_wrap_closure\u001b[39m(\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     98\u001b[0m     model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     99\u001b[0m     optimizer: Steppable,\n\u001b[1;32m    100\u001b[0m     closure: Callable[[], Any],\n\u001b[1;32m    101\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    102\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    hook is called.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m \n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m     closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer)\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m closure_result\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:146\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:131\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39menable_grad()\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ClosureResult:\n\u001b[0;32m--> 131\u001b[0m     step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarning_cache\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:319\u001b[0m, in \u001b[0;36m_AutomaticOptimization._training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Performs the actual train step with the tied hooks.\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \n\u001b[1;32m    310\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    315\u001b[0m \n\u001b[1;32m    316\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    317\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\n\u001b[0;32m--> 319\u001b[0m training_step_output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mpost_training_step()  \u001b[38;5;66;03m# unused hook - call anyway for backward compatibility\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training_step_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mworld_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:328\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 328\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    331\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:391\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[50], line 65\u001b[0m, in \u001b[0;36mMAEPretrainSwin.training_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtraining_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, batch_idx):\n\u001b[1;32m     64\u001b[0m     x \u001b[38;5;241m=\u001b[39m batch  \u001b[38;5;66;03m# (B, 3, T, H, W)\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m     recon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(recon, x)\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Step \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[50], line 56\u001b[0m, in \u001b[0;36mMAEPretrainSwin.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 56\u001b[0m     x_masked \u001b[38;5;241m=\u001b[39m \u001b[43mmask_video_patches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask_ratio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x_masked)\n\u001b[1;32m     58\u001b[0m     feat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# (B, C, T', H', W')\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[50], line 14\u001b[0m, in \u001b[0;36mmask_video_patches\u001b[0;34m(x, patch_size, mask_ratio)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmask_video_patches\u001b[39m(x, patch_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m16\u001b[39m,\u001b[38;5;241m16\u001b[39m), mask_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.75\u001b[39m):\n\u001b[0;32m---> 14\u001b[0m     B, C, T, H, W \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     15\u001b[0m     pt, ph, pw \u001b[38;5;241m=\u001b[39m patch_size\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m T \u001b[38;5;241m%\u001b[39m pt \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m H \u001b[38;5;241m%\u001b[39m ph \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m W \u001b[38;5;241m%\u001b[39m pw \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVideo must divide evenly by patch size\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/_tensor.py:1225\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# class DummyVideoDataset(Dataset):\n",
    "#     def __init__(self, num_samples=10, channels=3, frames=16, height=224, width=224):\n",
    "#         self.num_samples = num_samples\n",
    "#         self.shape = (channels, frames, height, width)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.num_samples\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         video = torch.rand(self.shape)  # (C, T, H, W)\n",
    "#         return video\n",
    "\n",
    "def mask_video_patches(x, patch_size=(2,16,16), mask_ratio=0.75):\n",
    "    B, C, T, H, W = x.shape\n",
    "    pt, ph, pw = patch_size\n",
    "    assert T % pt == 0 and H % ph == 0 and W % pw == 0, \"Video must divide evenly by patch size\"\n",
    "    nt, nh, nw = T // pt, H // ph, W // pw\n",
    "    num_patches = nt * nh * nw\n",
    "    len_keep = int(num_patches * (1 - mask_ratio))\n",
    "\n",
    "    noise = torch.rand(B, num_patches, device=x.device)\n",
    "    ids_shuffle = torch.argsort(noise, dim=1)\n",
    "    ids_keep = ids_shuffle[:, :len_keep]\n",
    "\n",
    "    mask = torch.zeros(B, num_patches, device=x.device)\n",
    "    mask.scatter_(1, ids_keep, 1)\n",
    "\n",
    "    mask = mask.view(B, nt, nh, nw, 1, 1, 1).expand(-1, -1, -1, -1, pt, ph, pw)\n",
    "    mask = mask.reshape(B, 1, T, H, W)\n",
    "    x_masked = x * mask\n",
    "    return x_masked\n",
    "\n",
    "class MAEPretrainSwin(pl.LightningModule):\n",
    "    def __init__(self, lr=1e-5, mask_ratio=0.75):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.encoder = swin_transformer.swin3d_t(weights=\"KINETICS400_V1\")\n",
    "        self.encoder.head = nn.Identity()\n",
    "\n",
    "        self.features = None\n",
    "        self.encoder.features[-1].register_forward_hook(self._hook)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv3d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(256, 3, kernel_size=1)\n",
    "        )\n",
    "\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def _hook(self, module, input, output):\n",
    "        self.features = output  # (B, T', H', W', C)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_masked = mask_video_patches(x, patch_size=(2,16,16), mask_ratio=self.hparams.mask_ratio)\n",
    "        _ = self.encoder(x_masked)\n",
    "        feat = self.features.permute(0, 4, 1, 2, 3)  # (B, C, T', H', W')\n",
    "        recon = self.decoder(feat)\n",
    "        recon = nn.functional.interpolate(recon, size=x.shape[2:], mode='trilinear', align_corners=False)\n",
    "        return recon\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x = batch  # (B, 3, T, H, W)\n",
    "        recon = self(x)\n",
    "        loss = self.criterion(recon, x)\n",
    "        print(f\"Epoch {self.current_epoch} | Step {batch_idx} | Loss: {loss.item():.4f}\")\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.hparams.lr)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset = train_dataset#DummyVideoDataset(num_samples=5)  # Small set to test overfitting\n",
    "    dataloader = train_loader#DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "    model = MAEPretrainSwin(mask_ratio=0.)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=100,\n",
    "        accelerator='auto',\n",
    "        logger=False,\n",
    "        enable_checkpointing=False,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb6c5b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "017f5135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0566,  0.3355,  0.1786,  ..., -1.2331, -1.1111,  0.8758],\n",
      "          [ 0.9455,  1.3290,  0.7364,  ...,  1.1547,  0.1089, -0.0479],\n",
      "          [ 0.6144,  0.1612,  1.5033,  ..., -0.1874,  0.4052,  0.0392],\n",
      "          ...,\n",
      "          [-1.0588,  1.5556,  0.7364,  ...,  0.5447,  2.2004, -0.4314],\n",
      "          [ 0.4749,  0.9630,  0.7887,  ..., -0.7800,  1.8693,  1.7298],\n",
      "          [ 0.8758, -0.1351, -0.9717,  ...,  0.5621,  0.2832,  0.5447]],\n",
      "\n",
      "         [[ 0.0566,  0.3355,  0.1786,  ..., -1.2331, -1.1111,  0.8758],\n",
      "          [ 0.9455,  1.3290,  0.7364,  ...,  1.1547,  0.1089, -0.0479],\n",
      "          [ 0.6144,  0.1612,  1.5033,  ..., -0.1874,  0.4052,  0.0392],\n",
      "          ...,\n",
      "          [-1.0588,  1.5556,  0.7364,  ...,  0.5447,  2.2004, -0.4314],\n",
      "          [ 0.4749,  0.9630,  0.7887,  ..., -0.7800,  1.8693,  1.7298],\n",
      "          [ 0.8758, -0.1351, -0.9717,  ...,  0.5621,  0.2832,  0.5447]],\n",
      "\n",
      "         [[ 0.0566,  0.3355,  0.1786,  ..., -1.2331, -1.1111,  0.8758],\n",
      "          [ 0.9455,  1.3290,  0.7364,  ...,  1.1547,  0.1089, -0.0479],\n",
      "          [ 0.6144,  0.1612,  1.5033,  ..., -0.1874,  0.4052,  0.0392],\n",
      "          ...,\n",
      "          [-1.0588,  1.5556,  0.7364,  ...,  0.5447,  2.2004, -0.4314],\n",
      "          [ 0.4749,  0.9630,  0.7887,  ..., -0.7800,  1.8693,  1.7298],\n",
      "          [ 0.8758, -0.1351, -0.9717,  ...,  0.5621,  0.2832,  0.5447]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3181, -1.2331,  1.9216,  ...,  0.1786, -0.3268, -1.3028],\n",
      "          [ 0.2658,  0.0218,  0.8061,  ...,  0.1786,  1.8519,  0.0392],\n",
      "          [ 0.5447,  1.3813,  1.1198,  ...,  0.6667, -0.8671, -0.7800],\n",
      "          ...,\n",
      "          [ 1.2593, -0.7974,  0.5272,  ...,  1.2418,  1.4336,  0.9107],\n",
      "          [ 1.5556,  0.5447, -0.1176,  ..., -0.1002, -0.7277,  0.4575],\n",
      "          [ 0.1961,  0.3704, -1.0414,  ..., -0.5185,  1.7298, -0.8322]],\n",
      "\n",
      "         [[ 0.3181, -1.2331,  1.9216,  ...,  0.1786, -0.3268, -1.3028],\n",
      "          [ 0.2658,  0.0218,  0.8061,  ...,  0.1786,  1.8519,  0.0392],\n",
      "          [ 0.5447,  1.3813,  1.1198,  ...,  0.6667, -0.8671, -0.7800],\n",
      "          ...,\n",
      "          [ 1.2593, -0.7974,  0.5272,  ...,  1.2418,  1.4336,  0.9107],\n",
      "          [ 1.5556,  0.5447, -0.1176,  ..., -0.1002, -0.7277,  0.4575],\n",
      "          [ 0.1961,  0.3704, -1.0414,  ..., -0.5185,  1.7298, -0.8322]],\n",
      "\n",
      "         [[ 0.3181, -1.2331,  1.9216,  ...,  0.1786, -0.3268, -1.3028],\n",
      "          [ 0.2658,  0.0218,  0.8061,  ...,  0.1786,  1.8519,  0.0392],\n",
      "          [ 0.5447,  1.3813,  1.1198,  ...,  0.6667, -0.8671, -0.7800],\n",
      "          ...,\n",
      "          [ 1.2593, -0.7974,  0.5272,  ...,  1.2418,  1.4336,  0.9107],\n",
      "          [ 1.5556,  0.5447, -0.1176,  ..., -0.1002, -0.7277,  0.4575],\n",
      "          [ 0.1961,  0.3704, -1.0414,  ..., -0.5185,  1.7298, -0.8322]]],\n",
      "\n",
      "\n",
      "        [[[-0.8148,  0.4052, -0.8671,  ..., -1.1285,  0.6492,  2.0087],\n",
      "          [-1.4597,  1.2418, -1.1460,  ...,  1.5904, -1.3377,  1.2593],\n",
      "          [-1.1808,  1.1547,  0.7712,  ...,  1.3638,  0.7538, -1.3203],\n",
      "          ...,\n",
      "          [ 0.5447, -1.0588,  1.4510,  ...,  1.9216,  1.3638,  0.5272],\n",
      "          [-0.1525,  1.2593,  0.9107,  ..., -1.0414,  1.8344,  0.1438],\n",
      "          [-0.6231,  1.4510,  0.2832,  ..., -0.3094,  1.0501,  0.2309]],\n",
      "\n",
      "         [[-0.8148,  0.4052, -0.8671,  ..., -1.1285,  0.6492,  2.0087],\n",
      "          [-1.4597,  1.2418, -1.1460,  ...,  1.5904, -1.3377,  1.2593],\n",
      "          [-1.1808,  1.1547,  0.7712,  ...,  1.3638,  0.7538, -1.3203],\n",
      "          ...,\n",
      "          [ 0.5447, -1.0588,  1.4510,  ...,  1.9216,  1.3638,  0.5272],\n",
      "          [-0.1525,  1.2593,  0.9107,  ..., -1.0414,  1.8344,  0.1438],\n",
      "          [-0.6231,  1.4510,  0.2832,  ..., -0.3094,  1.0501,  0.2309]],\n",
      "\n",
      "         [[-0.8148,  0.4052, -0.8671,  ..., -1.1285,  0.6492,  2.0087],\n",
      "          [-1.4597,  1.2418, -1.1460,  ...,  1.5904, -1.3377,  1.2593],\n",
      "          [-1.1808,  1.1547,  0.7712,  ...,  1.3638,  0.7538, -1.3203],\n",
      "          ...,\n",
      "          [ 0.5447, -1.0588,  1.4510,  ...,  1.9216,  1.3638,  0.5272],\n",
      "          [-0.1525,  1.2593,  0.9107,  ..., -1.0414,  1.8344,  0.1438],\n",
      "          [-0.6231,  1.4510,  0.2832,  ..., -0.3094,  1.0501,  0.2309]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.6492, -0.4314,  1.3115,  ...,  0.8758,  0.4401,  0.9455],\n",
      "          [-0.1699,  0.6318,  1.7996,  ...,  0.7887, -1.0937, -1.1460],\n",
      "          [-0.2222, -0.5534,  1.0501,  ..., -0.5882, -0.2919,  1.2070],\n",
      "          ...,\n",
      "          [ 0.6144,  0.7364, -0.4837,  ...,  0.2309, -0.0305,  0.8932],\n",
      "          [ 0.5272, -0.2745, -0.6754,  ...,  0.6667, -0.1351,  0.5795],\n",
      "          [ 0.0044, -1.3900,  0.3704,  ...,  0.0044, -0.9194,  0.7887]],\n",
      "\n",
      "         [[ 0.6492, -0.4314,  1.3115,  ...,  0.8758,  0.4401,  0.9455],\n",
      "          [-0.1699,  0.6318,  1.7996,  ...,  0.7887, -1.0937, -1.1460],\n",
      "          [-0.2222, -0.5534,  1.0501,  ..., -0.5882, -0.2919,  1.2070],\n",
      "          ...,\n",
      "          [ 0.6144,  0.7364, -0.4837,  ...,  0.2309, -0.0305,  0.8932],\n",
      "          [ 0.5272, -0.2745, -0.6754,  ...,  0.6667, -0.1351,  0.5795],\n",
      "          [ 0.0044, -1.3900,  0.3704,  ...,  0.0044, -0.9194,  0.7887]],\n",
      "\n",
      "         [[ 0.6492, -0.4314,  1.3115,  ...,  0.8758,  0.4401,  0.9455],\n",
      "          [-0.1699,  0.6318,  1.7996,  ...,  0.7887, -1.0937, -1.1460],\n",
      "          [-0.2222, -0.5534,  1.0501,  ..., -0.5882, -0.2919,  1.2070],\n",
      "          ...,\n",
      "          [ 0.6144,  0.7364, -0.4837,  ...,  0.2309, -0.0305,  0.8932],\n",
      "          [ 0.5272, -0.2745, -0.6754,  ...,  0.6667, -0.1351,  0.5795],\n",
      "          [ 0.0044, -1.3900,  0.3704,  ...,  0.0044, -0.9194,  0.7887]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0392, -0.3965, -0.6405,  ...,  0.6318, -0.9542, -0.4488],\n",
      "          [ 0.5621,  0.8410,  0.3878,  ...,  1.6776,  1.1024,  2.0610],\n",
      "          [-0.6928,  1.0153,  1.0675,  ...,  0.5447,  0.2309, -0.7102],\n",
      "          ...,\n",
      "          [-1.6688, -0.5534,  0.3878,  ..., -0.3791,  0.5621,  2.2179],\n",
      "          [ 0.0915,  1.1895, -0.1525,  ...,  0.3704,  1.4684,  1.4684],\n",
      "          [ 0.1438, -0.5359, -0.3094,  ...,  1.1373, -0.2397,  0.4401]],\n",
      "\n",
      "         [[ 0.0392, -0.3965, -0.6405,  ...,  0.6318, -0.9542, -0.4488],\n",
      "          [ 0.5621,  0.8410,  0.3878,  ...,  1.6776,  1.1024,  2.0610],\n",
      "          [-0.6928,  1.0153,  1.0675,  ...,  0.5447,  0.2309, -0.7102],\n",
      "          ...,\n",
      "          [-1.6688, -0.5534,  0.3878,  ..., -0.3791,  0.5621,  2.2179],\n",
      "          [ 0.0915,  1.1895, -0.1525,  ...,  0.3704,  1.4684,  1.4684],\n",
      "          [ 0.1438, -0.5359, -0.3094,  ...,  1.1373, -0.2397,  0.4401]],\n",
      "\n",
      "         [[ 0.0392, -0.3965, -0.6405,  ...,  0.6318, -0.9542, -0.4488],\n",
      "          [ 0.5621,  0.8410,  0.3878,  ...,  1.6776,  1.1024,  2.0610],\n",
      "          [-0.6928,  1.0153,  1.0675,  ...,  0.5447,  0.2309, -0.7102],\n",
      "          ...,\n",
      "          [-1.6688, -0.5534,  0.3878,  ..., -0.3791,  0.5621,  2.2179],\n",
      "          [ 0.0915,  1.1895, -0.1525,  ...,  0.3704,  1.4684,  1.4684],\n",
      "          [ 0.1438, -0.5359, -0.3094,  ...,  1.1373, -0.2397,  0.4401]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8932,  0.6667,  1.1721,  ...,  0.6841, -0.7102,  0.1786],\n",
      "          [-0.6754, -0.1525,  0.0044,  ...,  0.3181, -0.7451, -0.7800],\n",
      "          [-0.5882, -0.2048, -1.1983,  ..., -1.4074, -0.1699,  0.2658],\n",
      "          ...,\n",
      "          [-0.3094,  0.0915,  0.1264,  ...,  1.8170,  1.5207,  0.2832],\n",
      "          [-0.3094, -0.2397, -0.9194,  ..., -0.0654, -0.8845, -0.3617],\n",
      "          [ 0.0218, -1.2505,  1.2070,  ..., -0.7625,  1.2244, -0.8497]],\n",
      "\n",
      "         [[ 0.8932,  0.6667,  1.1721,  ...,  0.6841, -0.7102,  0.1786],\n",
      "          [-0.6754, -0.1525,  0.0044,  ...,  0.3181, -0.7451, -0.7800],\n",
      "          [-0.5882, -0.2048, -1.1983,  ..., -1.4074, -0.1699,  0.2658],\n",
      "          ...,\n",
      "          [-0.3094,  0.0915,  0.1264,  ...,  1.8170,  1.5207,  0.2832],\n",
      "          [-0.3094, -0.2397, -0.9194,  ..., -0.0654, -0.8845, -0.3617],\n",
      "          [ 0.0218, -1.2505,  1.2070,  ..., -0.7625,  1.2244, -0.8497]],\n",
      "\n",
      "         [[ 0.8932,  0.6667,  1.1721,  ...,  0.6841, -0.7102,  0.1786],\n",
      "          [-0.6754, -0.1525,  0.0044,  ...,  0.3181, -0.7451, -0.7800],\n",
      "          [-0.5882, -0.2048, -1.1983,  ..., -1.4074, -0.1699,  0.2658],\n",
      "          ...,\n",
      "          [-0.3094,  0.0915,  0.1264,  ...,  1.8170,  1.5207,  0.2832],\n",
      "          [-0.3094, -0.2397, -0.9194,  ..., -0.0654, -0.8845, -0.3617],\n",
      "          [ 0.0218, -1.2505,  1.2070,  ..., -0.7625,  1.2244, -0.8497]]]])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 5, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 37\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Preprocess\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# video_np = pixel_values.numpy()\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# processed = processor(list(video_np), return_tensors=\"pt\")\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Run through model to get patch embeddings\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 37\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state  \u001b[38;5;66;03m# [1, num_patches+1, hidden_dim]\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbeddings shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membeddings\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# [1, num_tokens, 768]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/transformers/models/timesformer/modeling_timesformer.py:596\u001b[0m, in \u001b[0;36mTimesformerModel.forward\u001b[0;34m(self, pixel_values, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    591\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    592\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[1;32m    593\u001b[0m )\n\u001b[1;32m    594\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 596\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    598\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m    599\u001b[0m     embedding_output,\n\u001b[1;32m    600\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    601\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m    602\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m    603\u001b[0m )\n\u001b[1;32m    604\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/transformers/models/timesformer/modeling_timesformer.py:98\u001b[0m, in \u001b[0;36mTimesformerEmbeddings.forward\u001b[0;34m(self, pixel_values)\u001b[0m\n\u001b[1;32m     95\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m pixel_values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# create patch embeddings\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m embeddings, num_frames, patch_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m cls_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcls_token\u001b[38;5;241m.\u001b[39mexpand(embeddings\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    101\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((cls_tokens, embeddings), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/transformers/models/timesformer/modeling_timesformer.py:60\u001b[0m, in \u001b[0;36mTimesformerPatchEmbeddings.forward\u001b[0;34m(self, pixel_values)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, pixel_values):\n\u001b[0;32m---> 60\u001b[0m     batch_size, num_frames, num_channels, height, width \u001b[38;5;241m=\u001b[39m pixel_values\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     61\u001b[0m     pixel_values \u001b[38;5;241m=\u001b[39m pixel_values\u001b[38;5;241m.\u001b[39mreshape(batch_size \u001b[38;5;241m*\u001b[39m num_frames, num_channels, height, width)\n\u001b[1;32m     63\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojection(pixel_values)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 5, got 4)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoImageProcessor, TimesformerModel\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# Convert to PIL and then to 3 channels\n",
    "pil_transform = T.Compose([\n",
    "    T.ToPILImage(),                    # convert (C, H, W) to PIL\n",
    "    T.Grayscale(num_output_channels=3),  # convert to 3 channels\n",
    "])\n",
    "\n",
    "# from transformers import TimeSformerModel, TimeSformerConfig, TimeSformerImageProcessor\n",
    "import numpy as np\n",
    "\n",
    "# Load pretrained TimeSformer\n",
    "model = TimesformerModel.from_pretrained(\"facebook/timesformer-hr-finetuned-k600\")\n",
    "processor = AutoImageProcessor.from_pretrained(\"facebook/timesformer-base-finetuned-k400\")\n",
    "\n",
    "# Dummy video tensor: shape [batch, num_frames, height, width, channels]\n",
    "video = torch.rand(3,8, 224, 224)  # 8 frames of 224x224 RGB\n",
    "\n",
    "image = video.permute(1,0,2,3)\n",
    "frames = [pil_transform(frame.squeeze(0)) for frame in image] \n",
    "\n",
    "encoding = processor(\n",
    "    [frame for frame in frames],   # list of PIL\n",
    "    return_tensors='pt'\n",
    "    )\n",
    "processed = encoding[\"pixel_values\"].squeeze(0)\n",
    "print(processed)\n",
    "\n",
    "# Preprocess\n",
    "# video_np = pixel_values.numpy()\n",
    "# processed = processor(list(video_np), return_tensors=\"pt\")\n",
    "\n",
    "# Run through model to get patch embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = model(processed, output_hidden_states=True)\n",
    "    embeddings = outputs.last_hidden_state  # [1, num_patches+1, hidden_dim]\n",
    "\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")  # [1, num_tokens, 768]\n",
    "\n",
    "# Drop CLS token and mask patches\n",
    "patches = embeddings[:, 1:, :]  # Remove CLS token, shape [1, N, D]\n",
    "B, N, D = patches.shape\n",
    "\n",
    "# Random masking (75%)\n",
    "mask_ratio = 0.75\n",
    "len_keep = int(N * (1 - mask_ratio))\n",
    "\n",
    "noise = torch.rand(B, N)\n",
    "ids_shuffle = torch.argsort(noise, dim=1)\n",
    "ids_keep = ids_shuffle[:, :len_keep]\n",
    "ids_restore = torch.argsort(ids_shuffle, dim=1)\n",
    "\n",
    "# Gather visible patches\n",
    "patches_visible = torch.gather(patches, 1, ids_keep.unsqueeze(-1).repeat(1, 1, D))\n",
    "print(f\"Visible patches shape: {patches_visible.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fb85da",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (392x768 and 512x512)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 87\u001b[0m\n\u001b[1;32m     84\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(decoder\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# ----------- Forward + Loss -----------\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m decoder_output \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvisible_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids_restore\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (B, N, D)\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# Compute loss only on masked tokens\u001b[39;00m\n\u001b[1;32m     90\u001b[0m mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(B, N, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mscatter(\u001b[38;5;241m1\u001b[39m, ids_keep, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mbool()  \u001b[38;5;66;03m# (B, N)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[19], line 69\u001b[0m, in \u001b[0;36mMAEDecoder.forward\u001b[0;34m(self, visible_tokens, ids_restore)\u001b[0m\n\u001b[1;32m     66\u001b[0m N_total \u001b[38;5;241m=\u001b[39m ids_restore\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Project to decoder dim\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear_in\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvisible_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Create [MASK] tokens for missing patches\u001b[39;00m\n\u001b[1;32m     72\u001b[0m mask_token \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mParameter(torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, D, device\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdevice))\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (392x768 and 512x512)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from transformers import AutoImageProcessor, TimesformerModel\n",
    "from einops import rearrange\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# ----------- Configuration -----------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "num_frames = 8\n",
    "height = width = 224\n",
    "patch_dim = 768  # TimeSformer hidden size\n",
    "mask_ratio = 0.75\n",
    "\n",
    "# ----------- Load TimeSformer encoder -----------\n",
    "model = TimesformerModel.from_pretrained(\"facebook/timesformer-base-finetuned-k400\").to(device)\n",
    "processor = AutoImageProcessor.from_pretrained(\"facebook/timesformer-base-finetuned-k400\")\n",
    "\n",
    "# ----------- Dummy video data (uint8) -----------\n",
    "# Simulate a batch of 1 video: (T, C, H, W)\n",
    "video = torch.randint(0, 255, (num_frames, 3, height, width), dtype=torch.uint8)\n",
    "\n",
    "# ----------- Convert to PIL frames -----------\n",
    "to_pil = transforms.ToPILImage()\n",
    "frames = [to_pil(frame) for frame in video]  # List of PIL images\n",
    "\n",
    "# ----------- Preprocess video -----------\n",
    "encoding = processor(frames, return_tensors='pt')\n",
    "pixel_values = encoding[\"pixel_values\"].to(device)  # (1, T, C, H, W)\n",
    "\n",
    "# ----------- Encoder forward pass -----------\n",
    "with torch.no_grad():\n",
    "    outputs = model(pixel_values=pixel_values, output_hidden_states=True)\n",
    "    all_tokens = outputs.last_hidden_state  # (1, num_tokens, 768)\n",
    "\n",
    "# ----------- Remove CLS token -----------\n",
    "patch_tokens = all_tokens[:, 1:, :]  # (1, N, D)\n",
    "B, N, D = patch_tokens.shape\n",
    "\n",
    "# ----------- Random masking -----------\n",
    "def random_masking(x, mask_ratio):\n",
    "    len_keep = int(x.shape[1] * (1 - mask_ratio))\n",
    "    noise = torch.rand(B, N, device=x.device)\n",
    "    ids_shuffle = torch.argsort(noise, dim=1)\n",
    "    ids_restore = torch.argsort(ids_shuffle, dim=1)\n",
    "\n",
    "    ids_keep = ids_shuffle[:, :len_keep]\n",
    "    x_masked = torch.gather(x, dim=1, index=ids_keep.unsqueeze(-1).repeat(1, 1, D))\n",
    "\n",
    "    return x_masked, ids_restore, ids_keep\n",
    "\n",
    "visible_tokens, ids_restore, ids_keep = random_masking(patch_tokens, mask_ratio)\n",
    "\n",
    "# ----------- Tiny decoder -----------\n",
    "class MAEDecoder(nn.Module):\n",
    "    def __init__(self, input_dim=768, decoder_dim=512, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.linear_in = nn.Linear(input_dim, decoder_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=decoder_dim, nhead=8)\n",
    "        self.decoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.linear_out = nn.Linear(decoder_dim, input_dim)\n",
    "\n",
    "    def forward(self, visible_tokens, ids_restore):\n",
    "        B, N_visible, D = visible_tokens.shape\n",
    "        N_total = ids_restore.shape[1]\n",
    "\n",
    "        # Project to decoder dim\n",
    "        x = self.linear_in(visible_tokens)\n",
    "\n",
    "        # Create [MASK] tokens for missing patches\n",
    "        mask_token = nn.Parameter(torch.zeros(1, 1, D, device=x.device))\n",
    "        x_full = mask_token.expand(B, N_total, -1).clone()\n",
    "        x_full.scatter_(1, ids_keep.unsqueeze(-1), x)\n",
    "\n",
    "        # Decode\n",
    "        x_decoded = self.decoder(x_full)\n",
    "        return self.linear_out(x_decoded)\n",
    "\n",
    "decoder = MAEDecoder().to(device)\n",
    "\n",
    "# ----------- Loss and optimizer -----------\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(decoder.parameters(), lr=1e-4)\n",
    "\n",
    "# ----------- Forward + Loss -----------\n",
    "decoder_output = decoder(visible_tokens, ids_restore)  # (B, N, D)\n",
    "\n",
    "# Compute loss only on masked tokens\n",
    "mask = torch.ones(B, N, device=device).scatter(1, ids_keep, 0).bool()  # (B, N)\n",
    "loss = criterion(decoder_output[mask], patch_tokens[mask])\n",
    "\n",
    "print(f\"MAE loss: {loss.item():.4f}\")\n",
    "\n",
    "# ----------- Backprop -----------\n",
    "loss.backward()\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14872cad",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[8, 0, 14, 8, 768]' is invalid for input of size 301056",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 74\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Pass visible tokens to encoder\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 74\u001b[0m     encoded \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_input\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpos_input\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][:, \u001b[38;5;241m1\u001b[39m:, :]  \u001b[38;5;66;03m# Remove CLS\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# ----------- Tiny decoder -----------\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mMAEDecoder\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/transformers/models/timesformer/modeling_timesformer.py:442\u001b[0m, in \u001b[0;36mTimesformerEncoder.forward\u001b[0;34m(self, hidden_states, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    436\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    437\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    438\u001b[0m         hidden_states,\n\u001b[1;32m    439\u001b[0m         output_attentions,\n\u001b[1;32m    440\u001b[0m     )\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 442\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/dion/lib/python3.10/site-packages/transformers/models/timesformer/modeling_timesformer.py:348\u001b[0m, in \u001b[0;36mTimesformerLayer.forward\u001b[0;34m(self, hidden_states, output_attentions)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdivided_space_time\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;66;03m# Temporal\u001b[39;00m\n\u001b[1;32m    347\u001b[0m     temporal_embedding \u001b[38;5;241m=\u001b[39m hidden_states[:, \u001b[38;5;241m1\u001b[39m:, :]\n\u001b[0;32m--> 348\u001b[0m     temporal_embedding \u001b[38;5;241m=\u001b[39m \u001b[43mtemporal_embedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_patch_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_patch_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemporal_embedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(batch_size \u001b[38;5;241m*\u001b[39m num_patch_height \u001b[38;5;241m*\u001b[39m num_patch_width, num_frames, temporal_embedding\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m    352\u001b[0m     temporal_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemporal_attention(\n\u001b[1;32m    353\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemporal_layernorm(temporal_embedding),\n\u001b[1;32m    354\u001b[0m     )\n\u001b[1;32m    355\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m temporal_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[8, 0, 14, 8, 768]' is invalid for input of size 301056"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from transformers import TimesformerModel, AutoImageProcessor\n",
    "from einops import rearrange\n",
    "import random\n",
    "\n",
    "# ----------- Configuration -----------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "num_frames = 8\n",
    "height = width = 224\n",
    "mask_ratio = 0.75\n",
    "\n",
    "# ----------- Load TimeSformer encoder -----------\n",
    "model = TimesformerModel.from_pretrained(\"facebook/timesformer-base-finetuned-k400\").to(device)\n",
    "processor = AutoImageProcessor.from_pretrained(\"facebook/timesformer-base-finetuned-k400\")\n",
    "\n",
    "# ----------- Dummy video data -----------\n",
    "video = torch.randint(0, 255, (num_frames, 3, height, width), dtype=torch.uint8)\n",
    "to_pil = transforms.ToPILImage()\n",
    "frames = [to_pil(frame) for frame in video]  # List of (H, W, C) PIL images\n",
    "\n",
    "# ----------- Preprocess video frames -----------\n",
    "encoding = processor(frames, return_tensors='pt')\n",
    "pixel_values = encoding[\"pixel_values\"].to(device)  # shape: (1, T, C, H, W)\n",
    "\n",
    "# ----------- Embed all patches (no encoder yet) -----------\n",
    "# We use the TimeSformer’s patch embedding layer directly\n",
    "patch_embed = model.embeddings.patch_embeddings  # Conv3D patch embedding\n",
    "B, T, C, H, W = pixel_values.shape\n",
    "# video_embeds = patch_embed(pixel_values)  # shape: (B, D, T', H', W')\n",
    "video_embeds = patch_embed(pixel_values)[0]  # <- FIXED HERE ✅\n",
    "patches = video_embeds\n",
    "\n",
    "# Flatten to patches\n",
    "# patches = rearrange(video_embeds, 'b d t h w -> b (t h w) d')  # [B, N, D]\n",
    "B, N, D = patches.shape\n",
    "\n",
    "# ----------- Random masking BEFORE encoder -----------\n",
    "def random_masking(x, mask_ratio):\n",
    "    len_keep = int(x.shape[1] * (1 - mask_ratio))\n",
    "    noise = torch.rand(B, N, device=x.device)\n",
    "    ids_shuffle = torch.argsort(noise, dim=1)\n",
    "    ids_restore = torch.argsort(ids_shuffle, dim=1)\n",
    "\n",
    "    ids_keep = ids_shuffle[:, :len_keep]\n",
    "    x_visible = torch.gather(x, dim=1, index=ids_keep.unsqueeze(-1).repeat(1, 1, D))\n",
    "\n",
    "    return x_visible, ids_restore, ids_keep\n",
    "\n",
    "patches_visible, ids_restore, ids_keep = random_masking(patches, mask_ratio)\n",
    "\n",
    "# ----------- Encoder input: visible patches only -----------\n",
    "# Add dummy CLS token to match input shape\n",
    "cls_token = model.embeddings.cls_token.expand(B, -1, -1)\n",
    "encoder_input = torch.cat([cls_token, patches_visible], dim=1)\n",
    "\n",
    "# # Positional embeddings (use subset of visible)\n",
    "# pos_embed = model.embeddings.position_embeddings[:, 1:, :]  # exclude CLS pos\n",
    "# pos_visible = torch.gather(pos_embed.expand(B, -1, -1), 1, ids_keep.unsqueeze(-1).repeat(1, 1, D))\n",
    "# pos_input = torch.cat([model.embeddings.position_embeddings[:, :1, :], pos_visible], dim=1)\n",
    "# Positional embeddings\n",
    "pos_embed = model.embeddings.position_embeddings[:, 1:, :]  # exclude CLS\n",
    "pos_embed = pos_embed.expand(B, -1, -1)                     # [B, N, D]\n",
    "pos_visible = torch.gather(pos_embed, 1, ids_keep.unsqueeze(-1).repeat(1, 1, D))  # [B, N_visible, D]\n",
    "\n",
    "# Add CLS position embedding (expand to B)\n",
    "cls_pos = model.embeddings.position_embeddings[:, :1, :].expand(B, -1, -1)  # [B, 1, D]\n",
    "pos_input = torch.cat([cls_pos, pos_visible], dim=1)  # [B, N_visible+1, D]\n",
    "\n",
    "\n",
    "# Pass visible tokens to encoder\n",
    "with torch.no_grad():\n",
    "    encoded = model.encoder(encoder_input + pos_input)[0][:, 1:, :]  # Remove CLS\n",
    "\n",
    "# ----------- Tiny decoder -----------\n",
    "class MAEDecoder(nn.Module):\n",
    "    def __init__(self, input_dim=768, decoder_dim=512, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.linear_in = nn.Linear(input_dim, decoder_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=decoder_dim, nhead=8)\n",
    "        self.decoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.linear_out = nn.Linear(decoder_dim, input_dim)\n",
    "\n",
    "    def forward(self, visible_tokens, ids_restore):\n",
    "        B, N_visible, D = visible_tokens.shape\n",
    "        N_total = ids_restore.shape[1]\n",
    "\n",
    "        # Project to decoder dim\n",
    "        x = self.linear_in(visible_tokens)\n",
    "\n",
    "        # Create [MASK] tokens for missing patches\n",
    "        mask_token = nn.Parameter(torch.zeros(1, 1, x.size(-1), device=x.device))\n",
    "        x_full = mask_token.expand(B, N_total, -1).clone()\n",
    "        x_full.scatter_(1, ids_keep.unsqueeze(-1), x)\n",
    "\n",
    "        # Decode\n",
    "        x_decoded = self.decoder(x_full)\n",
    "        return self.linear_out(x_decoded)\n",
    "\n",
    "decoder = MAEDecoder().to(device)\n",
    "\n",
    "# ----------- Loss and optimizer -----------\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(decoder.parameters(), lr=1e-4)\n",
    "\n",
    "# ----------- Forward + Loss -----------\n",
    "reconstructed = decoder(encoded, ids_restore)  # (B, N, D)\n",
    "\n",
    "# Compute loss only on masked patches\n",
    "mask = torch.ones(B, N, device=device).scatter(1, ids_keep, 0).bool()\n",
    "loss = criterion(reconstructed[mask], patches[mask])\n",
    "\n",
    "print(f\"MAE loss: {loss.item():.4f}\")\n",
    "\n",
    "# ----------- Backprop -----------\n",
    "loss.backward()\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc65c82e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
